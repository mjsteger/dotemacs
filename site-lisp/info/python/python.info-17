This is python.info, produced by makeinfo version 4.8 from
build/texinfo/python.texi.

Generated by Sphinx 1.1pre.
INFO-DIR-SECTION Documentation tools
START-INFO-DIR-ENTRY
* Python: (python.info). The Python Programming Language
END-INFO-DIR-ENTRY

     Python 2.7.2, April 02, 2012

     Georg Brandl

     Copyright (C) 1990-2012, Python Software Foundation


File: python.info,  Node: Soapbox,  Prev: Debugging,  Up: doctest --- Test interactive Python examples

5.25.2.20 Soapbox
.................

As mentioned in the introduction, *note doctest: b6. has grown to have
three primary uses:

  1. Checking examples in docstrings.

  2. Regression testing.

  3. Executable documentation / literate testing.

  These uses have different requirements, and it is important to
distinguish them.  In particular, filling your docstrings with obscure
test cases makes for bad documentation.

  When writing a docstring, choose docstring examples with care.
There's an art to this that needs to be learned--it may not be natural
at first.  Examples should add genuine value to the documentation.  A
good example can often be worth many words. If done with care, the
examples will be invaluable for your users, and will pay back the time
it takes to collect them many times over as the years go by and things
change.  I'm still amazed at how often one of my *note doctest: b6.
examples stops working after a "harmless" change.

  Doctest also makes an excellent tool for regression testing,
especially if you don't skimp on explanatory text.  By interleaving
prose and examples, it becomes much easier to keep track of what's
actually being tested, and why.  When a test fails, good prose can make
it much easier to figure out what the problem is, and how it should be
fixed.  It's true that you could write extensive comments in code-based
testing, but few programmers do. Many have found that using doctest
approaches instead leads to much clearer tests.  Perhaps this is simply
because doctest makes writing prose a little easier than writing code,
while writing comments in code is a little harder.  I think it goes
deeper than just that: the natural attitude when writing a
doctest-based test is that you want to explain the fine points of your
software, and illustrate them with examples.  This in turn naturally
leads to test files that start with the simplest features, and
logically progress to complications and edge cases.  A coherent
narrative is the result, instead of a collection of isolated functions
that test isolated bits of functionality seemingly at random.  It's a
different attitude, and produces different results, blurring the
distinction between testing and explaining.

  Regression testing is best confined to dedicated objects or files.
There are several options for organizing tests:

   * Write text files containing test cases as interactive examples,
     and test the files using *note testfile(): 2158. or *note
     DocFileSuite(): 217d.  This is recommended, although is easiest to
     do for new projects, designed from the start to use doctest.

   * Define functions named `_regrtest_topic' that consist of single
     docstrings, containing test cases for the named topics.  These
     functions can be included in the same file as the module, or
     separated out into a separate test file.

   * Define a `__test__' dictionary mapping from regression test topics
     to docstrings containing test cases.


File: python.info,  Node: unittest --- Unit testing framework,  Next: 2to3 - Automated Python 2 to 3 code translation,  Prev: doctest --- Test interactive Python examples,  Up: Development Tools

5.25.3 `unittest' -- Unit testing framework
-------------------------------------------

New in version 2.1.

  (If you are already familiar with the basic concepts of testing, you
might want to skip to *note the list of assert methods: 21be.)

  The Python unit testing framework, sometimes referred to as "PyUnit,"
is a Python language version of JUnit, by Kent Beck and Erich Gamma.
JUnit is, in turn, a Java version of Kent's Smalltalk testing
framework.  Each is the de facto standard unit testing framework for
its respective language.

  *note unittest: 188. supports test automation, sharing of setup and
shutdown code for tests, aggregation of tests into collections, and
independence of the tests from the reporting framework.  The *note
unittest: 188. module provides classes that make it easy to support
these qualities for a set of tests.

  To achieve this, *note unittest: 188. supports some important
concepts:

test fixture
     A _test fixture_ represents the preparation needed to perform one
     or more tests, and any associate cleanup actions.  This may
     involve, for example, creating temporary or proxy databases,
     directories, or starting a server process.

test case
     A _test case_ is the smallest unit of testing.  It checks for a
     specific response to a particular set of inputs.  *note unittest:
     188. provides a base class, *note TestCase: 27d, which may be used
     to create new test cases.

test suite
     A _test suite_ is a collection of test cases, test suites, or
     both.  It is used to aggregate tests that should be executed
     together.

test runner
     A _test runner_ is a component which orchestrates the execution of
     tests and provides the outcome to the user.  The runner may use a
     graphical interface, a textual interface, or return a special
     value to indicate the results of executing the tests.

  The test case and test fixture concepts are supported through the
*note TestCase: 27d. and *note FunctionTestCase: 21bf. classes; the
former should be used when creating new tests, and the latter can be
used when integrating existing test code with a *note unittest:
188.-driven framework. When building test fixtures using *note
TestCase: 27d, the *note setUp(): 283. and *note tearDown(): 284.
methods can be overridden to provide initialization and cleanup for the
fixture.  With *note FunctionTestCase: 21bf, existing functions can be
passed to the constructor for these purposes.  When the test is run, the
fixture initialization is run first; if it succeeds, the cleanup method
is run after the test has been executed, regardless of the outcome of
the test.  Each instance of the *note TestCase: 27d. will only be used
to run a single test method, so a new fixture is created for each test.

  Test suites are implemented by the *note TestSuite: 44c. class.  This
class allows individual tests and test suites to be aggregated; when
the suite is executed, all tests added directly to the suite and in
"child" test suites are run.

  A test runner is an object that provides a single method, `run()',
which accepts a *note TestCase: 27d. or *note TestSuite: 44c.  object
as a parameter, and returns a result object.  The class *note
TestResult: 2a3. is provided for use as the result object. *note
unittest: 188.  provides the *note TextTestRunner: 21c0. as an example
test runner which reports test results on the standard error stream by
default.  Alternate runners can be implemented for other environments
(such as graphical environments) without any need to derive from a
specific class.

See also
........

Module *note doctest: b6.
     Another test-support module with a very different flavor.

unittest2: A backport of new unittest features for Python 2.4-2.6(1)
     Many new features were added to unittest in Python 2.7, including
     test discovery. unittest2 allows you to use these features with
     earlier versions of Python.

Simple Smalltalk Testing: With Patterns(2)
     Kent Beck's original paper on testing frameworks using the pattern
     shared by *note unittest: 188.

Nose(3) and py.test(4)
     Third-party unittest frameworks with a lighter-weight syntax for
     writing tests.  For example, `assert func(10) == 42'.

The Python Testing Tools Taxonomy(5)
     An extensive list of Python testing tools including functional
     testing frameworks and mock object libraries.

Testing in Python Mailing List(6)
     A special-interest-group for discussion of testing, and testing
     tools, in Python.

* Menu:

* Basic example::
* Command-Line Interface::
* Test Discovery::
* Organizing test code::
* Re-using old test code::
* Skipping tests and expected failures::
* Classes and functions::
* Class and Module Fixtures::
* Signal Handling::

  ---------- Footnotes ----------

  (1) http://pypi.python.org/pypi/unittest2

  (2) http://www.XProgramming.com/testfram.htm

  (3) http://code.google.com/p/python-nose/

  (4) http://pytest.org

  (5) http://pycheesecake.org/wiki/PythonTestingToolsTaxonomy

  (6) http://lists.idyll.org/listinfo/testing-in-python


File: python.info,  Node: Basic example,  Next: Command-Line Interface,  Up: unittest --- Unit testing framework

5.25.3.1 Basic example
......................

The *note unittest: 188. module provides a rich set of tools for
constructing and running tests.  This section demonstrates that a small
subset of the tools suffice to meet the needs of most users.

  Here is a short script to test three functions from the *note random:
143. module:

    import random
    import unittest

    class TestSequenceFunctions(unittest.TestCase):

        def setUp(self):
            self.seq = range(10)

        def test_shuffle(self):
            # make sure the shuffled sequence does not lose any elements
            random.shuffle(self.seq)
            self.seq.sort()
            self.assertEqual(self.seq, range(10))

            # should raise an exception for an immutable sequence
            self.assertRaises(TypeError, random.shuffle, (1,2,3))

        def test_choice(self):
            element = random.choice(self.seq)
            self.assertTrue(element in self.seq)

        def test_sample(self):
            with self.assertRaises(ValueError):
                random.sample(self.seq, 20)
            for element in random.sample(self.seq, 5):
                self.assertTrue(element in self.seq)

    if __name__ == '__main__':
        unittest.main()

A testcase is created by subclassing *note unittest.TestCase: 27d.  The
three individual tests are defined with methods whose names start with
the letters `test'.  This naming convention informs the test runner
about which methods represent tests.

  The crux of each test is a call to *note assertEqual(): 279. to check
for an expected result; *note assertTrue(): 27a. to verify a condition;
or *note assertRaises(): 27e. to verify that an expected exception gets
raised.  These methods are used instead of the *note assert: 441.
statement so the test runner can accumulate all test results and
produce a report.

  When a *note setUp(): 283. method is defined, the test runner will
run that method prior to each test.  Likewise, if a *note tearDown():
284. method is defined, the test runner will invoke that method after
each test.  In the example, *note setUp(): 283. was used to create a
fresh sequence for each test.

  The final block shows a simple way to run the tests. *note
unittest.main(): 276.  provides a command-line interface to the test
script.  When run from the command line, the above script produces an
output that looks like this:

    ...
    ----------------------------------------------------------------------
    Ran 3 tests in 0.000s

    OK

Instead of *note unittest.main(): 276, there are other ways to run the
tests with a finer level of control, less terse output, and no
requirement to be run from the command line.  For example, the last two
lines may be replaced with:

    suite = unittest.TestLoader().loadTestsFromTestCase(TestSequenceFunctions)
    unittest.TextTestRunner(verbosity=2).run(suite)

Running the revised script from the interpreter or another script
produces the following output:

    test_choice (__main__.TestSequenceFunctions) ... ok
    test_sample (__main__.TestSequenceFunctions) ... ok
    test_shuffle (__main__.TestSequenceFunctions) ... ok

    ----------------------------------------------------------------------
    Ran 3 tests in 0.110s

    OK

The above examples show the most commonly used *note unittest: 188.
features which are sufficient to meet many everyday testing needs.  The
remainder of the documentation explores the full feature set from first
principles.


File: python.info,  Node: Command-Line Interface,  Next: Test Discovery,  Prev: Basic example,  Up: unittest --- Unit testing framework

5.25.3.2 Command-Line Interface
...............................

The unittest module can be used from the command line to run tests from
modules, classes or even individual test methods:

    python -m unittest test_module1 test_module2
    python -m unittest test_module.TestClass
    python -m unittest test_module.TestClass.test_method

You can pass in a list with any combination of module names, and fully
qualified class or method names.

  You can run tests with more detail (higher verbosity) by passing in
the -v flag:

    python -m unittest -v test_module

For a list of all the command-line options:

    python -m unittest -h

Changed in version 2.7: In earlier versions it was only possible to run
individual test methods and not modules or classes.

* Menu:

* Command-line options::


File: python.info,  Node: Command-line options,  Up: Command-Line Interface

5.25.3.3 Command-line options
.............................

*unittest* supports these command-line options:

 -- Program Option: -b, -buffer
     The standard output and standard error streams are buffered during
     the test run. Output during a passing test is discarded. Output is
     echoed normally on test fail or error and is added to the failure
     messages.

 -- Program Option: -c, -catch
     Control-C during the test run waits for the current test to end
     and then reports all the results so far. A second control-C raises
     the normal *note KeyboardInterrupt: 24e. exception.

     See *note Signal Handling: 21c8. for the functions that provide
     this functionality.

 -- Program Option: -f, -failfast
     Stop the test run on the first error or failure.

  New in version 2.7: The command-line options `-b', `-c' and `-f' were
added.

  The command line can also be used for test discovery, for running all
of the tests in a project or just a subset.


File: python.info,  Node: Test Discovery,  Next: Organizing test code,  Prev: Command-Line Interface,  Up: unittest --- Unit testing framework

5.25.3.4 Test Discovery
.......................

New in version 2.7.

  Unittest supports simple test discovery. In order to be compatible
with test discovery, all of the test files must be *note modules: 55a.
or *note packages: 56d. importable from the top-level directory of the
project (this means that their filenames must be valid *note
identifiers: 689.).

  Test discovery is implemented in *note TestLoader.discover(): 21cc,
but can also be used from the command line. The basic command-line
usage is:

    cd project_directory
    python -m unittest discover

The `discover' sub-command has the following options:

 -- Program Option: -v, -verbose
     Verbose output

 -- Program Option: -s directory
     Directory to start discovery ('.' default)

 -- Program Option: -p pattern
     Pattern to match test files ('test*.py' default)

 -- Program Option: -t directory
     Top level directory of project (defaults to start directory)

  The *note -s: 21ce, *note -p: 21cf, and *note -t: 21d0. options can
be passed in as positional arguments in that order. The following two
command lines are equivalent:

    python -m unittest discover -s project_directory -p '*_test.py'
    python -m unittest discover project_directory '*_test.py'

As well as being a path it is possible to pass a package name, for
example `myproject.subpackage.test', as the start directory. The
package name you supply will then be imported and its location on the
filesystem will be used as the start directory.

     Caution: Test discovery loads tests by importing them. Once test
     discovery has found all the test files from the start directory
     you specify it turns the paths into package names to import. For
     example `foo/bar/baz.py' will be imported as `foo.bar.baz'.

     If you have a package installed globally and attempt test
     discovery on a different copy of the package then the import
     _could_ happen from the wrong place. If this happens test
     discovery will warn you and exit.

     If you supply the start directory as a package name rather than a
     path to a directory then discover assumes that whichever location
     it imports from is the location you intended, so you will not get
     the warning.

  Test modules and packages can customize test loading and discovery by
through the *note load_tests protocol: 21d1.


File: python.info,  Node: Organizing test code,  Next: Re-using old test code,  Prev: Test Discovery,  Up: unittest --- Unit testing framework

5.25.3.5 Organizing test code
.............................

The basic building blocks of unit testing are _test cases_ -- single
scenarios that must be set up and checked for correctness.  In *note
unittest: 188, test cases are represented by instances of *note
unittest: 188.'s *note TestCase: 27d.  class. To make your own test
cases you must write subclasses of *note TestCase: 27d, or use *note
FunctionTestCase: 21bf.

  An instance of a *note TestCase: 27d.-derived class is an object that
can completely run a single test method, together with optional set-up
and tidy-up code.

  The testing code of a *note TestCase: 27d. instance should be
entirely self contained, such that it can be run either in isolation or
in arbitrary combination with any number of other test cases.

  The simplest *note TestCase: 27d. subclass will simply override the
`runTest()' method in order to perform specific testing code:

    import unittest

    class DefaultWidgetSizeTestCase(unittest.TestCase):
        def runTest(self):
            widget = Widget('The widget')
            self.assertEqual(widget.size(), (50, 50), 'incorrect default size')

Note that in order to test something, we use the one of the `assert*()'
methods provided by the *note TestCase: 27d. base class.  If the test
fails, an exception will be raised, and *note unittest: 188. will
identify the test case as a _failure_.  Any other exceptions will be
treated as _errors_. This helps you identify where the problem is:
_failures_ are caused by incorrect results - a 5 where you expected a
6. _Errors_ are caused by incorrect code - e.g., a *note TypeError:
215. caused by an incorrect function call.

  The way to run a test case will be described later.  For now, note
that to construct an instance of such a test case, we call its
constructor without arguments:

    testCase = DefaultWidgetSizeTestCase()

Now, such test cases can be numerous, and their set-up can be
repetitive.  In the above case, constructing a `Widget' in each of 100
Widget test case subclasses would mean unsightly duplication.

  Luckily, we can factor out such set-up code by implementing a method
called *note setUp(): 283, which the testing framework will
automatically call for us when we run the test:

    import unittest

    class SimpleWidgetTestCase(unittest.TestCase):
        def setUp(self):
            self.widget = Widget('The widget')

    class DefaultWidgetSizeTestCase(SimpleWidgetTestCase):
        def runTest(self):
            self.assertEqual(self.widget.size(), (50,50),
                             'incorrect default size')

    class WidgetResizeTestCase(SimpleWidgetTestCase):
        def runTest(self):
            self.widget.resize(100,150)
            self.assertEqual(self.widget.size(), (100,150),
                             'wrong size after resize')

If the *note setUp(): 283. method raises an exception while the test is
running, the framework will consider the test to have suffered an
error, and the `runTest()' method will not be executed.

  Similarly, we can provide a *note tearDown(): 284. method that tidies
up after the `runTest()' method has been run:

    import unittest

    class SimpleWidgetTestCase(unittest.TestCase):
        def setUp(self):
            self.widget = Widget('The widget')

        def tearDown(self):
            self.widget.dispose()
            self.widget = None

If *note setUp(): 283. succeeded, the *note tearDown(): 284. method will
be run whether `runTest()' succeeded or not.

  Such a working environment for the testing code is called a _fixture_.

  Often, many small test cases will use the same fixture.  In this
case, we would end up subclassing `SimpleWidgetTestCase' into many
small one-method classes such as `DefaultWidgetSizeTestCase'.  This is
time-consuming and discouraging, so in the same vein as JUnit, *note
unittest: 188. provides a simpler mechanism:

    import unittest

    class WidgetTestCase(unittest.TestCase):
        def setUp(self):
            self.widget = Widget('The widget')

        def tearDown(self):
            self.widget.dispose()
            self.widget = None

        def test_default_size(self):
            self.assertEqual(self.widget.size(), (50,50),
                             'incorrect default size')

        def test_resize(self):
            self.widget.resize(100,150)
            self.assertEqual(self.widget.size(), (100,150),
                             'wrong size after resize')

Here we have not provided a `runTest()' method, but have instead
provided two different test methods.  Class instances will now each run
one of the `test_*()' methods, with `self.widget' created and destroyed
separately for each instance.  When creating an instance we must
specify the test method it is to run.  We do this by passing the method
name in the constructor:

    defaultSizeTestCase = WidgetTestCase('test_default_size')
    resizeTestCase = WidgetTestCase('test_resize')

Test case instances are grouped together according to the features they
test.  *note unittest: 188. provides a mechanism for this: the _test
suite_, represented by *note unittest: 188.'s *note TestSuite: 44c.
class:

    widgetTestSuite = unittest.TestSuite()
    widgetTestSuite.addTest(WidgetTestCase('test_default_size'))
    widgetTestSuite.addTest(WidgetTestCase('test_resize'))

For the ease of running tests, as we will see later, it is a good idea
to provide in each test module a callable object that returns a
pre-built test suite:

    def suite():
        suite = unittest.TestSuite()
        suite.addTest(WidgetTestCase('test_default_size'))
        suite.addTest(WidgetTestCase('test_resize'))
        return suite

or even:

    def suite():
        tests = ['test_default_size', 'test_resize']

        return unittest.TestSuite(map(WidgetTestCase, tests))

Since it is a common pattern to create a *note TestCase: 27d. subclass
with many similarly named test functions, *note unittest: 188. provides
a *note TestLoader: 2a0.  class that can be used to automate the
process of creating a test suite and populating it with individual
tests. For example,

    suite = unittest.TestLoader().loadTestsFromTestCase(WidgetTestCase)

will create a test suite that will run
`WidgetTestCase.test_default_size()' and `WidgetTestCase.test_resize'.
*note TestLoader: 2a0. uses the `'test'' method name prefix to identify
test methods automatically.

  Note that the order in which the various test cases will be run is
determined by sorting the test function names with respect to the
built-in ordering for strings.

  Often it is desirable to group suites of test cases together, so as
to run tests for the whole system at once.  This is easy, since *note
TestSuite: 44c. instances can be added to a *note TestSuite: 44c. just
as *note TestCase: 27d. instances can be added to a *note TestSuite:
44c.:

    suite1 = module1.TheTestSuite()
    suite2 = module2.TheTestSuite()
    alltests = unittest.TestSuite([suite1, suite2])

You can place the definitions of test cases and test suites in the same
modules as the code they are to test (such as `widget.py'), but there
are several advantages to placing the test code in a separate module,
such as `test_widget.py':

   * The test module can be run standalone from the command line.

   * The test code can more easily be separated from shipped code.

   * There is less temptation to change test code to fit the code it
     tests without a good reason.

   * Test code should be modified much less frequently than the code it
     tests.

   * Tested code can be refactored more easily.

   * Tests for modules written in C must be in separate modules anyway,
     so why not be consistent?

   * If the testing strategy changes, there is no need to change the
     source code.


File: python.info,  Node: Re-using old test code,  Next: Skipping tests and expected failures,  Prev: Organizing test code,  Up: unittest --- Unit testing framework

5.25.3.6 Re-using old test code
...............................

Some users will find that they have existing test code that they would
like to run from *note unittest: 188, without converting every old test
function to a *note TestCase: 27d. subclass.

  For this reason, *note unittest: 188. provides a *note
FunctionTestCase: 21bf. class.  This subclass of *note TestCase: 27d.
can be used to wrap an existing test function.  Set-up and tear-down
functions can also be provided.

  Given the following test function:

    def testSomething():
        something = makeSomething()
        assert something.name is not None
        # ...

one can create an equivalent test case instance as follows:

    testcase = unittest.FunctionTestCase(testSomething)

If there are additional set-up and tear-down methods that should be
called as part of the test case's operation, they can also be provided
like so:

    testcase = unittest.FunctionTestCase(testSomething,
                                         setUp=makeSomethingDB,
                                         tearDown=deleteSomethingDB)

To make migrating existing test suites easier, *note unittest: 188.
supports tests raising *note AssertionError: 7dd. to indicate test
failure. However, it is recommended that you use the explicit
`TestCase.fail*()' and `TestCase.assert*()' methods instead, as future
versions of *note unittest: 188.  may treat *note AssertionError: 7dd.
differently.

     Note: Even though *note FunctionTestCase: 21bf. can be used to
     quickly convert an existing test base over to a *note unittest:
     188.-based system, this approach is not recommended.  Taking the
     time to set up proper *note TestCase: 27d.  subclasses will make
     future test refactorings infinitely easier.

  In some cases, the existing tests may have been written using the
*note doctest: b6.  module.  If so, *note doctest: b6. provides a
`DocTestSuite' class that can automatically build *note
unittest.TestSuite: 44c. instances from the existing *note doctest:
b6.-based tests.


File: python.info,  Node: Skipping tests and expected failures,  Next: Classes and functions,  Prev: Re-using old test code,  Up: unittest --- Unit testing framework

5.25.3.7 Skipping tests and expected failures
.............................................

New in version 2.7.

  Unittest supports skipping individual test methods and even whole
classes of tests.  In addition, it supports marking a test as a
"expected failure," a test that is broken and will fail, but shouldn't
be counted as a failure on a *note TestResult: 2a3.

  Skipping a test is simply a matter of using the *note skip(): 21d8.
*note decorator: 827.  or one of its conditional variants.

  Basic skipping looks like this:

    class MyTestCase(unittest.TestCase):

        @unittest.skip("demonstrating skipping")
        def test_nothing(self):
            self.fail("shouldn't happen")

        @unittest.skipIf(mylib.__version__ < (1, 3),
                         "not supported in this library version")
        def test_format(self):
            # Tests that work for only a certain version of the library.
            pass

        @unittest.skipUnless(sys.platform.startswith("win"), "requires Windows")
        def test_windows_support(self):
            # windows specific testing code
            pass

This is the output of running the example above in verbose mode:

    test_format (__main__.MyTestCase) ... skipped 'not supported in this library version'
    test_nothing (__main__.MyTestCase) ... skipped 'demonstrating skipping'
    test_windows_support (__main__.MyTestCase) ... skipped 'requires Windows'

    ----------------------------------------------------------------------
    Ran 3 tests in 0.005s

    OK (skipped=3)

Classes can be skipped just like methods:

    @skip("showing class skipping")
    class MySkippedTestCase(unittest.TestCase):
        def test_not_run(self):
            pass

*note TestCase.setUp(): 283. can also skip the test.  This is useful
when a resource that needs to be set up is not available.

  Expected failures use the *note expectedFailure(): 21d9. decorator.

    class ExpectedFailureTestCase(unittest.TestCase):
        @unittest.expectedFailure
        def test_fail(self):
            self.assertEqual(1, 0, "broken")

It's easy to roll your own skipping decorators by making a decorator
that calls *note skip(): 21d8. on the test when it wants it to be
skipped.  This decorator skips the test unless the passed object has a
certain attribute:

    def skipUnlessHasattr(obj, attr):
        if hasattr(obj, attr):
            return lambda func: func
        return unittest.skip("{0!r} doesn't have {1!r}".format(obj, attr))

The following decorators implement test skipping and expected failures:

 -- Function: unittest.skip (reason)
     Unconditionally skip the decorated test.  _reason_ should describe
     why the test is being skipped.

 -- Function: unittest.skipIf (condition, reason)
     Skip the decorated test if _condition_ is true.

 -- Function: unittest.skipUnless (condition, reason)
     Skip the decorated test unless _condition_ is true.

 -- Function: unittest.expectedFailure ()
     Mark the test as an expected failure.  If the test fails when run,
     the test is not counted as a failure.

  Skipped tests will not have `setUp()' or `tearDown()' run around them.
Skipped classes will not have `setUpClass()' or `tearDownClass()' run.


File: python.info,  Node: Classes and functions,  Next: Class and Module Fixtures,  Prev: Skipping tests and expected failures,  Up: unittest --- Unit testing framework

5.25.3.8 Classes and functions
..............................

This section describes in depth the API of *note unittest: 188.

* Menu:

* Test cases::
* Grouping tests::
* Loading and running tests::

Test cases

* Deprecated aliases::

Loading and running tests

* load_tests Protocol::


File: python.info,  Node: Test cases,  Next: Grouping tests,  Up: Classes and functions

5.25.3.9 Test cases
...................

 -- Class: unittest.TestCase (methodName='runTest')
     Instances of the *note TestCase: 27d. class represent the smallest
     testable units in the *note unittest: 188. universe.  This class
     is intended to be used as a base class, with specific tests being
     implemented by concrete subclasses.  This class implements the
     interface needed by the test runner to allow it to drive the test,
     and methods that the test code can use to check for and report
     various kinds of failure.

     Each instance of *note TestCase: 27d. will run a single test
     method: the method named _methodName_.  If you remember, we had an
     earlier example that went something like this:

         def suite():
             suite = unittest.TestSuite()
             suite.addTest(WidgetTestCase('test_default_size'))
             suite.addTest(WidgetTestCase('test_resize'))
             return suite

     Here, we create two instances of `WidgetTestCase', each of which
     runs a single test.

     _methodName_ defaults to `runTest()'.

     *note TestCase: 27d. instances provide three groups of methods:
     one group used to run the test, another used by the test
     implementation to check conditions and report failures, and some
     inquiry methods allowing information about the test itself to be
     gathered.

     Methods in the first group (running the test) are:

      -- Method: setUp ()
          Method called to prepare the test fixture.  This is called
          immediately before calling the test method; any exception
          raised by this method will be considered an error rather than
          a test failure. The default implementation does nothing.

      -- Method: tearDown ()
          Method called immediately after the test method has been
          called and the result recorded.  This is called even if the
          test method raised an exception, so the implementation in
          subclasses may need to be particularly careful about checking
          internal state.  Any exception raised by this method will be
          considered an error rather than a test failure.  This method
          will only be called if the *note setUp(): 283. succeeds,
          regardless of the outcome of the test method. The default
          implementation does nothing.

      -- Method: setUpClass ()
          A class method called before tests in an individual class run.
          `setUpClass' is called with the class as the only argument
          and must be decorated as a *note classmethod(): 3e5.:

              @classmethod
              def setUpClass(cls):
                  ...

          See *note Class and Module Fixtures: 21e0. for more details.

          New in version 2.7.

      -- Method: tearDownClass ()
          A class method called after tests in an individual class have
          run.  `tearDownClass' is called with the class as the only
          argument and must be decorated as a *note classmethod(): 3e5.:

              @classmethod
              def tearDownClass(cls):
                  ...

          See *note Class and Module Fixtures: 21e0. for more details.

          New in version 2.7.

      -- Method: run (result=None)
          Run the test, collecting the result into the test result
          object passed as _result_.  If _result_ is omitted or `None',
          a temporary result object is created (by calling the *note
          defaultTestResult(): 21e2. method) and used. The result
          object is not returned to *note run(): 21e1.'s caller.

          The same effect may be had by simply calling the *note
          TestCase: 27d.  instance.

      -- Method: skipTest (reason)
          Calling this during a test method or *note setUp(): 283.
          skips the current test.  See *note Skipping tests and
          expected failures: 21d7. for more information.

          New in version 2.7.

      -- Method: debug ()
          Run the test without collecting the result.  This allows
          exceptions raised by the test to be propagated to the caller,
          and can be used to support running tests under a debugger.

     The *note TestCase: 27d. class provides a number of methods to
     check for and report failures, such as:

     Method                                        Checks that                       New in
     ---------------------------------------------------------------------------------------------------- 
     *note assertEqual(a, b): 279.                 `a == b'                          
     *note assertNotEqual(a, b): 21e5.             `a != b'                          
     *note assertTrue(x): 27a.                     `bool(x) is True'                 
     *note assertFalse(x): 27b.                    `bool(x) is False'                
     *note assertIs(a, b): 287.                    `a is b'                          2.7
     *note assertIsNot(a, b): 288.                 `a is not b'                      2.7
     *note assertIsNone(x): 285.                   `x is None'                       2.7
     *note assertIsNotNone(x): 286.                `x is not None'                   2.7
     *note assertIn(a, b): 293.                    `a in b'                          2.7
     *note assertNotIn(a, b): 294.                 `a not in b'                      2.7
     *note assertIsInstance(a, b): 289.            `isinstance(a, b)'                2.7
     *note assertNotIsInstance(a, b): 28a.         `not isinstance(a, b)'            2.7

     All the assert methods (except *note assertRaises(): 27e, *note
     assertRaisesRegexp(): 292.)  accept a _msg_ argument that, if
     specified, is used as the error message on failure (see also *note
     longMessage: 27c.).

      -- Method: assertEqual (first, second, msg=None)
          Test that _first_ and _second_ are equal.  If the values do
          not compare equal, the test will fail.

          In addition, if _first_ and _second_ are the exact same type
          and one of list, tuple, dict, set, frozenset or unicode or
          any type that a subclass registers with *note
          addTypeEqualityFunc(): 2a1. the type specific equality
          function will be called in order to generate a more useful
          default error message (see also the *note list of
          type-specific methods: 21e6.).

          Changed in version 2.7: Added the automatic calling of type
          specific equality function.

      -- Method: assertNotEqual (first, second, msg=None)
          Test that _first_ and _second_ are not equal.  If the values
          do compare equal, the test will fail.

      -- Method: assertTrue (expr, msg=None)
      -- Method: assertFalse (expr, msg=None)
          Test that _expr_ is true (or false).

          Note that this is equivalent to `bool(expr) is True' and not
          to `expr is True' (use `assertIs(expr, True)' for the
          latter).  This method should also be avoided when more
          specific methods are available (e.g.  `assertEqual(a, b)'
          instead of `assertTrue(a == b)'), because they provide a
          better error message in case of failure.

      -- Method: assertIs (first, second, msg=None)
      -- Method: assertIsNot (first, second, msg=None)
          Test that _first_ and _second_ evaluate (or don't evaluate)
          to the same object.

          New in version 2.7.

      -- Method: assertIsNone (expr, msg=None)
      -- Method: assertIsNotNone (expr, msg=None)
          Test that _expr_ is (or is not) None.

          New in version 2.7.

      -- Method: assertIn (first, second, msg=None)
      -- Method: assertNotIn (first, second, msg=None)
          Test that _first_ is (or is not) in _second_.

          New in version 2.7.

      -- Method: assertIsInstance (obj, cls, msg=None)
      -- Method: assertNotIsInstance (obj, cls, msg=None)
          Test that _obj_ is (or is not) an instance of _cls_ (which
          can be a class or a tuple of classes, as supported by *note
          isinstance(): 30e.).

          New in version 2.7.

     It is also possible to check that exceptions and warnings are
     raised using the following methods:

     Method                                                        Checks that                                New in
     -------------------------------------------------------------------------------------------------------------------------- 
     *note assertRaises(exc, fun, *args, **kwds): 27e.             `fun(*args, **kwds)' raises `exc'          
     *note assertRaisesRegexp(exc, re, fun, *args, **kwds): 292.   `fun(*args, **kwds)' raises `exc' and the  2.7
                                                                   message matches `re'                       

      -- Method: assertRaises (exception, callable, *args, **kwds)
      -- Method: assertRaises (exception)
          Test that an exception is raised when _callable_ is called
          with any positional or keyword arguments that are also passed
          to *note assertRaises(): 27e.  The test passes if _exception_
          is raised, is an error if another exception is raised, or
          fails if no exception is raised.  To catch any of a group of
          exceptions, a tuple containing the exception classes may be
          passed as _exception_.

          If only the _exception_ argument is given, returns a context
          manager so that the code under test can be written inline
          rather than as a function:

              with self.assertRaises(SomeException):
                  do_something()

          The context manager will store the caught exception object in
          its `exception' attribute.  This can be useful if the
          intention is to perform additional checks on the exception
          raised:

              with self.assertRaises(SomeException) as cm:
                  do_something()

              the_exception = cm.exception
              self.assertEqual(the_exception.error_code, 3)

          Changed in version 2.7: Added the ability to use *note
          assertRaises(): 27e. as a context manager.

      -- Method: assertRaisesRegexp (exception, regexp, callable,
               *args, **kwds)
      -- Method: assertRaisesRegexp (exception, regexp)
          Like *note assertRaises(): 27e. but also tests that _regexp_
          matches on the string representation of the raised exception.
          _regexp_ may be a regular expression object or a string
          containing a regular expression suitable for use by *note
          re.search(): 988.  Examples:

              self.assertRaisesRegexp(ValueError, 'invalid literal for.*XYZ$',
                                      int, 'XYZ')

          or:

              with self.assertRaisesRegexp(ValueError, 'literal'):
                 int('XYZ')

          New in version 2.7.

     There are also other methods used to perform more specific checks,
     such as:

     Method                                      Checks that                          New in
     ---------------------------------------------------------------------------------------------------- 
     *note assertAlmostEqual(a, b): 29c.         `round(a-b, 7) == 0'                 
     *note assertNotAlmostEqual(a, b): 29d.      `round(a-b, 7) != 0'                 
     *note assertGreater(a, b): 28b.             `a > b'                              2.7
     *note assertGreaterEqual(a, b): 28c.        `a >= b'                             2.7
     *note assertLess(a, b): 28d.                `a < b'                              2.7
     *note assertLessEqual(a, b): 28e.           `a <= b'                             2.7
     *note assertRegexpMatches(s, re): 290.      `regex.search(s)'                    2.7
     *note assertNotRegexpMatches(s, re): 291.   `not regex.search(s)'                2.7
     *note assertItemsEqual(a, b): 295.          sorted(a) == sorted(b) and works     2.7
                                                 with unhashable objs                 
     *note assertDictContainsSubset(a, b): 29b.  all the key/value pairs in `a'       2.7
                                                 exist in `b'                         

      -- Method: assertAlmostEqual (first, second, places=7, msg=None,
               delta=None)
      -- Method: assertNotAlmostEqual (first, second, places=7,
               msg=None, delta=None)
          Test that _first_ and _second_ are approximately (or not
          approximately) equal by computing the difference, rounding to
          the given number of decimal _places_ (default 7), and
          comparing to zero.  Note that these methods round the values
          to the given number of _decimal places_ (i.e.  like the *note
          round(): 1c2. function) and not _significant digits_.

          If _delta_ is supplied instead of _places_ then the difference
          between _first_ and _second_ must be less (or more) than
          _delta_.

          Supplying both _delta_ and _places_ raises a `TypeError'.

          Changed in version 2.7: *note assertAlmostEqual(): 29c.
          automatically considers almost equal objects that compare
          equal.  *note assertNotAlmostEqual(): 29d. automatically fails
          if the objects compare equal.  Added the _delta_ keyword
          argument.

      -- Method: assertGreater (first, second, msg=None)
      -- Method: assertGreaterEqual (first, second, msg=None)
      -- Method: assertLess (first, second, msg=None)
      -- Method: assertLessEqual (first, second, msg=None)
          Test that _first_ is respectively >, >=, < or <= than
          _second_ depending on the method name.  If not, the test will
          fail:

              >>> self.assertGreaterEqual(3, 4)
              AssertionError: "3" unexpectedly not greater than or equal to "4"

          New in version 2.7.

      -- Method: assertRegexpMatches (text, regexp, msg=None)
          Test that a _regexp_ search matches _text_.  In case of
          failure, the error message will include the pattern and the
          _text_ (or the pattern and the part of _text_ that
          unexpectedly matched).  _regexp_ may be a regular expression
          object or a string containing a regular expression suitable
          for use by *note re.search(): 988.

          New in version 2.7.

      -- Method: assertNotRegexpMatches (text, regexp, msg=None)
          Verifies that a _regexp_ search does not match _text_.  Fails
          with an error message including the pattern and the part of
          _text_ that matches.  _regexp_ may be a regular expression
          object or a string containing a regular expression suitable
          for use by *note re.search(): 988.

          New in version 2.7.

      -- Method: assertItemsEqual (actual, expected, msg=None)
          Test that sequence _expected_ contains the same elements as
          _actual_, regardless of their order. When they don't, an
          error message listing the differences between the sequences
          will be generated.

          Duplicate elements are _not_ ignored when comparing _actual_
          and _expected_. It verifies if each element has the same
          count in both sequences. It is the equivalent of
          `assertEqual(sorted(expected), sorted(actual))' but it works
          with sequences of unhashable objects as well.

          New in version 2.7.

      -- Method: assertDictContainsSubset (expected, actual, msg=None)
          Tests whether the key/value pairs in dictionary _actual_ are a
          superset of those in _expected_.  If not, an error message
          listing the missing keys and mismatched values is generated.

          New in version 2.7.

          Deprecated since version 3.2.

     The *note assertEqual(): 279. method dispatches the equality check
     for objects of the same type to different type-specific methods.
     These methods are already implemented for most of the built-in
     types, but it's also possible to register new methods using *note
     addTypeEqualityFunc(): 2a1.:

      -- Method: addTypeEqualityFunc (typeobj, function)
          Registers a type-specific method called by *note
          assertEqual(): 279. to check if two objects of exactly the
          same _typeobj_ (not subclasses) compare equal.  _function_
          must take two positional arguments and a third msg=None
          keyword argument just as *note assertEqual(): 279. does.  It
          must raise *note self.failureException(msg): 21e7. when
          inequality between the first two parameters is detected -
          possibly providing useful information and explaining the
          inequalities in details in the error message.

          New in version 2.7.

     The list of type-specific methods automatically used by *note
     assertEqual(): 279. are summarized in the following table.  Note
     that it's usually not necessary to invoke these methods directly.

     Method                                        Used to compare                   New in
     --------------------------------------------------------------------------------------------------- 
     *note assertMultiLineEqual(a, b): 28f.        strings                           2.7
     *note assertSequenceEqual(a, b): 299.         sequences                         2.7
     *note assertListEqual(a, b): 297.             lists                             2.7
     *note assertTupleEqual(a, b): 298.            tuples                            2.7
     *note assertSetEqual(a, b): 296.              sets or frozensets                2.7
     *note assertDictEqual(a, b): 29a.             dicts                             2.7

      -- Method: assertMultiLineEqual (first, second, msg=None)
          Test that the multiline string _first_ is equal to the string
          _second_.  When not equal a diff of the two strings
          highlighting the differences will be included in the error
          message. This method is used by default when comparing
          strings with *note assertEqual(): 279.

          New in version 2.7.

      -- Method: assertSequenceEqual (seq1, seq2, msg=None,
               seq_type=None)
          Tests that two sequences are equal.  If a _seq_type_ is
          supplied, both _seq1_ and _seq2_ must be instances of
          _seq_type_ or a failure will be raised.  If the sequences are
          different an error message is constructed that shows the
          difference between the two.

          This method is not called directly by *note assertEqual():
          279, but it's used to implement *note assertListEqual(): 297.
          and *note assertTupleEqual(): 298.

          New in version 2.7.

      -- Method: assertListEqual (list1, list2, msg=None)
      -- Method: assertTupleEqual (tuple1, tuple2, msg=None)
          Tests that two lists or tuples are equal.  If not an error
          message is constructed that shows only the differences
          between the two.  An error is also raised if either of the
          parameters are of the wrong type.  These methods are used by
          default when comparing lists or tuples with *note
          assertEqual(): 279.

          New in version 2.7.

      -- Method: assertSetEqual (set1, set2, msg=None)
          Tests that two sets are equal.  If not, an error message is
          constructed that lists the differences between the sets.
          This method is used by default when comparing sets or
          frozensets with *note assertEqual(): 279.

          Fails if either of _set1_ or _set2_ does not have a *note
          set.difference(): 8b2.  method.

          New in version 2.7.

      -- Method: assertDictEqual (expected, actual, msg=None)
          Test that two dictionaries are equal.  If not, an error
          message is constructed that shows the differences in the
          dictionaries. This method will be used by default to compare
          dictionaries in calls to *note assertEqual(): 279.

          New in version 2.7.

     Finally the *note TestCase: 27d. provides the following methods
     and attributes:

      -- Method: fail (msg=None)
          Signals a test failure unconditionally, with _msg_ or `None'
          for the error message.

      -- Attribute: failureException
          This class attribute gives the exception raised by the test
          method.  If a test framework needs to use a specialized
          exception, possibly to carry additional information, it must
          subclass this exception in order to "play fair" with the
          framework.  The initial value of this attribute is *note
          AssertionError: 7dd.

      -- Attribute: longMessage
          If set to `True' then any explicit failure message you pass
          in to the *note assert methods: 21be. will be appended to the
          end of the normal failure message.  The normal messages
          contain useful information about the objects involved, for
          example the message from assertEqual shows you the repr of
          the two unequal objects. Setting this attribute to `True'
          allows you to have a custom error message in addition to the
          normal one.

          This attribute defaults to `False', meaning that a custom
          message passed to an assert method will silence the normal
          message.

          The class setting can be overridden in individual tests by
          assigning an instance attribute to `True' or `False' before
          calling the assert methods.

          New in version 2.7.

      -- Attribute: maxDiff
          This attribute controls the maximum length of diffs output by
          assert methods that report diffs on failure. It defaults to
          80*8 characters.  Assert methods affected by this attribute
          are *note assertSequenceEqual(): 299. (including all the
          sequence comparison methods that delegate to it), *note
          assertDictEqual(): 29a. and *note assertMultiLineEqual(): 28f.

          Setting `maxDiff' to None means that there is no maximum
          length of diffs.

          New in version 2.7.

     Testing frameworks can use the following methods to collect
     information on the test:

      -- Method: countTestCases ()
          Return the number of tests represented by this test object.
          For *note TestCase: 27d. instances, this will always be `1'.

      -- Method: defaultTestResult ()
          Return an instance of the test result class that should be
          used for this test case class (if no other result instance is
          provided to the *note run(): 21e1. method).

          For *note TestCase: 27d. instances, this will always be an
          instance of *note TestResult: 2a3.; subclasses of *note
          TestCase: 27d. should override this as necessary.

      -- Method: id ()
          Return a string identifying the specific test case.  This is
          usually the full name of the test method, including the
          module and class name.

      -- Method: shortDescription ()
          Returns a description of the test, or `None' if no description
          has been provided.  The default implementation of this method
          returns the first line of the test method's docstring, if
          available, or *note None: 389.

      -- Method: addCleanup (function, *args, **kwargs)
          Add a function to be called after *note tearDown(): 284. to
          cleanup resources used during the test. Functions will be
          called in reverse order to the order they are added (LIFO).
          They are called with any arguments and keyword arguments
          passed into *note addCleanup(): 281. when they are added.

          If *note setUp(): 283. fails, meaning that *note tearDown():
          284. is not called, then any cleanup functions added will
          still be called.

          New in version 2.7.

      -- Method: doCleanups ()
          This method is called unconditionally after *note tearDown():
          284, or after *note setUp(): 283. if *note setUp(): 283.
          raises an exception.

          It is responsible for calling all the cleanup functions added
          by *note addCleanup(): 281. If you need cleanup functions to
          be called _prior_ to *note tearDown(): 284. then you can call
          *note doCleanups(): 282.  yourself.

          *note doCleanups(): 282. pops methods off the stack of cleanup
          functions one at a time, so it can be called at any time.

          New in version 2.7.

 -- Class: unittest.FunctionTestCase (testFunc, setUp=None,
          tearDown=None, description=None)
     This class implements the portion of the *note TestCase: 27d.
     interface which allows the test runner to drive the test, but does
     not provide the methods which test code can use to check and
     report errors.  This is used to create test cases using legacy
     test code, allowing it to be integrated into a *note unittest:
     188.-based test framework.

* Menu:

* Deprecated aliases::


File: python.info,  Node: Deprecated aliases,  Up: Test cases

5.25.3.10 Deprecated aliases
............................

For historical reasons, some of the *note TestCase: 27d. methods had
one or more aliases that are now deprecated.  The following table lists
the correct names along with their deprecated aliases:

      Method Name                        Deprecated alias(es)
     ----------------------------------------------------------------------- 
     *note assertEqual(): 279.          failUnlessEqual, assertEquals
     *note assertNotEqual(): 21e5.      failIfEqual
     *note assertTrue(): 27a.           failUnless, assert_
     *note assertFalse(): 27b.          failIf
     *note assertRaises(): 27e.         failUnlessRaises
     *note assertAlmostEqual(): 29c.    failUnlessAlmostEqual
     *note assertNotAlmostEqual(): 29d. failIfAlmostEqual

     Deprecated since version 2.7: the aliases listed in the second
     column


File: python.info,  Node: Grouping tests,  Next: Loading and running tests,  Prev: Test cases,  Up: Classes and functions

5.25.3.11 Grouping tests
........................

 -- Class: unittest.TestSuite (tests=())
     This class represents an aggregation of individual tests cases and
     test suites.  The class presents the interface needed by the test
     runner to allow it to be run as any other test case.  Running a
     *note TestSuite: 44c. instance is the same as iterating over the
     suite, running each test individually.

     If _tests_ is given, it must be an iterable of individual test
     cases or other test suites that will be used to build the suite
     initially. Additional methods are provided to add test cases and
     suites to the collection later on.

     *note TestSuite: 44c. objects behave much like *note TestCase:
     27d. objects, except they do not actually implement a test.
     Instead, they are used to aggregate tests into groups of tests
     that should be run together. Some additional methods are available
     to add tests to *note TestSuite: 44c. instances:

      -- Method: addTest (test)
          Add a *note TestCase: 27d. or *note TestSuite: 44c. to the
          suite.

      -- Method: addTests (tests)
          Add all the tests from an iterable of *note TestCase: 27d.
          and *note TestSuite: 44c.  instances to this test suite.

          This is equivalent to iterating over _tests_, calling *note
          addTest(): 21f1. for each element.

     *note TestSuite: 44c. shares the following methods with *note
     TestCase: 27d.:

      -- Method: run (result)
          Run the tests associated with this suite, collecting the
          result into the test result object passed as _result_.  Note
          that unlike *note TestCase.run(): 21e1, *note
          TestSuite.run(): 21f3. requires the result object to be
          passed in.

      -- Method: debug ()
          Run the tests associated with this suite without collecting
          the result. This allows exceptions raised by the test to be
          propagated to the caller and can be used to support running
          tests under a debugger.

      -- Method: countTestCases ()
          Return the number of tests represented by this test object,
          including all individual tests and sub-suites.

      -- Method: __iter__ ()
          Tests grouped by a *note TestSuite: 44c. are always accessed
          by iteration.  Subclasses can lazily provide tests by
          overriding *note __iter__(): 21f6. Note that this method
          maybe called several times on a single suite (for example
          when counting tests or comparing for equality) so the tests
          returned must be the same for repeated iterations.

          Changed in version 2.7: In earlier versions the *note
          TestSuite: 44c. accessed tests directly rather than through
          iteration, so overriding *note __iter__(): 21f6. wasn't
          sufficient for providing tests.

     In the typical usage of a *note TestSuite: 44c. object, the *note
     run(): 21f3. method is invoked by a `TestRunner' rather than by
     the end-user test harness.


File: python.info,  Node: Loading and running tests,  Prev: Grouping tests,  Up: Classes and functions

5.25.3.12 Loading and running tests
...................................

 -- Class: unittest.TestLoader
     The *note TestLoader: 2a0. class is used to create test suites
     from classes and modules.  Normally, there is no need to create an
     instance of this class; the *note unittest: 188. module provides
     an instance that can be shared as `unittest.defaultTestLoader'.
     Using a subclass or instance, however, allows customization of
     some configurable properties.

     *note TestLoader: 2a0. objects have the following methods:

      -- Method: loadTestsFromTestCase (testCaseClass)
          Return a suite of all tests cases contained in the *note
          TestCase: 27d.-derived `testCaseClass'.

      -- Method: loadTestsFromModule (module)
          Return a suite of all tests cases contained in the given
          module. This method searches _module_ for classes derived
          from *note TestCase: 27d. and creates an instance of the
          class for each test method defined for the class.

               Note: While using a hierarchy of *note TestCase:
               27d.-derived classes can be convenient in sharing
               fixtures and helper functions, defining test methods on
               base classes that are not intended to be instantiated
               directly does not play well with this method.  Doing so,
               however, can be useful when the fixtures are different
               and defined in subclasses.

          If a module provides a `load_tests' function it will be
          called to load the tests. This allows modules to customize
          test loading.  This is the *note load_tests protocol: 21d1.

          Changed in version 2.7: Support for `load_tests' added.

      -- Method: loadTestsFromName (name, module=None)
          Return a suite of all tests cases given a string specifier.

          The specifier _name_ is a "dotted name" that may resolve
          either to a module, a test case class, a test method within a
          test case class, a *note TestSuite: 44c. instance, or a
          callable object which returns a *note TestCase: 27d. or *note
          TestSuite: 44c. instance.  These checks are applied in the
          order listed here; that is, a method on a possible test case
          class will be picked up as "a test method within a test case
          class", rather than "a callable object".

          For example, if you have a module `SampleTests' containing a
          *note TestCase: 27d.-derived class `SampleTestCase' with
          three test methods (`test_one()', `test_two()', and
          `test_three()'), the specifier `'SampleTests.SampleTestCase''
          would cause this method to return a suite which will run all
          three test methods. Using the specifier
          `'SampleTests.SampleTestCase.test_two'' would cause it to
          return a test suite which will run only the `test_two()' test
          method. The specifier can refer to modules and packages which
          have not been imported; they will be imported as a
          side-effect.

          The method optionally resolves _name_ relative to the given
          _module_.

      -- Method: loadTestsFromNames (names, module=None)
          Similar to *note loadTestsFromName(): 29e, but takes a
          sequence of names rather than a single name.  The return
          value is a test suite which supports all the tests defined
          for each name.

      -- Method: getTestCaseNames (testCaseClass)
          Return a sorted sequence of method names found within
          _testCaseClass_; this should be a subclass of *note TestCase:
          27d.

      -- Method: discover (start_dir, pattern='test*.py',
               top_level_dir=None)
          Find and return all test modules from the specified start
          directory, recursing into subdirectories to find them. Only
          test files that match _pattern_ will be loaded. (Using shell
          style pattern matching.) Only module names that are
          importable (i.e. are valid Python identifiers) will be loaded.

          All test modules must be importable from the top level of the
          project. If the start directory is not the top level
          directory then the top level directory must be specified
          separately.

          If importing a module fails, for example due to a syntax
          error, then this will be recorded as a single error and
          discovery will continue.

          If a test package name (directory with `__init__.py') matches
          the pattern then the package will be checked for a
          `load_tests' function. If this exists then it will be called
          with _loader_, _tests_, _pattern_.

          If load_tests exists then discovery does _not_ recurse into
          the package, `load_tests' is responsible for loading all
          tests in the package.

          The pattern is deliberately not stored as a loader attribute
          so that packages can continue discovery themselves.
          _top_level_dir_ is stored so `load_tests' does not need to
          pass this argument in to `loader.discover()'.

          _start_dir_ can be a dotted module name as well as a
          directory.

          New in version 2.7.

     The following attributes of a *note TestLoader: 2a0. can be
     configured either by subclassing or assignment on an instance:

      -- Attribute: testMethodPrefix
          String giving the prefix of method names which will be
          interpreted as test methods.  The default value is `'test''.

          This affects *note getTestCaseNames(): 21fb. and all the
          `loadTestsFrom*()' methods.

      -- Attribute: sortTestMethodsUsing
          Function to be used to compare method names when sorting them
          in *note getTestCaseNames(): 21fb. and all the
          `loadTestsFrom*()' methods. The default value is the built-in
          *note cmp(): 4ab. function; the attribute can also be set to
          *note None: 389. to disable the sort.

      -- Attribute: suiteClass
          Callable object that constructs a test suite from a list of
          tests. No methods on the resulting object are needed.  The
          default value is the *note TestSuite: 44c. class.

          This affects all the `loadTestsFrom*()' methods.

 -- Class: unittest.TestResult
     This class is used to compile information about which tests have
     succeeded and which have failed.

     A *note TestResult: 2a3. object stores the results of a set of
     tests.  The *note TestCase: 27d. and *note TestSuite: 44c. classes
     ensure that results are properly recorded; test authors do not
     need to worry about recording the outcome of tests.

     Testing frameworks built on top of *note unittest: 188. may want
     access to the *note TestResult: 2a3. object generated by running a
     set of tests for reporting purposes; a *note TestResult: 2a3.
     instance is returned by the `TestRunner.run()' method for this
     purpose.

     *note TestResult: 2a3. instances have the following attributes
     that will be of interest when inspecting the results of running a
     set of tests:

      -- Attribute: errors
          A list containing 2-tuples of *note TestCase: 27d. instances
          and strings holding formatted tracebacks. Each tuple
          represents a test which raised an unexpected exception.

          Changed in version 2.2: Contains formatted tracebacks instead
          of *note sys.exc_info(): 2e4. results.

      -- Attribute: failures
          A list containing 2-tuples of *note TestCase: 27d. instances
          and strings holding formatted tracebacks. Each tuple
          represents a test where a failure was explicitly signalled
          using the `TestCase.fail*()' or `TestCase.assert*()' methods.

          Changed in version 2.2: Contains formatted tracebacks instead
          of *note sys.exc_info(): 2e4. results.

      -- Attribute: skipped
          A list containing 2-tuples of *note TestCase: 27d. instances
          and strings holding the reason for skipping the test.

          New in version 2.7.

      -- Attribute: expectedFailures
          A list containing 2-tuples of *note TestCase: 27d. instances
          and strings holding formatted tracebacks.  Each tuple
          represents an expected failure of the test case.

      -- Attribute: unexpectedSuccesses
          A list containing *note TestCase: 27d. instances that were
          marked as expected failures, but succeeded.

      -- Attribute: shouldStop
          Set to `True' when the execution of tests should stop by
          *note stop(): 2204.

      -- Attribute: testsRun
          The total number of tests run so far.

      -- Attribute: buffer
          If set to true, `sys.stdout' and `sys.stderr' will be
          buffered in between *note startTest(): 2207. and *note
          stopTest(): 2208. being called. Collected output will only be
          echoed onto the real `sys.stdout' and `sys.stderr' if the test
          fails or errors. Any output is also attached to the failure /
          error message.

          New in version 2.7.

      -- Attribute: failfast
          If set to true *note stop(): 2204. will be called on the
          first failure or error, halting the test run.

          New in version 2.7.

      -- Method: wasSuccessful ()
          Return `True' if all tests run so far have passed, otherwise
          returns `False'.

      -- Method: stop ()
          This method can be called to signal that the set of tests
          being run should be aborted by setting the *note shouldStop:
          2203. attribute to `True'.  `TestRunner' objects should
          respect this flag and return without running any additional
          tests.

          For example, this feature is used by the *note
          TextTestRunner: 21c0. class to stop the test framework when
          the user signals an interrupt from the keyboard.  Interactive
          tools which provide `TestRunner' implementations can use this
          in a similar manner.

     The following methods of the *note TestResult: 2a3. class are used
     to maintain the internal data structures, and may be extended in
     subclasses to support additional reporting requirements.  This is
     particularly useful in building tools which support interactive
     reporting while tests are being run.

      -- Method: startTest (test)
          Called when the test case _test_ is about to be run.

      -- Method: stopTest (test)
          Called after the test case _test_ has been executed,
          regardless of the outcome.

      -- Method: startTestRun (test)
          Called once before any tests are executed.

          New in version 2.7.

      -- Method: stopTestRun (test)
          Called once after all tests are executed.

          New in version 2.7.

      -- Method: addError (test, err)
          Called when the test case _test_ raises an unexpected
          exception _err_ is a tuple of the form returned by *note
          sys.exc_info(): 2e4.: `(type, value, traceback)'.

          The default implementation appends a tuple `(test,
          formatted_err)' to the instance's *note errors: 21fe.
          attribute, where _formatted_err_ is a formatted traceback
          derived from _err_.

      -- Method: addFailure (test, err)
          Called when the test case _test_ signals a failure. _err_ is
          a tuple of the form returned by *note sys.exc_info(): 2e4.:
          `(type, value, traceback)'.

          The default implementation appends a tuple `(test,
          formatted_err)' to the instance's *note failures: 21ff.
          attribute, where _formatted_err_ is a formatted traceback
          derived from _err_.

      -- Method: addSuccess (test)
          Called when the test case _test_ succeeds.

          The default implementation does nothing.

      -- Method: addSkip (test, reason)
          Called when the test case _test_ is skipped.  _reason_ is the
          reason the test gave for skipping.

          The default implementation appends a tuple `(test, reason)'
          to the instance's *note skipped: 2200. attribute.

      -- Method: addExpectedFailure (test, err)
          Called when the test case _test_ fails, but was marked with
          the *note expectedFailure(): 21d9. decorator.

          The default implementation appends a tuple `(test,
          formatted_err)' to the instance's *note expectedFailures:
          2201. attribute, where _formatted_err_ is a formatted
          traceback derived from _err_.

      -- Method: addUnexpectedSuccess (test)
          Called when the test case _test_ was marked with the *note
          expectedFailure(): 21d9. decorator, but succeeded.

          The default implementation appends the test to the instance's
          *note unexpectedSuccesses: 2202. attribute.

 -- Class: unittest.TextTestResult (stream, descriptions, verbosity)
     A concrete implementation of *note TestResult: 2a3. used by the
     *note TextTestRunner: 21c0.

     New in version 2.7: This class was previously named
     `_TextTestResult'. The old name still exists as an alias but is
     deprecated.

 -- Data: unittest.defaultTestLoader
     Instance of the *note TestLoader: 2a0. class intended to be
     shared.  If no customization of the *note TestLoader: 2a0. is
     needed, this instance can be used instead of repeatedly creating
     new instances.

 -- Class: unittest.TextTestRunner (stream=sys.stderr,
          descriptions=True, verbosity=1)
     A basic test runner implementation which prints results on
     standard error.  It has a few configurable parameters, but is
     essentially very simple.  Graphical applications which run test
     suites should provide alternate implementations.

      -- Method: _makeResult ()
          This method returns the instance of `TestResult' used by
          `run()'.  It is not intended to be called directly, but can
          be overridden in subclasses to provide a custom `TestResult'.

          `_makeResult()' instantiates the class or callable passed in
          the `TextTestRunner' constructor as the `resultclass'
          argument. It defaults to *note TextTestResult: 2211. if no
          `resultclass' is provided.  The result class is instantiated
          with the following arguments:

              stream, descriptions, verbosity



 -- Function: unittest.main ([module[, defaultTest[, argv[,
          testRunner[, testLoader[, exit[, verbosity[, failfast[,
          catchbreak[, buffer]]]]]]]]]])
     A command-line program that runs a set of tests; this is primarily
     for making test modules conveniently executable.  The simplest use
     for this function is to include the following line at the end of a
     test script:

         if __name__ == '__main__':
             unittest.main()

     You can run tests with more detailed information by passing in the
     verbosity argument:

         if __name__ == '__main__':
             unittest.main(verbosity=2)

     The _testRunner_ argument can either be a test runner class or an
     already created instance of it. By default `main' calls *note
     sys.exit(): 2a2. with an exit code indicating success or failure
     of the tests run.

     `main' supports being used from the interactive interpreter by
     passing in the argument `exit=False'. This displays the result on
     standard output without calling *note sys.exit(): 2a2.:

         >>> from unittest import main
         >>> main(module='test_module', exit=False)

     The `failfast', `catchbreak' and `buffer' parameters have the same
     effect as the same-name *note command-line options: 21c5.

     Calling `main' actually returns an instance of the `TestProgram'
     class.  This stores the result of the tests run as the `result'
     attribute.

     Changed in version 2.7: The `exit', `verbosity', `failfast',
     `catchbreak' and `buffer' parameters were added.

* Menu:

* load_tests Protocol::


File: python.info,  Node: load_tests Protocol,  Up: Loading and running tests

5.25.3.13 load_tests Protocol
.............................

New in version 2.7.

  Modules or packages can customize how tests are loaded from them
during normal test runs or test discovery by implementing a function
called `load_tests'.

  If a test module defines `load_tests' it will be called by *note
TestLoader.loadTestsFromModule(): 21f9. with the following arguments:

    load_tests(loader, standard_tests, None)

It should return a *note TestSuite: 44c.

  _loader_ is the instance of *note TestLoader: 2a0. doing the loading.
_standard_tests_ are the tests that would be loaded by default from the
module. It is common for test modules to only want to add or remove
tests from the standard set of tests.  The third argument is used when
loading packages as part of test discovery.

  A typical `load_tests' function that loads tests from a specific set
of *note TestCase: 27d. classes may look like:

    test_cases = (TestCase1, TestCase2, TestCase3)

    def load_tests(loader, tests, pattern):
        suite = TestSuite()
        for test_class in test_cases:
            tests = loader.loadTestsFromTestCase(test_class)
            suite.addTests(tests)
        return suite

If discovery is started, either from the command line or by calling
*note TestLoader.discover(): 21cc, with a pattern that matches a package
name then the package `__init__.py' will be checked for `load_tests'.

     Note: The default pattern is 'test*.py'. This matches all Python
     files that start with 'test' but _won't_ match any test
     directories.

     A pattern like 'test*' will match test packages as well as modules.

  If the package `__init__.py' defines `load_tests' then it will be
called and discovery not continued into the package. `load_tests' is
called with the following arguments:

    load_tests(loader, standard_tests, pattern)

This should return a *note TestSuite: 44c. representing all the tests
from the package. (`standard_tests' will only contain tests collected
from `__init__.py'.)

  Because the pattern is passed into `load_tests' the package is free to
continue (and potentially modify) test discovery. A 'do nothing'
`load_tests' function for a test package would look like:

    def load_tests(loader, standard_tests, pattern):
        # top level directory cached on loader instance
        this_dir = os.path.dirname(__file__)
        package_tests = loader.discover(start_dir=this_dir, pattern=pattern)
        standard_tests.addTests(package_tests)
        return standard_tests



File: python.info,  Node: Class and Module Fixtures,  Next: Signal Handling,  Prev: Classes and functions,  Up: unittest --- Unit testing framework

5.25.3.14 Class and Module Fixtures
...................................

Class and module level fixtures are implemented in *note TestSuite:
44c. When the test suite encounters a test from a new class then
`tearDownClass()' from the previous class (if there is one) is called,
followed by `setUpClass()' from the new class.

  Similarly if a test is from a different module from the previous test
then `tearDownModule' from the previous module is run, followed by
`setUpModule' from the new module.

  After all the tests have run the final `tearDownClass' and
`tearDownModule' are run.

  Note that shared fixtures do not play well with [potential] features
like test parallelization and they break test isolation. They should be
used with care.

  The default ordering of tests created by the unittest test loaders is
to group all tests from the same modules and classes together. This
will lead to `setUpClass' / `setUpModule' (etc) being called exactly
once per class and module. If you randomize the order, so that tests
from different modules and classes are adjacent to each other, then
these shared fixture functions may be called multiple times in a single
test run.

  Shared fixtures are not intended to work with suites with non-standard
ordering. A `BaseTestSuite' still exists for frameworks that don't want
to support shared fixtures.

  If there are any exceptions raised during one of the shared fixture
functions the test is reported as an error. Because there is no
corresponding test instance an `_ErrorHolder' object (that has the same
interface as a *note TestCase: 27d.) is created to represent the error.
If you are just using the standard unittest test runner then this
detail doesn't matter, but if you are a framework author it may be
relevant.

* Menu:

* setUpClass and tearDownClass::
* setUpModule and tearDownModule::


File: python.info,  Node: setUpClass and tearDownClass,  Next: setUpModule and tearDownModule,  Up: Class and Module Fixtures

5.25.3.15 setUpClass and tearDownClass
......................................

These must be implemented as class methods:

    import unittest

    class Test(unittest.TestCase):
        @classmethod
        def setUpClass(cls):
            cls._connection = createExpensiveConnectionObject()

        @classmethod
        def tearDownClass(cls):
            cls._connection.destroy()

If you want the `setUpClass' and `tearDownClass' on base classes called
then you must call up to them yourself. The implementations in *note
TestCase: 27d. are empty.

  If an exception is raised during a `setUpClass' then the tests in the
class are not run and the `tearDownClass' is not run. Skipped classes
will not have `setUpClass' or `tearDownClass' run. If the exception is a
`SkipTest' exception then the class will be reported as having been
skipped instead of as an error.


File: python.info,  Node: setUpModule and tearDownModule,  Prev: setUpClass and tearDownClass,  Up: Class and Module Fixtures

5.25.3.16 setUpModule and tearDownModule
........................................

These should be implemented as functions:

    def setUpModule():
        createConnection()

    def tearDownModule():
        closeConnection()

If an exception is raised in a `setUpModule' then none of the tests in
the module will be run and the `tearDownModule' will not be run. If the
exception is a `SkipTest' exception then the module will be reported as
having been skipped instead of as an error.


File: python.info,  Node: Signal Handling,  Prev: Class and Module Fixtures,  Up: unittest --- Unit testing framework

5.25.3.17 Signal Handling
.........................

The *note -c/-catch: 21c7. command-line option to unittest, along with
the `catchbreak' parameter to *note unittest.main(): 276, provide more
friendly handling of control-C during a test run. With catch break
behavior enabled control-C will allow the currently running test to
complete, and the test run will then end and report all the results so
far. A second control-c will raise a *note KeyboardInterrupt: 24e. in
the usual way.

  The control-c handling signal handler attempts to remain compatible
with code or tests that install their own `signal.SIGINT' handler. If
the `unittest' handler is called but _isn't_ the installed
`signal.SIGINT' handler, i.e. it has been replaced by the system under
test and delegated to, then it calls the default handler. This will
normally be the expected behavior by code that replaces an installed
handler and delegates to it. For individual tests that need `unittest'
control-c handling disabled the *note removeHandler(): 278.  decorator
can be used.

  There are a few utility functions for framework authors to enable
control-c handling functionality within test frameworks.

 -- Function: unittest.installHandler ()
     Install the control-c handler. When a `signal.SIGINT' is received
     (usually in response to the user pressing control-c) all
     registered results have *note stop(): 2204. called.

     New in version 2.7.

 -- Function: unittest.registerResult (result)
     Register a *note TestResult: 2a3. object for control-c handling.
     Registering a result stores a weak reference to it, so it doesn't
     prevent the result from being garbage collected.

     Registering a *note TestResult: 2a3. object has no side-effects if
     control-c handling is not enabled, so test frameworks can
     unconditionally register all results they create independently of
     whether or not handling is enabled.

     New in version 2.7.

 -- Function: unittest.removeResult (result)
     Remove a registered result. Once a result has been removed then
     *note stop(): 2204. will no longer be called on that result object
     in response to a control-c.

     New in version 2.7.

 -- Function: unittest.removeHandler (function=None)
     When called without arguments this function removes the control-c
     handler if it has been installed. This function can also be used
     as a test decorator to temporarily remove the handler whilst the
     test is being executed:

         @unittest.removeHandler
         def test_signal_handling(self):
             ...

     New in version 2.7.


File: python.info,  Node: 2to3 - Automated Python 2 to 3 code translation,  Next: test --- Regression tests package for Python,  Prev: unittest --- Unit testing framework,  Up: Development Tools

5.25.4 2to3 - Automated Python 2 to 3 code translation
------------------------------------------------------

2to3 is a Python program that reads Python 2.x source code and applies
a series of _fixers_ to transform it into valid Python 3.x code.  The
standard library contains a rich set of fixers that will handle almost
all code.  2to3 supporting library *note lib2to3: ff. is, however, a
flexible and generic library, so it is possible to write your own
fixers for 2to3.  *note lib2to3: ff. could also be adapted to custom
applications in which Python code needs to be edited automatically.

* Menu:

* Using 2to3::
* Fixers::
* lib2to3 - 2to3's library::


File: python.info,  Node: Using 2to3,  Next: Fixers,  Up: 2to3 - Automated Python 2 to 3 code translation

5.25.4.1 Using 2to3
...................

2to3 will usually be installed with the Python interpreter as a script.
It is also located in the `Tools/scripts' directory of the Python root.

  2to3's basic arguments are a list of files or directories to
transform.  The directories are to recursively traversed for Python
sources.

  Here is a sample Python 2.x source file, `example.py':

    def greet(name):
        print "Hello, {0}!".format(name)
    print "What's your name?"
    name = raw_input()
    greet(name)

It can be converted to Python 3.x code via 2to3 on the command line:

    $ 2to3 example.py

A diff against the original source file is printed.  2to3 can also
write the needed modifications right back to the source file.  (A
backup of the original file is made unless `-n' is also given.)
Writing the changes back is enabled with the `-w' flag:

    $ 2to3 -w example.py

After transformation, `example.py' looks like this:

    def greet(name):
        print("Hello, {0}!".format(name))
    print("What's your name?")
    name = input()
    greet(name)

Comments and exact indentation are preserved throughout the translation
process.

  By default, 2to3 runs a set of *note predefined fixers: 221d.  The
`-l' flag lists all available fixers.  An explicit set of fixers to run
can be given with `-f'.  Likewise the *note -x: 621. explicitly
disables a fixer.  The following example runs only the `imports' and
`has_key' fixers:

    $ 2to3 -f imports -f has_key example.py

This command runs every fixer except the `apply' fixer:

    $ 2to3 -x apply example.py

Some fixers are _explicit_, meaning they aren't run by default and must
be listed on the command line to be run.  Here, in addition to the
default fixers, the `idioms' fixer is run:

    $ 2to3 -f all -f idioms example.py

Notice how passing `all' enables all default fixers.

  Sometimes 2to3 will find a place in your source code that needs to be
changed, but 2to3 cannot fix automatically.  In this case, 2to3 will
print a warning beneath the diff for a file.  You should address the
warning in order to have compliant 3.x code.

  2to3 can also refactor doctests.  To enable this mode, use the *note
-d: 615.  flag.  Note that _only_ doctests will be refactored.  This
also doesn't require the module to be valid Python.  For example,
doctest like examples in a reST document could also be refactored with
this option.

  The *note -v: 3a2. option enables output of more information on the
translation process.

  Since some print statements can be parsed as function calls or
statements, 2to3 cannot always read files containing the print
function.  When 2to3 detects the presence of the `from __future__
import print_function' compiler directive, it modifies its internal
grammar to interpret *note print(): 2fc. as a function.  This change
can also be enabled manually with the `-p' flag.  Use `-p' to run
fixers on code that already has had its print statements converted.


File: python.info,  Node: Fixers,  Next: lib2to3 - 2to3's library,  Prev: Using 2to3,  Up: 2to3 - Automated Python 2 to 3 code translation

5.25.4.2 Fixers
...............

Each step of transforming code is encapsulated in a fixer.  The command
`2to3 -l' lists them.  As *note documented above: 221b, each can be
turned on and off individually.  They are described here in more detail.

 -- 2to3fixer: apply
     Removes usage of *note apply(): 2f4.  For example `apply(function,
     *args, **kwargs)' is converted to `function(*args, **kwargs)'.

 -- 2to3fixer: basestring
     Converts *note basestring: 447. to *note str: 1e7.

 -- 2to3fixer: buffer
     Converts *note buffer: 306. to *note memoryview: 1c0.  This fixer
     is optional because the *note memoryview: 1c0. API is similar but
     not exactly the same as that of *note buffer: 306.

 -- 2to3fixer: callable
     Converts `callable(x)' to `isinstance(x, collections.Callable)',
     adding an import to *note collections: 65. if needed.

 -- 2to3fixer: dict
     Fixes dictionary iteration methods.  *note dict.iteritems(): 8c6.
     is converted to *note dict.items(): 1e0, *note dict.iterkeys():
     8c1. to *note dict.keys(): 1de, and *note dict.itervalues(): 8c7.
     to *note dict.values(): 1df.  Similarly, *note dict.viewitems():
     1e3, *note dict.viewkeys(): 1e1. and *note dict.viewvalues(): 1e2.
     are converted respectively to *note dict.items(): 1e0, *note
     dict.keys(): 1de. and *note dict.values(): 1df.  It also wraps
     existing usages of *note dict.items(): 1e0, *note dict.keys():
     1de, and *note dict.values(): 1df. in a call to *note list: 3ab.

 -- 2to3fixer: except
     Converts `except X, T' to `except X as T'.

 -- 2to3fixer: exec
     Converts the *note exec: 3f3. statement to the `exec()' function.

 -- 2to3fixer: execfile
     Removes usage of *note execfile(): 425.  The argument to *note
     execfile(): 425. is wrapped in calls to *note open(): 2cb, *note
     compile(): 1f8, and `exec()'.

 -- 2to3fixer: exitfunc
     Changes assignment of *note sys.exitfunc: 3fd. to use of the *note
     atexit: 12.  module.

 -- 2to3fixer: filter
     Wraps *note filter(): 3f8. usage in a *note list: 3ab. call.

 -- 2to3fixer: funcattrs
     Fixes function attributes that have been renamed.  For example,
     `my_function.func_closure' is converted to
     `my_function.__closure__'.

 -- 2to3fixer: future
     Removes `from __future__ import new_feature' statements.

 -- 2to3fixer: getcwdu
     Renames *note os.getcwdu(): 421. to *note os.getcwd(): 10e9.

 -- 2to3fixer: has_key
     Changes `dict.has_key(key)' to `key in dict'.

 -- 2to3fixer: idioms
     This optional fixer performs several transformations that make
     Python code more idiomatic.  Type comparisons like `type(x) is
     SomeClass' and `type(x) == SomeClass' are converted to
     `isinstance(x, SomeClass)'.  `while 1' becomes `while True'.  This
     fixer also tries to make use of *note sorted(): 220. in
     appropriate places.  For example, this block

         L = list(some_iterable)
         L.sort()

     is changed to

         L = sorted(some_iterable)



 -- 2to3fixer: import
     Detects sibling imports and converts them to relative imports.

 -- 2to3fixer: imports
     Handles module renames in the standard library.

 -- 2to3fixer: imports2
     Handles other modules renames in the standard library.  It is
     separate from the *note imports: 222f. fixer only because of
     technical limitations.

 -- 2to3fixer: input
     Converts `input(prompt)' to `eval(input(prompt))'

 -- 2to3fixer: intern
     Converts *note intern(): 847. to `sys.intern()'.

 -- 2to3fixer: isinstance
     Fixes duplicate types in the second argument of *note
     isinstance(): 30e.  For example, `isinstance(x, (int, int))' is
     converted to `isinstance(x, (int))'.

 -- 2to3fixer: itertools_imports
     Removes imports of *note itertools.ifilter(): 84c, *note
     itertools.izip(): 3f5, and *note itertools.imap(): d1f.  Imports
     of *note itertools.ifilterfalse(): 84d. are also changed to
     `itertools.filterfalse()'.

 -- 2to3fixer: itertools
     Changes usage of *note itertools.ifilter(): 84c, *note
     itertools.izip(): 3f5, and *note itertools.imap(): d1f. to their
     built-in equivalents.  *note itertools.ifilterfalse(): 84d. is
     changed to `itertools.filterfalse()'.

 -- 2to3fixer: long
     Strips the `L' prefix on long literals and renames *note long:
     1f0. to *note int: 1ef.

 -- 2to3fixer: map
     Wraps *note map(): 2f5. in a *note list: 3ab. call.  It also
     changes `map(None, x)' to `list(x)'.  Using `from future_builtins
     import map' disables this fixer.

 -- 2to3fixer: metaclass
     Converts the old metaclass syntax (`__metaclass__ = Meta' in the
     class body) to the new (`class X(metaclass=Meta)').

 -- 2to3fixer: methodattrs
     Fixes old method attribute names.  For example, `meth.im_func' is
     converted to `meth.__func__'.

 -- 2to3fixer: ne
     Converts the old not-equal syntax, `<>', to `!='.

 -- 2to3fixer: next
     Converts the use of iterator's *note next(): 851. methods to the
     *note next(): 388. function.  It also renames *note next(): 388.
     methods to `__next__()'.

 -- 2to3fixer: nonzero
     Renames *note __nonzero__(): 6e3. to `__bool__()'.

 -- 2to3fixer: numliterals
     Converts octal literals into the new syntax.

 -- 2to3fixer: paren
     Add extra parenthesis where they are required in list
     comprehensions.  For example, `[x for x in 1, 2]' becomes `[x for
     x in (1, 2)]'.

 -- 2to3fixer: print
     Converts the *note print: 4cd. statement to the *note print():
     2fc. function.

 -- 2to3fixer: raise
     Converts `raise E, V' to `raise E(V)', and `raise E, V, T' to
     `raise E(V).with_traceback(T)'.  If `E' is a tuple, the
     translation will be incorrect because substituting tuples for
     exceptions has been removed in 3.0.

 -- 2to3fixer: raw_input
     Converts *note raw_input(): 83a. to *note input(): 3ae.

 -- 2to3fixer: reduce
     Handles the move of *note reduce(): 2d9. to *note
     functools.reduce(): 2d8.

 -- 2to3fixer: renames
     Changes *note sys.maxint: 2244. to *note sys.maxsize: 7a6.

 -- 2to3fixer: repr
     Replaces backtick repr with the *note repr(): 146. function.

 -- 2to3fixer: set_literal
     Replaces use of the *note set: 359. constructor with set literals.
     This fixer is optional.

 -- 2to3fixer: standard_error
     Renames *note StandardError: 371. to *note Exception: 328.

 -- 2to3fixer: sys_exc
     Changes the deprecated *note sys.exc_value: 2249, *note
     sys.exc_type: 224a, *note sys.exc_traceback: 224b. to use *note
     sys.exc_info(): 2e4.

 -- 2to3fixer: throw
     Fixes the API change in generator's `throw()' method.

 -- 2to3fixer: tuple_params
     Removes implicit tuple parameter unpacking.  This fixer inserts
     temporary variables.

 -- 2to3fixer: types
     Fixes code broken from the removal of some members in the *note
     types: 186.  module.

 -- 2to3fixer: unicode
     Renames *note unicode: 1f2. to *note str: 1e7.

 -- 2to3fixer: urllib
     Handles the rename of *note urllib: 189. and *note urllib2: 18a.
     to the *note urllib: 189.  package.

 -- 2to3fixer: ws_comma
     Removes excess whitespace from comma separated items.  This fixer
     is optional.

 -- 2to3fixer: xrange
     Renames *note xrange(): 44a. to *note range(): 2cd. and wraps
     existing *note range(): 2cd.  calls with *note list: 3ab.

 -- 2to3fixer: xreadlines
     Changes `for x in file.xreadlines()' to `for x in file'.

 -- 2to3fixer: zip
     Wraps *note zip(): 3f4. usage in a *note list: 3ab. call.  This is
     disabled when `from future_builtins import zip' appears.


File: python.info,  Node: lib2to3 - 2to3's library,  Prev: Fixers,  Up: 2to3 - Automated Python 2 to 3 code translation

5.25.4.3 `lib2to3' - 2to3's library
...................................

     Note: The *note lib2to3: ff. API should be considered unstable and
     may change drastically in the future.


File: python.info,  Node: test --- Regression tests package for Python,  Next: test test_support --- Utility functions for tests,  Prev: 2to3 - Automated Python 2 to 3 code translation,  Up: Development Tools

5.25.5 `test' -- Regression tests package for Python
----------------------------------------------------

     Note: The *note test: 176. package is meant for internal use by
     Python only. It is documented for the benefit of the core
     developers of Python. Any use of this package outside of Python's
     standard library is discouraged as code mentioned here can change
     or be removed without notice between releases of Python.

The *note test: 176. package contains all regression tests for Python
as well as the modules *note test.test_support: 177. and
`test.regrtest'.  *note test.test_support: 177. is used to enhance your
tests while `test.regrtest' drives the testing suite.

  Each module in the *note test: 176. package whose name starts with
`test_' is a testing suite for a specific module or feature. All new
tests should be written using the *note unittest: 188. or *note
doctest: b6. module.  Some older tests are written using a
"traditional" testing style that compares output printed to
`sys.stdout'; this style of test is considered deprecated.

See also
........

Module *note unittest: 188.
     Writing PyUnit regression tests.

Module *note doctest: b6.
     Tests embedded in documentation strings.

* Menu:

* Writing Unit Tests for the test package::
* Running tests using the command-line interface::


File: python.info,  Node: Writing Unit Tests for the test package,  Next: Running tests using the command-line interface,  Up: test --- Regression tests package for Python

5.25.5.1 Writing Unit Tests for the `test' package
..................................................

It is preferred that tests that use the *note unittest: 188. module
follow a few guidelines. One is to name the test module by starting it
with `test_' and end it with the name of the module being tested. The
test methods in the test module should start with `test_' and end with
a description of what the method is testing. This is needed so that the
methods are recognized by the test driver as test methods. Also, no
documentation string for the method should be included. A comment (such
as `# Tests function returns only True or False') should be used to
provide documentation for test methods. This is done because
documentation strings get printed out if they exist and thus what test
is being run is not stated.

  A basic boilerplate is often used:

    import unittest
    from test import test_support

    class MyTestCase1(unittest.TestCase):

        # Only use setUp() and tearDown() if necessary

        def setUp(self):
            ... code to execute in preparation for tests ...

        def tearDown(self):
            ... code to execute to clean up after tests ...

        def test_feature_one(self):
            # Test feature one.
            ... testing code ...

        def test_feature_two(self):
            # Test feature two.
            ... testing code ...

        ... more test methods ...

    class MyTestCase2(unittest.TestCase):
        ... same structure as MyTestCase1 ...

    ... more test classes ...

    def test_main():
        test_support.run_unittest(MyTestCase1,
                                  MyTestCase2,
                                  ... list other tests ...
                                 )

    if __name__ == '__main__':
        test_main()

This boilerplate code allows the testing suite to be run by
`test.regrtest' as well as on its own as a script.

  The goal for regression testing is to try to break code. This leads
to a few guidelines to be followed:

   * The testing suite should exercise all classes, functions, and
     constants. This includes not just the external API that is to be
     presented to the outside world but also "private" code.

   * Whitebox testing (examining the code being tested when the tests
     are being written) is preferred. Blackbox testing (testing only
     the published user interface) is not complete enough to make sure
     all boundary and edge cases are tested.

   * Make sure all possible values are tested including invalid ones.
     This makes sure that not only all valid values are acceptable but
     also that improper values are handled correctly.

   * Exhaust as many code paths as possible. Test where branching
     occurs and thus tailor input to make sure as many different paths
     through the code are taken.

   * Add an explicit test for any bugs discovered for the tested code.
     This will make sure that the error does not crop up again if the
     code is changed in the future.

   * Make sure to clean up after your tests (such as close and remove
     all temporary files).

   * If a test is dependent on a specific condition of the operating
     system then verify the condition already exists before attempting
     the test.

   * Import as few modules as possible and do it as soon as possible.
     This minimizes external dependencies of tests and also minimizes
     possible anomalous behavior from side-effects of importing a
     module.

   * Try to maximize code reuse. On occasion, tests will vary by
     something as small as what type of input is used. Minimize code
     duplication by subclassing a basic test class with a class that
     specifies the input:

         class TestFuncAcceptsSequences(unittest.TestCase):

             func = mySuperWhammyFunction

             def test_func(self):
                 self.func(self.arg)

         class AcceptLists(TestFuncAcceptsSequences):
             arg = [1, 2, 3]

         class AcceptStrings(TestFuncAcceptsSequences):
             arg = 'abc'

         class AcceptTuples(TestFuncAcceptsSequences):
             arg = (1, 2, 3)



See also
........

Test Driven Development
     A book by Kent Beck on writing tests before code.


File: python.info,  Node: Running tests using the command-line interface,  Prev: Writing Unit Tests for the test package,  Up: test --- Regression tests package for Python

5.25.5.2 Running tests using the command-line interface
.......................................................

The `test.regrtest' module can be run as a script to drive Python's
regression test suite, thanks to the *note -m: 2ec. option: *python -m
test.regrtest*.  Running the script by itself automatically starts
running all regression tests in the *note test: 176. package. It does
this by finding all modules in the package whose name starts with
`test_', importing them, and executing the function `test_main()' if
present. The names of tests to execute may also be passed to the
script. Specifying a single regression test (*python -m test.regrtest
test_spam*) will minimize output and only print whether the test passed
or failed and thus minimize output.

  Running `test.regrtest' directly allows what resources are available
for tests to use to be set. You do this by using the *note -u: 466.
command-line option. Run *python -m test.regrtest -uall* to turn on all
resources; specifying `all' as an option for `-u' enables all possible
resources. If all but one resource is desired (a more common case), a
comma-separated list of resources that are not desired may be listed
after `all'. The command *python -m test.regrtest
-uall,-audio,-largefile* will run `test.regrtest' with all resources
except the `audio' and `largefile' resources. For a list of all
resources and more command-line options, run *python -m test.regrtest
-h*.

  Some other ways to execute the regression tests depend on what
platform the tests are being executed on. On Unix, you can run *make
test* at the top-level directory where Python was built. On Windows,
executing *rt.bat* from your `PCBuild' directory will run all regression
tests.


File: python.info,  Node: test test_support --- Utility functions for tests,  Prev: test --- Regression tests package for Python,  Up: Development Tools

5.25.6 `test.test_support' -- Utility functions for tests
---------------------------------------------------------

     Note: The *note test.test_support: 177. module has been renamed to
     `test.support' in Python 3.x.

The *note test.test_support: 177. module provides support for Python's
regression tests.

  This module defines the following exceptions:

 -- Exception: test.test_support.TestFailed
     Exception to be raised when a test fails. This is deprecated in
     favor of *note unittest: 188.-based tests and *note
     unittest.TestCase: 27d.'s assertion methods.

 -- Exception: test.test_support.ResourceDenied
     Subclass of `unittest.SkipTest'. Raised when a resource (such as a
     network connection) is not available. Raised by the *note
     requires(): 225f.  function.

  The *note test.test_support: 177. module defines the following
constants:

 -- Data: test.test_support.verbose
     *note True: 39f. when verbose output is enabled. Should be checked
     when more detailed information is desired about a running test.
     _verbose_ is set by `test.regrtest'.

 -- Data: test.test_support.have_unicode
     *note True: 39f. when Unicode support is available.

 -- Data: test.test_support.is_jython
     *note True: 39f. if the running interpreter is Jython.

 -- Data: test.test_support.TESTFN
     Set to a name that is safe to use as the name of a temporary file.
     Any temporary file that is created should be closed and unlinked
     (removed).

  The *note test.test_support: 177. module defines the following
functions:

 -- Function: test.test_support.forget (module_name)
     Remove the module named _module_name_ from `sys.modules' and
     delete any byte-compiled files of the module.

 -- Function: test.test_support.is_resource_enabled (resource)
     Return *note True: 39f. if _resource_ is enabled and available.
     The list of available resources is only set when `test.regrtest'
     is executing the tests.

 -- Function: test.test_support.requires (resource[, msg])
     Raise *note ResourceDenied: 225e. if _resource_ is not available.
     _msg_ is the argument to *note ResourceDenied: 225e. if it is
     raised. Always returns *note True: 39f. if called by a function
     whose `__name__' is `'__main__''.  Used when tests are executed by
     `test.regrtest'.

 -- Function: test.test_support.findfile (filename)
     Return the path to the file named _filename_. If no match is found
     _filename_ is returned. This does not equal a failure since it
     could be the path to the file.

 -- Function: test.test_support.run_unittest (*classes)
     Execute *note unittest.TestCase: 27d. subclasses passed to the
     function. The function scans the classes for methods starting with
     the prefix `test_' and executes the tests individually.

     It is also legal to pass strings as parameters; these should be
     keys in `sys.modules'. Each associated module will be scanned by
     `unittest.TestLoader.loadTestsFromModule()'. This is usually seen
     in the following `test_main()' function:

         def test_main():
             test_support.run_unittest(__name__)

     This will run all tests defined in the named module.

 -- Function: test.test_support.check_warnings (*filters, quiet=True)
     A convenience wrapper for *note warnings.catch_warnings(): 2269.
     that makes it easier to test that a warning was correctly raised.
     It is approximately equivalent to calling
     `warnings.catch_warnings(record=True)' with *note
     warnings.simplefilter(): 226a. set to `always' and with the option
     to automatically validate the results that are recorded.

     `check_warnings' accepts 2-tuples of the form `("message regexp",
     WarningCategory)' as positional arguments. If one or more
     _filters_ are provided, or if the optional keyword argument
     _quiet_ is *note False: 3a0, it checks to make sure the warnings
     are as expected:  each specified filter must match at least one of
     the warnings raised by the enclosed code or the test fails, and if
     any warnings are raised that do not match any of the specified
     filters the test fails.  To disable the first of these checks, set
     _quiet_ to *note True: 39f.

     If no arguments are specified, it defaults to:

         check_warnings(("", Warning), quiet=True)

     In this case all warnings are caught and no errors are raised.

     On entry to the context manager, a `WarningRecorder' instance is
     returned. The underlying warnings list from *note
     catch_warnings(): 2269. is available via the recorder object's
     *note warnings: 194. attribute.  As a convenience, the attributes
     of the object representing the most recent warning can also be
     accessed directly through the recorder object (see example below).
     If no warning has been raised, then any of the attributes that
     would otherwise be expected on an object representing a warning
     will return *note None: 389.

     The recorder object also has a `reset()' method, which clears the
     warnings list.

     The context manager is designed to be used like this:

         with check_warnings(("assertion is always true", SyntaxWarning),
                             ("", UserWarning)):
             exec('assert(False, "Hey!")')
             warnings.warn(UserWarning("Hide me!"))

     In this case if either warning was not raised, or some other
     warning was raised, *note check_warnings(): 2268. would raise an
     error.

     When a test needs to look more deeply into the warnings, rather
     than just checking whether or not they occurred, code like this
     can be used:

         with check_warnings(quiet=True) as w:
             warnings.warn("foo")
             assert str(w.args[0]) == "foo"
             warnings.warn("bar")
             assert str(w.args[0]) == "bar"
             assert str(w.warnings[0].args[0]) == "foo"
             assert str(w.warnings[1].args[0]) == "bar"
             w.reset()
             assert len(w.warnings) == 0

     Here all warnings will be caught, and the test code tests the
     captured warnings directly.

     New in version 2.6.

     Changed in version 2.7: New optional arguments _filters_ and
     _quiet_.

 -- Function: test.test_support.check_py3k_warnings (*filters,
          quiet=False)
     Similar to *note check_warnings(): 2268, but for Python 3
     compatibility warnings.  If `sys.py3kwarning == 1', it checks if
     the warning is effectively raised.  If `sys.py3kwarning == 0', it
     checks that no warning is raised.  It accepts 2-tuples of the form
     `("message regexp", WarningCategory)' as positional arguments.
     When the optional keyword argument _quiet_ is *note True: 39f, it
     does not fail if a filter catches nothing.  Without arguments, it
     defaults to:

         check_py3k_warnings(("", DeprecationWarning), quiet=False)

     New in version 2.7.

 -- Function: test.test_support.captured_stdout ()
     This is a context manager that runs the *note with: 1bd. statement
     body using a *note StringIO.StringIO: 2d1. object as sys.stdout.
     That object can be retrieved using the `as' clause of the *note
     with: 1bd. statement.

     Example use:

         with captured_stdout() as s:
             print "hello"
         assert s.getvalue() == "hello"

     New in version 2.6.

 -- Function: test.test_support.import_module (name, deprecated=False)
     This function imports and returns the named module. Unlike a normal
     import, this function raises `unittest.SkipTest' if the module
     cannot be imported.

     Module and package deprecation messages are suppressed during this
     import if _deprecated_ is *note True: 39f.

     New in version 2.7.

 -- Function: test.test_support.import_fresh_module (name, fresh=(),
          blocked=(), deprecated=False)
     This function imports and returns a fresh copy of the named Python
     module by removing the named module from `sys.modules' before
     doing the import.  Note that unlike *note reload(): 55f, the
     original module is not affected by this operation.

     _fresh_ is an iterable of additional module names that are also
     removed from the `sys.modules' cache before doing the import.

     _blocked_ is an iterable of module names that are replaced with `0'
     in the module cache during the import to ensure that attempts to
     import them raise *note ImportError: 35f.

     The named module and any modules named in the _fresh_ and _blocked_
     parameters are saved before starting the import and then
     reinserted into `sys.modules' when the fresh import is complete.

     Module and package deprecation messages are suppressed during this
     import if _deprecated_ is *note True: 39f.

     This function will raise `unittest.SkipTest' is the named module
     cannot be imported.

     Example use:

         # Get copies of the warnings module for testing without
         # affecting the version being used by the rest of the test suite
         # One copy uses the C implementation, the other is forced to use
         # the pure Python fallback implementation
         py_warnings = import_fresh_module('warnings', blocked=['_warnings'])
         c_warnings = import_fresh_module('warnings', fresh=['_warnings'])

     New in version 2.7.

  The *note test.test_support: 177. module defines the following
classes:

 -- Class: test.test_support.TransientResource (exc[, **kwargs])
     Instances are a context manager that raises *note ResourceDenied:
     225e. if the specified exception type is raised.  Any keyword
     arguments are treated as attribute/value pairs to be compared
     against any exception raised within the *note with: 1bd.
     statement.  Only if all pairs match properly against attributes on
     the exception is *note ResourceDenied: 225e. raised.

     New in version 2.6.

 -- Class: test.test_support.EnvironmentVarGuard
     Class used to temporarily set or unset environment variables.
     Instances can be used as a context manager and have a complete
     dictionary interface for querying/modifying the underlying
     `os.environ'. After exit from the context manager all changes to
     environment variables done through this instance will be rolled
     back.

     New in version 2.6.

     Changed in version 2.7: Added dictionary interface.

 -- Method: EnvironmentVarGuard.set (envvar, value)
     Temporarily set the environment variable `envvar' to the value of
     `value'.

 -- Method: EnvironmentVarGuard.unset (envvar)
     Temporarily unset the environment variable `envvar'.

 -- Class: test.test_support.WarningsRecorder
     Class used to record warnings for unit tests. See documentation of
     *note check_warnings(): 2268. above for more details.

     New in version 2.6.


File: python.info,  Node: Debugging and Profiling,  Next: Python Runtime Services,  Prev: Development Tools,  Up: The Python Standard Library

5.26 Debugging and Profiling
============================

These libraries help you with Python development: the debugger enables
you to step through code, analyze stack frames and set breakpoints
etc., and the profilers run code and give you a detailed breakdown of
execution times, allowing you to identify bottlenecks in your programs.

* Menu:

* bdb: bdb --- Debugger framework. Debugger framework
* pdb: pdb --- The Python Debugger. The Python Debugger
* Debugger Commands::
* The Python Profilers::
* hotshot: hotshot --- High performance logging profiler. High performance logging profiler
* timeit: timeit --- Measure execution time of small code snippets. Measure execution time of small code snippets
* trace: trace --- Trace or track Python statement execution. Trace or track Python statement execution


File: python.info,  Node: bdb --- Debugger framework,  Next: pdb --- The Python Debugger,  Up: Debugging and Profiling

5.26.1 `bdb' -- Debugger framework
----------------------------------

The *note bdb: 18. module handles basic debugger functions, like
setting breakpoints or managing execution via the debugger.

  The following exception is defined:

 -- Exception: bdb.BdbQuit
     Exception raised by the *note Bdb: 200. class for quitting the
     debugger.

  The *note bdb: 18. module also defines two classes:

 -- Class: bdb.Breakpoint (self, file, line[, temporary=0[, cond=None[,
          funcname=None]]])
     This class implements temporary breakpoints, ignore counts,
     disabling and (re-)enabling, and conditionals.

     Breakpoints are indexed by number through a list called
     `bpbynumber' and by `(file, line)' pairs through `bplist'.  The
     former points to a single instance of class *note Breakpoint:
     2279.  The latter points to a list of such instances since there
     may be more than one breakpoint per line.

     When creating a breakpoint, its associated filename should be in
     canonical form.  If a _funcname_ is defined, a breakpoint hit will
     be counted when the first line of that function is executed.  A
     conditional breakpoint always counts a hit.

     *note Breakpoint: 2279. instances have the following methods:

      -- Method: deleteMe ()
          Delete the breakpoint from the list associated to a
          file/line.  If it is the last breakpoint in that position, it
          also deletes the entry for the file/line.

      -- Method: enable ()
          Mark the breakpoint as enabled.

      -- Method: disable ()
          Mark the breakpoint as disabled.

      -- Method: pprint ([out])
          Print all the information about the breakpoint:

             * The breakpoint number.

             * If it is temporary or not.

             * Its file,line position.

             * The condition that causes a break.

             * If it must be ignored the next N times.

             * The breakpoint hit count.

 -- Class: bdb.Bdb (skip=None)
     The *note Bdb: 200. class acts as a generic Python debugger base
     class.

     This class takes care of the details of the trace facility; a
     derived class should implement user interaction.  The standard
     debugger class (*note pdb.Pdb: 227e.) is an example.

     The _skip_ argument, if given, must be an iterable of glob-style
     module name patterns.  The debugger will not step into frames that
     originate in a module that matches one of these patterns. Whether a
     frame is considered to originate in a certain module is determined
     by the `__name__' in the frame globals.

     New in version 2.7: The _skip_ argument.

     The following methods of *note Bdb: 200. normally don't need to be
     overridden.

      -- Method: canonic (filename)
          Auxiliary method for getting a filename in a canonical form,
          that is, as a case-normalized (on case-insensitive
          filesystems) absolute path, stripped of surrounding angle
          brackets.

      -- Method: reset ()
          Set the `botframe', `stopframe', `returnframe' and `quitting'
          attributes with values ready to start debugging.

      -- Method: trace_dispatch (frame, event, arg)
          This function is installed as the trace function of debugged
          frames.  Its return value is the new trace function (in most
          cases, that is, itself).

          The default implementation decides how to dispatch a frame,
          depending on the type of event (passed as a string) that is
          about to be executed.  _event_ can be one of the following:

             * `"line"': A new line of code is going to be executed.

             * `"call"': A function is about to be called, or another
               code block entered.

             * `"return"': A function or other code block is about to
               return.

             * `"exception"': An exception has occurred.

             * `"c_call"': A C function is about to be called.

             * `"c_return"': A C function has returned.

             * `"c_exception"': A C function has raised an exception.

          For the Python events, specialized functions (see below) are
          called.  For the C events, no action is taken.

          The _arg_ parameter depends on the previous event.

          See the documentation for *note sys.settrace(): 48d. for more
          information on the trace function.  For more information on
          code and frame objects, refer to *note The standard type
          hierarchy: 6c8.

      -- Method: dispatch_line (frame)
          If the debugger should stop on the current line, invoke the
          *note user_line(): 2283. method (which should be overridden
          in subclasses).  Raise a *note BdbQuit: 2278. exception if
          the `Bdb.quitting' flag is set (which can be set from *note
          user_line(): 2283.).  Return a reference to the *note
          trace_dispatch(): 2281. method for further tracing in that
          scope.

      -- Method: dispatch_call (frame, arg)
          If the debugger should stop on this function call, invoke the
          *note user_call(): 2285. method (which should be overridden
          in subclasses).  Raise a *note BdbQuit: 2278. exception if
          the `Bdb.quitting' flag is set (which can be set from *note
          user_call(): 2285.).  Return a reference to the *note
          trace_dispatch(): 2281. method for further tracing in that
          scope.

      -- Method: dispatch_return (frame, arg)
          If the debugger should stop on this function return, invoke
          the *note user_return(): 2287. method (which should be
          overridden in subclasses).  Raise a *note BdbQuit: 2278.
          exception if the `Bdb.quitting' flag is set (which can be set
          from *note user_return(): 2287.).  Return a reference to the
          *note trace_dispatch(): 2281. method for further tracing in
          that scope.

      -- Method: dispatch_exception (frame, arg)
          If the debugger should stop at this exception, invokes the
          *note user_exception(): 2289. method (which should be
          overridden in subclasses).  Raise a *note BdbQuit: 2278.
          exception if the `Bdb.quitting' flag is set (which can be set
          from *note user_exception(): 2289.).  Return a reference to
          the *note trace_dispatch(): 2281. method for further tracing
          in that scope.

     Normally derived classes don't override the following methods, but
     they may if they want to redefine the definition of stopping and
     breakpoints.

      -- Method: stop_here (frame)
          This method checks if the _frame_ is somewhere below
          `botframe' in the call stack.  `botframe' is the frame in
          which debugging started.

      -- Method: break_here (frame)
          This method checks if there is a breakpoint in the filename
          and line belonging to _frame_ or, at least, in the current
          function.  If the breakpoint is a temporary one, this method
          deletes it.

      -- Method: break_anywhere (frame)
          This method checks if there is a breakpoint in the filename
          of the current frame.

     Derived classes should override these methods to gain control over
     debugger operation.

      -- Method: user_call (frame, argument_list)
          This method is called from *note dispatch_call(): 2284. when
          there is the possibility that a break might be necessary
          anywhere inside the called function.

      -- Method: user_line (frame)
          This method is called from *note dispatch_line(): 2282. when
          either *note stop_here(): 228a. or *note break_here(): 228b.
          yields True.

      -- Method: user_return (frame, return_value)
          This method is called from *note dispatch_return(): 2286.
          when *note stop_here(): 228a.  yields True.

      -- Method: user_exception (frame, exc_info)
          This method is called from *note dispatch_exception(): 2288.
          when *note stop_here(): 228a. yields True.

      -- Method: do_clear (arg)
          Handle how a breakpoint must be removed when it is a
          temporary one.

          This method must be implemented by derived classes.

     Derived classes and clients can call the following methods to
     affect the stepping state.

      -- Method: set_step ()
          Stop after one line of code.

      -- Method: set_next (frame)
          Stop on the next line in or below the given frame.

      -- Method: set_return (frame)
          Stop when returning from the given frame.

      -- Method: set_until (frame)
          Stop when the line with the line no greater than the current
          one is reached or when returning from current frame

      -- Method: set_trace ([frame])
          Start debugging from _frame_.  If _frame_ is not specified,
          debugging starts from caller's frame.

      -- Method: set_continue ()
          Stop only at breakpoints or when finished.  If there are no
          breakpoints, set the system trace function to None.

      -- Method: set_quit ()
          Set the `quitting' attribute to True.  This raises *note
          BdbQuit: 2278. in the next call to one of the `dispatch_*()'
          methods.

     Derived classes and clients can call the following methods to
     manipulate breakpoints.  These methods return a string containing
     an error message if something went wrong, or `None' if all is well.

      -- Method: set_break (filename, lineno[, temporary=0[, cond[,
               funcname]]])
          Set a new breakpoint.  If the _lineno_ line doesn't exist for
          the _filename_ passed as argument, return an error message.
          The _filename_ should be in canonical form, as described in
          the *note canonic(): 227f. method.

      -- Method: clear_break (filename, lineno)
          Delete the breakpoints in _filename_ and _lineno_.  If none
          were set, an error message is returned.

      -- Method: clear_bpbynumber (arg)
          Delete the breakpoint which has the index _arg_ in the
          `Breakpoint.bpbynumber'.  If _arg_ is not numeric or out of
          range, return an error message.

      -- Method: clear_all_file_breaks (filename)
          Delete all breakpoints in _filename_.  If none were set, an
          error message is returned.

      -- Method: clear_all_breaks ()
          Delete all existing breakpoints.

      -- Method: get_break (filename, lineno)
          Check if there is a breakpoint for _lineno_ of _filename_.

      -- Method: get_breaks (filename, lineno)
          Return all breakpoints for _lineno_ in _filename_, or an
          empty list if none are set.

      -- Method: get_file_breaks (filename)
          Return all breakpoints in _filename_, or an empty list if
          none are set.

      -- Method: get_all_breaks ()
          Return all breakpoints that are set.

     Derived classes and clients can call the following methods to get
     a data structure representing a stack trace.

      -- Method: get_stack (f, t)
          Get a list of records for a frame and all higher (calling)
          and lower frames, and the size of the higher part.

      -- Method: format_stack_entry (frame_lineno[, lprefix=': '])
          Return a string with information about a stack entry,
          identified by a `(frame, lineno)' tuple:

             * The canonical form of the filename which contains the
               frame.

             * The function name, or `"<lambda>"'.

             * The input arguments.

             * The return value.

             * The line of code (if it exists).

     The following two methods can be called by clients to use a
     debugger to debug a *note statement: d84, given as a string.

      -- Method: run (cmd[, globals[, locals]])
          Debug a statement executed via the *note exec: 3f3.
          statement.  _globals_ defaults to `__main__.__dict__',
          _locals_ defaults to _globals_.

      -- Method: runeval (expr[, globals[, locals]])
          Debug an expression executed via the *note eval(): 34f.
          function.  _globals_ and _locals_ have the same meaning as in
          *note run(): 22a0.

      -- Method: runctx (cmd, globals, locals)
          For backwards compatibility.  Calls the *note run(): 22a0.
          method.

      -- Method: runcall (func, *args, **kwds)
          Debug a single function call, and return its result.

  Finally, the module defines the following functions:

 -- Function: bdb.checkfuncname (b, frame)
     Check whether we should break here, depending on the way the
     breakpoint _b_ was set.

     If it was set via line number, it checks if `b.line' is the same
     as the one in the frame also passed as argument.  If the
     breakpoint was set via function name, we have to check we are in
     the right frame (the right function) and if we are in its first
     executable line.

 -- Function: bdb.effective (file, line, frame)
     Determine if there is an effective (active) breakpoint at this
     line of code.  Return a tuple of the breakpoint and a boolean that
     indicates if it is ok to delete a temporary breakpoint.  Return
     `(None, None)' if there is no matching breakpoint.

 -- Function: bdb.set_trace ()
     Start debugging with a *note Bdb: 200. instance from caller's
     frame.


File: python.info,  Node: pdb --- The Python Debugger,  Next: Debugger Commands,  Prev: bdb --- Debugger framework,  Up: Debugging and Profiling

5.26.2 `pdb' -- The Python Debugger
-----------------------------------

The module *note pdb: 12d. defines an interactive source code debugger
for Python programs.  It supports setting (conditional) breakpoints and
single stepping at the source line level, inspection of stack frames,
source code listing, and evaluation of arbitrary Python code in the
context of any stack frame.  It also supports post-mortem debugging and
can be called under program control.

  The debugger is extensible -- it is actually defined as the class
*note Pdb: 227e.  This is currently undocumented but easily understood
by reading the source.  The extension interface uses the modules *note
bdb: 18. and *note cmd: 61.

  The debugger's prompt is `(Pdb)'. Typical usage to run a program
under control of the debugger is:

    >>> import pdb
    >>> import mymodule
    >>> pdb.run('mymodule.test()')
    > <string>(0)?()
    (Pdb) continue
    > <string>(1)?()
    (Pdb) continue
    NameError: 'spam'
    > <string>(1)?()
    (Pdb)

`pdb.py' can also be invoked as a script to debug other scripts.  For
example:

    python -m pdb myscript.py

When invoked as a script, pdb will automatically enter post-mortem
debugging if the program being debugged exits abnormally. After
post-mortem debugging (or after normal exit of the program), pdb will
restart the program. Automatic restarting preserves pdb's state (such
as breakpoints) and in most cases is more useful than quitting the
debugger upon program's exit.

  New in version 2.4: Restarting post-mortem behavior added.

  The typical usage to break into the debugger from a running program
is to insert

    import pdb; pdb.set_trace()

at the location you want to break into the debugger.  You can then step
through the code following this statement, and continue running without
the debugger using the `c' command.

  The typical usage to inspect a crashed program is:

    >>> import pdb
    >>> import mymodule
    >>> mymodule.test()
    Traceback (most recent call last):
      File "<stdin>", line 1, in ?
      File "./mymodule.py", line 4, in test
        test2()
      File "./mymodule.py", line 3, in test2
        print spam
    NameError: spam
    >>> pdb.pm()
    > ./mymodule.py(3)test2()
    -> print spam
    (Pdb)

The module defines the following functions; each enters the debugger in
a slightly different way:

 -- Function: pdb.run (statement[, globals[, locals]])
     Execute the _statement_ (given as a string) under debugger
     control.  The debugger prompt appears before any code is executed;
     you can set breakpoints and type `continue', or you can step
     through the statement using `step' or `next' (all these commands
     are explained below).  The optional _globals_ and _locals_
     arguments specify the environment in which the code is executed; by
     default the dictionary of the module *note __main__: 2. is used.
     (See the explanation of the *note exec: 3f3. statement or the
     *note eval(): 34f. built-in function.)

 -- Function: pdb.runeval (expression[, globals[, locals]])
     Evaluate the _expression_ (given as a string) under debugger
     control.  When *note runeval(): 22aa. returns, it returns the
     value of the expression.  Otherwise this function is similar to
     *note run(): 21b0.

 -- Function: pdb.runcall (function[, argument, ...])
     Call the _function_ (a function or method object, not a string)
     with the given arguments.  When *note runcall(): 22ab. returns, it
     returns whatever the function call returned.  The debugger prompt
     appears as soon as the function is entered.

 -- Function: pdb.set_trace ()
     Enter the debugger at the calling stack frame.  This is useful to
     hard-code a breakpoint at a given point in a program, even if the
     code is not otherwise being debugged (e.g. when an assertion
     fails).

 -- Function: pdb.post_mortem ([traceback])
     Enter post-mortem debugging of the given _traceback_ object.  If no
     _traceback_ is given, it uses the one of the exception that is
     currently being handled (an exception must be being handled if the
     default is to be used).

 -- Function: pdb.pm ()
     Enter post-mortem debugging of the traceback found in *note
     sys.last_traceback: 22ad.

  The `run*' functions and *note set_trace(): 21ad. are aliases for
instantiating the *note Pdb: 227e. class and calling the method of the
same name.  If you want to access further features, you have to do this
yourself:

 -- Class: pdb.Pdb (completekey='tab', stdin=None, stdout=None,
          skip=None)
     *note Pdb: 227e. is the debugger class.

     The _completekey_, _stdin_ and _stdout_ arguments are passed to the
     underlying *note cmd.Cmd: 1fb8. class; see the description there.

     The _skip_ argument, if given, must be an iterable of glob-style
     module name patterns.  The debugger will not step into frames that
     originate in a module that matches one of these patterns. (1)

     Example call to enable tracing with _skip_:

         import pdb; pdb.Pdb(skip=['django.*']).set_trace()

     New in version 2.7: The _skip_ argument.

      -- Method: run (statement[, globals[, locals]])
      -- Method: runeval (expression[, globals[, locals]])
      -- Method: runcall (function[, argument, ...])
      -- Method: set_trace ()
          See the documentation for the functions explained above.

  ---------- Footnotes ----------

  (1) Whether a frame is considered to originate in a certain module is
determined by the `__name__' in the frame globals.


File: python.info,  Node: Debugger Commands,  Next: The Python Profilers,  Prev: pdb --- The Python Debugger,  Up: Debugging and Profiling

5.26.3 Debugger Commands
------------------------

The debugger recognizes the following commands.  Most commands can be
abbreviated to one or two letters; e.g. `h(elp)' means that either `h'
or `help' can be used to enter the help command (but not `he' or `hel',
nor `H' or `Help' or `HELP').  Arguments to commands must be separated
by whitespace (spaces or tabs).  Optional arguments are enclosed in
square brackets (`[]') in the command syntax; the square brackets must
not be typed.  Alternatives in the command syntax are separated by a
vertical bar (`|').

  Entering a blank line repeats the last command entered.  Exception:
if the last command was a `list' command, the next 11 lines are listed.

  Commands that the debugger doesn't recognize are assumed to be Python
statements and are executed in the context of the program being
debugged.  Python statements can also be prefixed with an exclamation
point (`!').  This is a powerful way to inspect the program being
debugged; it is even possible to change a variable or call a function.
When an exception occurs in such a statement, the exception name is
printed but the debugger's state is not changed.

  Multiple commands may be entered on a single line, separated by `;;'.
(A single `;' is not used as it is the separator for multiple commands
in a line that is passed to the Python parser.) No intelligence is
applied to separating the commands; the input is split at the first
`;;' pair, even if it is in the middle of a quoted string.

  The debugger supports aliases.  Aliases can have parameters which
allows one a certain level of adaptability to the context under
examination.

  If a file `.pdbrc'  exists in the user's home directory or in the
current directory, it is read in and executed as if it had been typed
at the debugger prompt. This is particularly useful for aliases.  If
both files exist, the one in the home directory is read first and
aliases defined there can be overridden by the local file.

h(elp) [_command_]
     Without argument, print the list of available commands.  With a
     _command_ as argument, print help about that command.  `help pdb'
     displays the full documentation file; if the environment variable `PAGER'
     is defined, the file is piped through that command instead.  Since
     the _command_ argument must be an identifier, `help exec' must be
     entered to get help on the `!' command.

w(here)
     Print a stack trace, with the most recent frame at the bottom.  An
     arrow indicates the current frame, which determines the context of
     most commands.

d(own)
     Move the current frame one level down in the stack trace (to a
     newer frame).

u(p)
     Move the current frame one level up in the stack trace (to an
     older frame).

b(reak) [[_filename_:]_lineno_ | _function_[, _condition_]]
     With a _lineno_ argument, set a break there in the current file.
     With a _function_ argument, set a break at the first executable
     statement within that function. The line number may be prefixed
     with a filename and a colon, to specify a breakpoint in another
     file (probably one that hasn't been loaded yet).  The file is
     searched on `sys.path'. Note that each breakpoint is assigned a
     number to which all the other breakpoint commands refer.

     If a second argument is present, it is an expression which must
     evaluate to true before the breakpoint is honored.

     Without argument, list all breaks, including for each breakpoint,
     the number of times that breakpoint has been hit, the current
     ignore count, and the associated condition if any.

tbreak [[_filename_:]_lineno_ | _function_[, _condition_]]
     Temporary breakpoint, which is removed automatically when it is
     first hit.  The arguments are the same as break.

cl(ear) [_filename:lineno_ | _bpnumber_ [_bpnumber ..._]]
     With a _filename:lineno_ argument, clear all the breakpoints at
     this line.  With a space separated list of breakpoint numbers,
     clear those breakpoints.  Without argument, clear all breaks (but
     first ask confirmation).

disable [_bpnumber_ [_bpnumber ..._]]
     Disables the breakpoints given as a space separated list of
     breakpoint numbers.  Disabling a breakpoint means it cannot cause
     the program to stop execution, but unlike clearing a breakpoint,
     it remains in the list of breakpoints and can be (re-)enabled.

enable [_bpnumber_ [_bpnumber ..._]]
     Enables the breakpoints specified.

ignore _bpnumber_ [_count_]
     Sets the ignore count for the given breakpoint number.  If count
     is omitted, the ignore count is set to 0.  A breakpoint becomes
     active when the ignore count is zero.  When non-zero, the count is
     decremented each time the breakpoint is reached and the breakpoint
     is not disabled and any associated condition evaluates to true.

condition _bpnumber_ [_condition_]
     Condition is an expression which must evaluate to true before the
     breakpoint is honored.  If condition is absent, any existing
     condition is removed; i.e., the breakpoint is made unconditional.

commands [_bpnumber_]
     Specify a list of commands for breakpoint number _bpnumber_.  The
     commands themselves appear on the following lines.  Type a line
     containing just 'end' to terminate the commands. An example:

         (Pdb) commands 1
         (com) print some_variable
         (com) end
         (Pdb)

     To remove all commands from a breakpoint, type commands and follow
     it immediately with  end; that is, give no commands.

     With no _bpnumber_ argument, commands refers to the last
     breakpoint set.

     You can use breakpoint commands to start your program up again.
     Simply use the continue command, or step, or any other command
     that resumes execution.

     Specifying any command resuming execution (currently continue,
     step, next, return, jump, quit and their abbreviations) terminates
     the command list (as if that command was immediately followed by
     end). This is because any time you resume execution (even with a
     simple next or step), you may encounter another breakpoint-which
     could have its own command list, leading to ambiguities about
     which list to execute.

     If you use the 'silent' command in the command list, the usual
     message about stopping at a breakpoint is not printed.  This may
     be desirable for breakpoints that are to print a specific message
     and then continue.  If none of the other commands print anything,
     you see no sign that the breakpoint was reached.

     New in version 2.5.

s(tep)
     Execute the current line, stop at the first possible occasion
     (either in a function that is called or on the next line in the
     current function).

n(ext)
     Continue execution until the next line in the current function is
     reached or it returns.  (The difference between `next' and `step'
     is that `step' stops inside a called function, while `next'
     executes called functions at (nearly) full speed, only stopping at
     the next line in the current function.)

unt(il)
     Continue execution until the line with the line number greater
     than the current one is reached or when returning from current
     frame.

     New in version 2.6.

r(eturn)
     Continue execution until the current function returns.

c(ont(inue))
     Continue execution, only stop when a breakpoint is encountered.

j(ump) _lineno_
     Set the next line that will be executed.  Only available in the
     bottom-most frame.  This lets you jump back and execute code
     again, or jump forward to skip code that you don't want to run.

     It should be noted that not all jumps are allowed -- for instance
     it is not possible to jump into the middle of a *note for: 2e1.
     loop or out of a *note finally: 385. clause.

l(ist) [_first_[, _last_]]
     List source code for the current file.  Without arguments, list 11
     lines around the current line or continue the previous listing.
     With one argument, list 11 lines around at that line.  With two
     arguments, list the given range; if the second argument is less
     than the first, it is interpreted as a count.

a(rgs)
     Print the argument list of the current function.

p _expression_
     Evaluate the _expression_ in the current context and print its
     value.

          Note: `print' can also be used, but is not a debugger command
          -- this executes the Python *note print: 4cd. statement.

pp _expression_
     Like the `p' command, except the value of the expression is
     pretty-printed using the *note pprint: 139. module.

alias [_name_ [command]]
     Creates an alias called _name_ that executes _command_.  The
     command must _not_ be enclosed in quotes.  Replaceable parameters
     can be indicated by `%1', `%2', and so on, while `%*' is replaced
     by all the parameters.  If no command is given, the current alias
     for _name_ is shown. If no arguments are given, all aliases are
     listed.

     Aliases may be nested and can contain anything that can be legally
     typed at the pdb prompt.  Note that internal pdb commands _can_ be
     overridden by aliases.  Such a command is then hidden until the
     alias is removed.  Aliasing is recursively applied to the first
     word of the command line; all other words in the line are left
     alone.

     As an example, here are two useful aliases (especially when placed
     in the `.pdbrc' file):

         #Print instance variables (usage "pi classInst")
         alias pi for k in %1.__dict__.keys(): print "%1.",k,"=",%1.__dict__[k]
         #Print instance variables in self
         alias ps pi self


unalias _name_
     Deletes the specified alias.

[!]_statement_
     Execute the (one-line) _statement_ in the context of the current
     stack frame.  The exclamation point can be omitted unless the
     first word of the statement resembles a debugger command. To set a
     global variable, you can prefix the assignment command with a
     `global' command on the same line, e.g.:

         (Pdb) global list_options; list_options = ['-l']
         (Pdb)


run [_args_ ...]
     Restart the debugged Python program. If an argument is supplied,
     it is split with "shlex" and the result is used as the new
     sys.argv. History, breakpoints, actions and debugger options are
     preserved. "restart" is an alias for "run".

     New in version 2.6.

q(uit)
     Quit from the debugger. The program being executed is aborted.


File: python.info,  Node: The Python Profilers,  Next: hotshot --- High performance logging profiler,  Prev: Debugger Commands,  Up: Debugging and Profiling

5.26.4 The Python Profilers
---------------------------

Copyright © 1994, by InfoSeek Corporation, all rights reserved.

  Written by James Roskind. (1)

  Permission to use, copy, modify, and distribute this Python software
and its associated documentation for any purpose (subject to the
restriction in the following sentence) without fee is hereby granted,
provided that the above copyright notice appears in all copies, and
that both that copyright notice and this permission notice appear in
supporting documentation, and that the name of InfoSeek not be used in
advertising or publicity pertaining to distribution of the software
without specific, written prior permission.  This permission is
explicitly restricted to the copying and modification of the software
to remain in Python, compiled Python, or other languages (such as C)
wherein the modified or derived code is exclusively imported into a
Python module.

  INFOSEEK CORPORATION DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS
SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS. IN NO EVENT SHALL INFOSEEK CORPORATION BE LIABLE FOR ANY
SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER
RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF
CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

* Menu:

* Introduction to the profilers::
* Instant User's Manual::
* What Is Deterministic Profiling?::
* Reference Manual: Reference Manual -- profile and cProfile. profile and cProfile
* Limitations::
* Calibration::
* Extensions: Extensions --- Deriving Better Profilers. Deriving Better Profilers

  ---------- Footnotes ----------

  (1) Updated and converted to LaTeX by Guido van Rossum. Further
updated by Armin Rigo to integrate the documentation for the new *note
cProfile: 74. module of Python 2.5.


File: python.info,  Node: Introduction to the profilers,  Next: Instant User's Manual,  Up: The Python Profilers

5.26.4.1 Introduction to the profilers
......................................

A _profiler_ is a program that describes the run time performance of a
program, providing a variety of statistics.  This documentation
describes the profiler functionality provided in the modules *note
cProfile: 74, *note profile: 13a. and *note pstats: 13b.  This profiler
provides _deterministic profiling_ of Python programs.  It also
provides a series of report generation tools to allow users to rapidly
examine the results of a profile operation.

  The Python standard library provides three different profilers:

  1. *note cProfile: 74. is recommended for most users; it's a C
     extension with reasonable overhead that makes it suitable for
     profiling long-running programs.  Based on `lsprof', contributed
     by Brett Rosen and Ted Czotter.

     New in version 2.5.

  2. *note profile: 13a, a pure Python module whose interface is
     imitated by *note cProfile: 74.  Adds significant overhead to
     profiled programs.  If you're trying to extend the profiler in
     some way, the task might be easier with this module.  Copyright ©
     1994, by InfoSeek Corporation.

     Changed in version 2.4: Now also reports the time spent in calls
     to built-in functions and methods.

  3. *note hotshot: ea. was an experimental C module that focused on
     minimizing the overhead of profiling, at the expense of longer data
     post-processing times.  It is no longer maintained and may be
     dropped in a future version of Python.

     Changed in version 2.5: The results should be more meaningful than
     in the past: the timing core contained a critical bug.

  The *note profile: 13a. and *note cProfile: 74. modules export the
same interface, so they are mostly interchangeable; *note cProfile: 74.
has a much lower overhead but is newer and might not be available on
all systems.  *note cProfile: 74. is really a compatibility layer on
top of the internal `_lsprof' module.  The *note hotshot: ea. module is
reserved for specialized usage.


File: python.info,  Node: Instant User's Manual,  Next: What Is Deterministic Profiling?,  Prev: Introduction to the profilers,  Up: The Python Profilers

5.26.4.2 Instant User's Manual
..............................

This section is provided for users that "don't want to read the
manual." It provides a very brief overview, and allows a user to
rapidly perform profiling on an existing application.

  To profile an application with a main entry point of `foo()', you
would add the following to your module:

    import cProfile
    cProfile.run('foo()')

(Use *note profile: 13a. instead of *note cProfile: 74. if the latter
is not available on your system.)

  The above action would cause `foo()' to be run, and a series of
informative lines (the profile) to be printed.  The above approach is
most useful when working with the interpreter.  If you would like to
save the results of a profile into a file for later examination, you
can supply a file name as the second argument to the `run()' function:

    import cProfile
    cProfile.run('foo()', 'fooprof')

The file `cProfile.py' can also be invoked as a script to profile
another script.  For example:

    python -m cProfile myscript.py

`cProfile.py' accepts two optional arguments on the command line:

    cProfile.py [-o output_file] [-s sort_order]

`-s' only applies to standard output (`-o' is not supplied).  Look in
the `Stats' documentation for valid sort values.

  When you wish to review the profile, you should use the methods in the
*note pstats: 13b. module.  Typically you would load the statistics
data as follows:

    import pstats
    p = pstats.Stats('fooprof')

The class `Stats' (the above code just created an instance of this
class) has a variety of methods for manipulating and printing the data
that was just read into `p'.  When you ran *note cProfile.run(): 22bb.
above, what was printed was the result of three method calls:

    p.strip_dirs().sort_stats(-1).print_stats()

The first method removed the extraneous path from all the module names.
The second method sorted all the entries according to the standard
module/line/name string that is printed. The third method printed out
all the statistics.  You might try the following sort calls:

    p.sort_stats('name')
    p.print_stats()

The first call will actually sort the list by function name, and the
second call will print out the statistics.  The following are some
interesting calls to experiment with:

    p.sort_stats('cumulative').print_stats(10)

This sorts the profile by cumulative time in a function, and then only
prints the ten most significant lines.  If you want to understand what
algorithms are taking time, the above line is what you would use.

  If you were looking to see what functions were looping a lot, and
taking a lot of time, you would do:

    p.sort_stats('time').print_stats(10)

to sort according to time spent within each function, and then print the
statistics for the top ten functions.

  You might also try:

    p.sort_stats('file').print_stats('__init__')

This will sort all the statistics by file name, and then print out
statistics for only the class init methods (since they are spelled with
`__init__' in them).  As one final example, you could try:

    p.sort_stats('time', 'cum').print_stats(.5, 'init')

This line sorts statistics with a primary key of time, and a secondary
key of cumulative time, and then prints out some of the statistics. To
be specific, the list is first culled down to 50% (re: `.5') of its
original size, then only lines containing `init' are maintained, and
that sub-sub-list is printed.

  If you wondered what functions called the above functions, you could
now (`p' is still sorted according to the last criteria) do:

    p.print_callers(.5, 'init')

and you would get a list of callers for each of the listed functions.

  If you want more functionality, you're going to have to read the
manual, or guess what the following functions do:

    p.print_callees()
    p.add('fooprof')

Invoked as a script, the *note pstats: 13b. module is a statistics
browser for reading and examining profile dumps.  It has a simple
line-oriented interface (implemented using *note cmd: 61.) and
interactive help.


File: python.info,  Node: What Is Deterministic Profiling?,  Next: Reference Manual -- profile and cProfile,  Prev: Instant User's Manual,  Up: The Python Profilers

5.26.4.3 What Is Deterministic Profiling?
.........................................

_Deterministic profiling_ is meant to reflect the fact that all
_function call_, _function return_, and _exception_ events are
monitored, and precise timings are made for the intervals between these
events (during which time the user's code is executing).  In contrast,
_statistical profiling_ (which is not done by this module) randomly
samples the effective instruction pointer, and deduces where time is
being spent.  The latter technique traditionally involves less overhead
(as the code does not need to be instrumented), but provides only
relative indications of where time is being spent.

  In Python, since there is an interpreter active during execution, the
presence of instrumented code is not required to do deterministic
profiling.  Python automatically provides a _hook_ (optional callback)
for each event.  In addition, the interpreted nature of Python tends to
add so much overhead to execution, that deterministic profiling tends
to only add small processing overhead in typical applications.  The
result is that deterministic profiling is not that expensive, yet
provides extensive run time statistics about the execution of a Python
program.

  Call count statistics can be used to identify bugs in code
(surprising counts), and to identify possible inline-expansion points
(high call counts).  Internal time statistics can be used to identify
"hot loops" that should be carefully optimized.  Cumulative time
statistics should be used to identify high level errors in the
selection of algorithms.  Note that the unusual handling of cumulative
times in this profiler allows statistics for recursive implementations
of algorithms to be directly compared to iterative implementations.


File: python.info,  Node: Reference Manual -- profile and cProfile,  Next: Limitations,  Prev: What Is Deterministic Profiling?,  Up: The Python Profilers

5.26.4.4 Reference Manual - `profile' and `cProfile'
....................................................

The primary entry point for the profiler is the global function
`profile.run()' (resp. *note cProfile.run(): 22bb.). It is typically
used to create any profile information.  The reports are formatted and
printed using methods of the class *note pstats.Stats: 22bf.  The
following is a description of all of these standard entry points and
functions.  For a more in-depth view of some of the code, consider
reading the later section on Profiler Extensions, which includes
discussion of how to derive "better" profilers from the classes
presented, or reading the source code for these modules.

 -- Function: cProfile.run (command[, filename])
     This function takes a single argument that can be passed to the
     *note exec: 3f3. statement, and an optional file name.  In all
     cases this routine attempts to *note exec: 3f3. its first
     argument, and gather profiling statistics from the execution. If
     no file name is present, then this function automatically prints a
     simple profiling report, sorted by the standard name string
     (file/line/function-name) that is presented in each line.  The
     following is a typical output from such a call:

               2706 function calls (2004 primitive calls) in 4.504 CPU seconds

         Ordered by: standard name

         ncalls  tottime  percall  cumtime  percall filename:lineno(function)
              2    0.006    0.003    0.953    0.477 pobject.py:75(save_objects)
           43/3    0.533    0.012    0.749    0.250 pobject.py:99(evaluate)
          ...

     The first line indicates that 2706 calls were monitored.  Of those
     calls, 2004 were _primitive_.  We define _primitive_ to mean that
     the call was not induced via recursion. The next line: `Ordered
     by: standard name', indicates that the text string in the far
     right column was used to sort the output. The column headings
     include:

    ncalls
          for the number of calls,

    tottime
          for the total time spent in the given function (and excluding
          time made in calls to sub-functions),

    percall
          is the quotient of `tottime' divided by `ncalls'

    cumtime
          is the total time spent in this and all subfunctions (from
          invocation till exit). This figure is accurate _even_ for
          recursive functions.

    percall
          is the quotient of `cumtime' divided by primitive calls

    filename:lineno(function)
          provides the respective data of each function

     When there are two numbers in the first column (for example,
     `43/3'), then the latter is the number of primitive calls, and the
     former is the actual number of calls.  Note that when the function
     does not recurse, these two values are the same, and only the
     single figure is printed.

 -- Function: cProfile.runctx (command, globals, locals[, filename])
     This function is similar to *note run(): 22bb, with added
     arguments to supply the globals and locals dictionaries for the
     _command_ string.

  Analysis of the profiler data is done using the `Stats' class.

     Note: The `Stats' class is defined in the *note pstats: 13b.
     module.

 -- Class: pstats.Stats (filename[, stream=sys.stdout[, ...]])
     This class constructor creates an instance of a "statistics
     object" from a _filename_ (or set of filenames).  *note Stats:
     22bf. objects are manipulated by methods, in order to print useful
     reports.  You may specify an alternate output stream by giving the
     keyword argument, `stream'.

     The file selected by the above constructor must have been created
     by the corresponding version of *note profile: 13a. or *note
     cProfile: 74.  To be specific, there is _no_ file compatibility
     guaranteed with future versions of this profiler, and there is no
     compatibility with files produced by other profilers.  If several
     files are provided, all the statistics for identical functions will
     be coalesced, so that an overall view of several processes can be
     considered in a single report.  If additional files need to be
     combined with data in an existing *note Stats: 22bf. object, the
     *note add(): 22c1. method can be used.

     Changed in version 2.5: The _stream_ parameter was added.

* Menu:

* The Stats Class::


File: python.info,  Node: The Stats Class,  Up: Reference Manual -- profile and cProfile

5.26.4.5 The `Stats' Class
..........................

*note Stats: 22bf. objects have the following methods:

 -- Method: Stats.strip_dirs ()
     This method for the *note Stats: 22bf. class removes all leading
     path information from file names.  It is very useful in reducing
     the size of the printout to fit within (close to) 80 columns.
     This method modifies the object, and the stripped information is
     lost.  After performing a strip operation, the object is
     considered to have its entries in a "random" order, as it was just
     after object initialization and loading.  If *note strip_dirs():
     22c4. causes two function names to be indistinguishable (they are
     on the same line of the same filename, and have the same function
     name), then the statistics for these two entries are accumulated
     into a single entry.

 -- Method: Stats.add (filename[, ...])
     This method of the *note Stats: 22bf. class accumulates additional
     profiling information into the current profiling object.  Its
     arguments should refer to filenames created by the corresponding
     version of `profile.run()' or *note cProfile.run(): 22bb.
     Statistics for identically named (re: file, line, name) functions
     are automatically accumulated into single function statistics.

 -- Method: Stats.dump_stats (filename)
     Save the data loaded into the *note Stats: 22bf. object to a file
     named _filename_.  The file is created if it does not exist, and
     is overwritten if it already exists.  This is equivalent to the
     method of the same name on the `profile.Profile' and
     `cProfile.Profile' classes.

     New in version 2.3.

 -- Method: Stats.sort_stats (key[, ...])
     This method modifies the *note Stats: 22bf. object by sorting it
     according to the supplied criteria.  The argument is typically a
     string identifying the basis of a sort (example: `'time'' or
     `'name'').

     When more than one key is provided, then additional keys are used
     as secondary criteria when there is equality in all keys selected
     before them.  For example, `sort_stats('name', 'file')' will sort
     all the entries according to their function name, and resolve all
     ties (identical function names) by sorting by file name.

     Abbreviations can be used for any key names, as long as the
     abbreviation is unambiguous.  The following are the keys currently
     defined:

     Valid Arg              Meaning
     -------------------------------------------------- 
     `'calls''              call count
     `'cumulative''         cumulative time
     `'file''               file name
     `'module''             file name
     `'pcalls''             primitive call count
     `'line''               line number
     `'name''               function name
     `'nfl''                name/file/line
     `'stdname''            standard name
     `'time''               internal time

     Note that all sorts on statistics are in descending order (placing
     most time consuming items first), where as name, file, and line
     number searches are in ascending order (alphabetical). The subtle
     distinction between `'nfl'' and `'stdname'' is that the standard
     name is a sort of the name as printed, which means that the
     embedded line numbers get compared in an odd way.  For example,
     lines 3, 20, and 40 would (if the file names were the same) appear
     in the string order 20, 3 and 40.  In contrast, `'nfl'' does a
     numeric compare of the line numbers.  In fact, `sort_stats('nfl')'
     is the same as `sort_stats('name', 'file', 'line')'.

     For backward-compatibility reasons, the numeric arguments `-1',
     `0', `1', and `2' are permitted.  They are interpreted as
     `'stdname'', `'calls'', `'time'', and `'cumulative'' respectively.
     If this old style format (numeric) is used, only one sort key
     (the numeric key) will be used, and additional arguments will be
     silently ignored.


 -- Method: Stats.reverse_order ()
     This method for the *note Stats: 22bf. class reverses the ordering
     of the basic list within the object.  Note that by default
     ascending vs descending order is properly selected based on the
     sort key of choice.


 -- Method: Stats.print_stats ([restriction, ...])
     This method for the *note Stats: 22bf. class prints out a report
     as described in the `profile.run()' definition.

     The order of the printing is based on the last *note sort_stats():
     22c6. operation done on the object (subject to caveats in *note
     add(): 22c1. and *note strip_dirs(): 22c4.).

     The arguments provided (if any) can be used to limit the list down
     to the significant entries.  Initially, the list is taken to be
     the complete set of profiled functions.  Each restriction is
     either an integer (to select a count of lines), or a decimal
     fraction between 0.0 and 1.0 inclusive (to select a percentage of
     lines), or a regular expression (to pattern match the standard
     name that is printed; as of Python 1.5b1, this uses the Perl-style
     regular expression syntax defined by the *note re: 144. module).
     If several restrictions are provided, then they are applied
     sequentially.  For example:

         print_stats(.1, 'foo:')

     would first limit the printing to first 10% of list, and then only
     print functions that were part of filename `.*foo:'.  In contrast,
     the command:

         print_stats('foo:', .1)

     would limit the list to all functions having file names `.*foo:',
     and then proceed to only print the first 10% of them.

 -- Method: Stats.print_callers ([restriction, ...])
     This method for the *note Stats: 22bf. class prints a list of all
     functions that called each function in the profiled database.  The
     ordering is identical to that provided by *note print_stats():
     22c8, and the definition of the restricting argument is also
     identical.  Each caller is reported on its own line.  The format
     differs slightly depending on the profiler that produced the stats:

        * With *note profile: 13a, a number is shown in parentheses
          after each caller to show how many times this specific call
          was made.  For convenience, a second non-parenthesized number
          repeats the cumulative time spent in the function at the
          right.

        * With *note cProfile: 74, each caller is preceded by three
          numbers: the number of times this specific call was made, and
          the total and cumulative times spent in the current function
          while it was invoked by this specific caller.

 -- Method: Stats.print_callees ([restriction, ...])
     This method for the *note Stats: 22bf. class prints a list of all
     function that were called by the indicated function.  Aside from
     this reversal of direction of calls (re: called vs was called by),
     the arguments and ordering are identical to the *note
     print_callers(): 22c9. method.


File: python.info,  Node: Limitations,  Next: Calibration,  Prev: Reference Manual -- profile and cProfile,  Up: The Python Profilers

5.26.4.6 Limitations
....................

One limitation has to do with accuracy of timing information. There is a
fundamental problem with deterministic profilers involving accuracy.
The most obvious restriction is that the underlying "clock" is only
ticking at a rate (typically) of about .001 seconds.  Hence no
measurements will be more accurate than the underlying clock.  If
enough measurements are taken, then the "error" will tend to average
out. Unfortunately, removing this first error induces a second source
of error.

  The second problem is that it "takes a while" from when an event is
dispatched until the profiler's call to get the time actually _gets_
the state of the clock.  Similarly, there is a certain lag when exiting
the profiler event handler from the time that the clock's value was
obtained (and then squirreled away), until the user's code is once
again executing.  As a result, functions that are called many times, or
call many functions, will typically accumulate this error. The error
that accumulates in this fashion is typically less than the accuracy of
the clock (less than one clock tick), but it _can_ accumulate and
become very significant.

  The problem is more important with *note profile: 13a. than with the
lower-overhead *note cProfile: 74.  For this reason, *note profile:
13a. provides a means of calibrating itself for a given platform so
that this error can be probabilistically (on the average) removed.
After the profiler is calibrated, it will be more accurate (in a least
square sense), but it will sometimes produce negative numbers (when
call counts are exceptionally low, and the gods of probability work
against you :-). )  Do _not_ be alarmed by negative numbers in the
profile.  They should _only_ appear if you have calibrated your
profiler, and the results are actually better than without calibration.


File: python.info,  Node: Calibration,  Next: Extensions --- Deriving Better Profilers,  Prev: Limitations,  Up: The Python Profilers

5.26.4.7 Calibration
....................

The profiler of the *note profile: 13a. module subtracts a constant
from each event handling time to compensate for the overhead of calling
the time function, and socking away the results.  By default, the
constant is 0. The following procedure can be used to obtain a better
constant for a given platform (see discussion in section Limitations
above).

    import profile
    pr = profile.Profile()
    for i in range(5):
        print pr.calibrate(10000)

The method executes the number of Python calls given by the argument,
directly and again under the profiler, measuring the time for both. It
then computes the hidden overhead per profiler event, and returns that
as a float.  For example, on an 800 MHz Pentium running Windows 2000,
and using Python's time.clock() as the timer, the magical number is
about 12.5e-6.

  The object of this exercise is to get a fairly consistent result. If
your computer is _very_ fast, or your timer function has poor
resolution, you might have to pass 100000, or even 1000000, to get
consistent results.

  When you have a consistent answer, there are three ways you can use
it: (1)

    import profile

    # 1. Apply computed bias to all Profile instances created hereafter.
    profile.Profile.bias = your_computed_bias

    # 2. Apply computed bias to a specific Profile instance.
    pr = profile.Profile()
    pr.bias = your_computed_bias

    # 3. Specify computed bias in instance constructor.
    pr = profile.Profile(bias=your_computed_bias)

If you have a choice, you are better off choosing a smaller constant,
and then your results will "less often" show up as negative in profile
statistics.

  ---------- Footnotes ----------

  (1) Prior to Python 2.2, it was necessary to edit the profiler source
code to embed the bias as a literal number.  You still can, but that
method is no longer described, because no longer needed.


File: python.info,  Node: Extensions --- Deriving Better Profilers,  Prev: Calibration,  Up: The Python Profilers

5.26.4.8 Extensions -- Deriving Better Profilers
................................................

The `Profile' class of both modules, *note profile: 13a. and *note
cProfile: 74, were written so that derived classes could be developed
to extend the profiler.  The details are not described here, as doing
this successfully requires an expert understanding of how the `Profile'
class works internally.  Study the source code of the module carefully
if you want to pursue this.

  If all you want to do is change how current time is determined (for
example, to force use of wall-clock time or elapsed process time), pass
the timing function you want to the `Profile' class constructor:

    pr = profile.Profile(your_time_func)

The resulting profiler will then call `your_time_func()'.

`profile.Profile'
     `your_time_func()' should return a single number, or a list of
     numbers whose sum is the current time (like what *note os.times():
     1133. returns).  If the function returns a single time number, or
     the list of returned numbers has length 2, then you will get an
     especially fast version of the dispatch routine.

     Be warned that you should calibrate the profiler class for the
     timer function that you choose.  For most machines, a timer that
     returns a lone integer value will provide the best results in
     terms of low overhead during profiling.  (*note os.times(): 1133.
     is _pretty_ bad, as it returns a tuple of floating point values).
     If you want to substitute a better timer in the cleanest fashion,
     derive a class and hardwire a replacement dispatch method that
     best handles your timer call, along with the appropriate
     calibration constant.

`cProfile.Profile'
     `your_time_func()' should return a single number.  If it returns
     plain integers, you can also invoke the class constructor with a
     second argument specifying the real duration of one unit of time.
     For example, if `your_integer_time_func()' returns times measured
     in thousands of seconds, you would construct the `Profile'
     instance as follows:

         pr = profile.Profile(your_integer_time_func, 0.001)

     As the `cProfile.Profile' class cannot be calibrated, custom timer
     functions should be used with care and should be as fast as
     possible.  For the best results with a custom timer, it might be
     necessary to hard-code it in the C source of the internal
     `_lsprof' module.


File: python.info,  Node: hotshot --- High performance logging profiler,  Next: timeit --- Measure execution time of small code snippets,  Prev: The Python Profilers,  Up: Debugging and Profiling

5.26.5 `hotshot' -- High performance logging profiler
-----------------------------------------------------

New in version 2.2.

  This module provides a nicer interface to the `_hotshot' C module.
Hotshot is a replacement for the existing *note profile: 13a. module.
As it's written mostly in C, it should result in a much smaller
performance impact than the existing *note profile: 13a. module.

     Note: The *note hotshot: ea. module focuses on minimizing the
     overhead while profiling, at the expense of long data
     post-processing times. For common usage it is recommended to use
     *note cProfile: 74. instead. *note hotshot: ea. is not maintained
     and might be removed from the standard library in the future.

  Changed in version 2.5: The results should be more meaningful than in
the past: the timing core contained a critical bug.

     Note: The *note hotshot: ea. profiler does not yet work well with
     threads. It is useful to use an unthreaded script to run the
     profiler over the code you're interested in measuring if at all
     possible.

 -- Class: hotshot.Profile (logfile[, lineevents[, linetimings]])
     The profiler object. The argument _logfile_ is the name of a log
     file to use for logged profile data. The argument _lineevents_
     specifies whether to generate events for every source line, or
     just on function call/return. It defaults to `0' (only log
     function call/return). The argument _linetimings_ specifies
     whether to record timing information. It defaults to `1' (store
     timing information).

* Menu:

* Profile Objects::
* Using hotshot data::
* Example Usage::


File: python.info,  Node: Profile Objects,  Next: Using hotshot data,  Up: hotshot --- High performance logging profiler

5.26.5.1 Profile Objects
........................

Profile objects have the following methods:

 -- Method: Profile.addinfo (key, value)
     Add an arbitrary labelled value to the profile output.

 -- Method: Profile.close ()
     Close the logfile and terminate the profiler.

 -- Method: Profile.fileno ()
     Return the file descriptor of the profiler's log file.

 -- Method: Profile.run (cmd)
     Profile an *note exec: 3f3.-compatible string in the script
     environment. The globals from the *note __main__: 2. module are
     used as both the globals and locals for the script.

 -- Method: Profile.runcall (func, *args, **keywords)
     Profile a single call of a callable. Additional positional and
     keyword arguments may be passed along; the result of the call is
     returned, and exceptions are allowed to propagate cleanly, while
     ensuring that profiling is disabled on the way out.

 -- Method: Profile.runctx (cmd, globals, locals)
     Evaluate an *note exec: 3f3.-compatible string in a specific
     environment. The string is compiled before profiling begins.

 -- Method: Profile.start ()
     Start the profiler.

 -- Method: Profile.stop ()
     Stop the profiler.


File: python.info,  Node: Using hotshot data,  Next: Example Usage,  Prev: Profile Objects,  Up: hotshot --- High performance logging profiler

5.26.5.2 Using hotshot data
...........................

New in version 2.2.

  This module loads hotshot profiling data into the standard *note
pstats: 13b. Stats objects.

 -- Function: hotshot.stats.load (filename)
     Load hotshot data from _filename_. Returns an instance of the
     *note pstats.Stats: 22bf. class.

See also
........

Module *note profile: 13a.
     The *note profile: 13a. module's `Stats' class


File: python.info,  Node: Example Usage,  Prev: Using hotshot data,  Up: hotshot --- High performance logging profiler

5.26.5.3 Example Usage
......................

Note that this example runs the Python "benchmark" pystones.  It can
take some time to run, and will produce large output files.

    >>> import hotshot, hotshot.stats, test.pystone
    >>> prof = hotshot.Profile("stones.prof")
    >>> benchtime, stones = prof.runcall(test.pystone.pystones)
    >>> prof.close()
    >>> stats = hotshot.stats.load("stones.prof")
    >>> stats.strip_dirs()
    >>> stats.sort_stats('time', 'calls')
    >>> stats.print_stats(20)
             850004 function calls in 10.090 CPU seconds

       Ordered by: internal time, call count

       ncalls  tottime  percall  cumtime  percall filename:lineno(function)
            1    3.295    3.295   10.090   10.090 pystone.py:79(Proc0)
       150000    1.315    0.000    1.315    0.000 pystone.py:203(Proc7)
        50000    1.313    0.000    1.463    0.000 pystone.py:229(Func2)
     .
     .
     .



File: python.info,  Node: timeit --- Measure execution time of small code snippets,  Next: trace --- Trace or track Python statement execution,  Prev: hotshot --- High performance logging profiler,  Up: Debugging and Profiling

5.26.6 `timeit' -- Measure execution time of small code snippets
----------------------------------------------------------------

New in version 2.3.

  This module provides a simple way to time small bits of Python code.
It has both command line as well as callable interfaces.  It avoids a
number of common traps for measuring execution times.  See also Tim
Peters' introduction to the "Algorithms" chapter in the Python
Cookbook, published by O'Reilly.

  The module defines the following public class:

 -- Class: timeit.Timer ([stmt='pass'[, setup='pass'[, timer=<timer
          function>]]])
     Class for timing execution speed of small code snippets.

     The constructor takes a statement to be timed, an additional
     statement used for setup, and a timer function.  Both statements
     default to `'pass''; the timer function is platform-dependent (see
     the module doc string).  _stmt_ and _setup_ may also contain
     multiple statements separated by `;' or newlines, as long as they
     don't contain multi-line string literals.

     To measure the execution time of the first statement, use the
     *note timeit(): 17c.  method.  The *note repeat(): 22e5. method is
     a convenience to call *note timeit(): 17c.  multiple times and
     return a list of results.

     Changed in version 2.6: The _stmt_ and _setup_ parameters can now
     also take objects that are callable without arguments. This will
     embed calls to them in a timer function that will then be executed
     by *note timeit(): 17c.  Note that the timing overhead is a little
     larger in this case because of the extra function calls.

 -- Method: Timer.print_exc ([file=None])
     Helper to print a traceback from the timed code.

     Typical use:

         t = Timer(...)       # outside the try/except
         try:
             t.timeit(...)    # or t.repeat(...)
         except:
             t.print_exc()

     The advantage over the standard traceback is that source lines in
     the compiled template will be displayed. The optional _file_
     argument directs where the traceback is sent; it defaults to
     `sys.stderr'.

 -- Method: Timer.repeat ([repeat=3[, number=1000000]])
     Call *note timeit(): 17c. a few times.

     This is a convenience function that calls the *note timeit(): 17c.
     repeatedly, returning a list of results.  The first argument
     specifies how many times to call *note timeit(): 17c.  The second
     argument specifies the _number_ argument for *note timeit(): 17c.

          Note: It's tempting to calculate mean and standard deviation
          from the result vector and report these.  However, this is
          not very useful.  In a typical case, the lowest value gives a
          lower bound for how fast your machine can run the given code
          snippet; higher values in the result vector are typically not
          caused by variability in Python's speed, but by other
          processes interfering with your timing accuracy.  So the
          *note min(): 221. of the result is probably the only number
          you should be interested in.  After that, you should look at
          the entire vector and apply common sense rather than
          statistics.

 -- Method: Timer.timeit ([number=1000000])
     Time _number_ executions of the main statement. This executes the
     setup statement once, and then returns the time it takes to
     execute the main statement a number of times, measured in seconds
     as a float.  The argument is the number of times through the loop,
     defaulting to one million.  The main statement, the setup
     statement and the timer function to be used are passed to the
     constructor.

          Note: By default, *note timeit(): 17c. temporarily turns off
          *note garbage collection: 5ea.  during the timing.  The
          advantage of this approach is that it makes independent
          timings more comparable.  This disadvantage is that GC may be
          an important component of the performance of the function
          being measured.  If so, GC can be re-enabled as the first
          statement in the _setup_ string.  For example:

              timeit.Timer('for i in xrange(10): oct(i)', 'gc.enable()').timeit()



  Starting with version 2.6, the module also defines two convenience
functions:

 -- Function: timeit.repeat (stmt[, setup[, timer[, repeat=3[,
          number=1000000]]]])
     Create a *note Timer: 22e4. instance with the given statement,
     setup code and timer function and run its *note repeat(): 22e5.
     method with the given repeat count and _number_ executions.

     New in version 2.6.

 -- Function: timeit.timeit (stmt[, setup[, timer[, number=1000000]]])
     Create a *note Timer: 22e4. instance with the given statement,
     setup code and timer function and run its *note timeit(): 17c.
     method with _number_ executions.

     New in version 2.6.

* Menu:

* Command Line Interface::
* Examples: Examples<16>.


File: python.info,  Node: Command Line Interface,  Next: Examples<16>,  Up: timeit --- Measure execution time of small code snippets

5.26.6.1 Command Line Interface
...............................

When called as a program from the command line, the following form is
used:

    python -m timeit [-n N] [-r N] [-s S] [-t] [-c] [-h] [statement ...]

Where the following options are understood:

 -- Program Option: -n N, -number=N
     how many times to execute 'statement'

 -- Program Option: -r N, -repeat=N
     how many times to repeat the timer (default 3)

 -- Program Option: -s S, -setup=S
     statement to be executed once initially (default `pass')

 -- Program Option: -t, -time
     use *note time.time(): 450. (default on all platforms but Windows)

 -- Program Option: -c, -clock
     use *note time.clock(): 119d. (default on Windows)

 -- Program Option: -v, -verbose
     print raw timing results; repeat for more digits precision

 -- Program Option: -h, -help
     print a short usage message and exit

  A multi-line statement may be given by specifying each line as a
separate statement argument; indented lines are possible by enclosing
an argument in quotes and using leading spaces.  Multiple *note -s:
22ed. options are treated similarly.

  If *note -n: 22eb. is not given, a suitable number of loops is
calculated by trying successive powers of 10 until the total time is at
least 0.2 seconds.

  The default timer function is platform dependent.  On Windows, *note
time.clock(): 119d. has microsecond granularity but *note time.time():
450.'s granularity is 1/60th of a second; on Unix, *note time.clock():
119d. has 1/100th of a second granularity and *note time.time(): 450.
is much more precise.  On either platform, the default timer functions
measure wall clock time, not the CPU time.  This means that other
processes running on the same computer may interfere with the timing.
The best thing to do when accurate timing is necessary is to repeat the
timing a few times and use the best time.  The *note -r: 22ec. option
is good for this; the default of 3 repetitions is probably enough in
most cases.  On Unix, you can use *note time.clock(): 119d. to measure
CPU time.

     Note: There is a certain baseline overhead associated with
     executing a pass statement.  The code here doesn't try to hide it,
     but you should be aware of it.  The baseline overhead can be
     measured by invoking the program without arguments.

  The baseline overhead differs between Python versions!  Also, to
fairly compare older Python versions to Python 2.3, you may want to use
Python's `-O' option for the older versions to avoid timing
`SET_LINENO' instructions.


File: python.info,  Node: Examples<16>,  Prev: Command Line Interface,  Up: timeit --- Measure execution time of small code snippets

5.26.6.2 Examples
.................

Here are two example sessions (one using the command line, one using
the module interface) that compare the cost of using *note hasattr():
31f. vs.  *note try: 384./*note except: 386. to test for missing and
present object attributes.

    % timeit.py 'try:' '  str.__nonzero__' 'except AttributeError:' '  pass'
    100000 loops, best of 3: 15.7 usec per loop
    % timeit.py 'if hasattr(str, "__nonzero__"): pass'
    100000 loops, best of 3: 4.26 usec per loop
    % timeit.py 'try:' '  int.__nonzero__' 'except AttributeError:' '  pass'
    1000000 loops, best of 3: 1.43 usec per loop
    % timeit.py 'if hasattr(int, "__nonzero__"): pass'
    100000 loops, best of 3: 2.23 usec per loop


    >>> import timeit
    >>> s = """\
    ... try:
    ...     str.__nonzero__
    ... except AttributeError:
    ...     pass
    ... """
    >>> t = timeit.Timer(stmt=s)
    >>> print "%.2f usec/pass" % (1000000 * t.timeit(number=100000)/100000)
    17.09 usec/pass
    >>> s = """\
    ... if hasattr(str, '__nonzero__'): pass
    ... """
    >>> t = timeit.Timer(stmt=s)
    >>> print "%.2f usec/pass" % (1000000 * t.timeit(number=100000)/100000)
    4.85 usec/pass
    >>> s = """\
    ... try:
    ...     int.__nonzero__
    ... except AttributeError:
    ...     pass
    ... """
    >>> t = timeit.Timer(stmt=s)
    >>> print "%.2f usec/pass" % (1000000 * t.timeit(number=100000)/100000)
    1.97 usec/pass
    >>> s = """\
    ... if hasattr(int, '__nonzero__'): pass
    ... """
    >>> t = timeit.Timer(stmt=s)
    >>> print "%.2f usec/pass" % (1000000 * t.timeit(number=100000)/100000)
    3.15 usec/pass

To give the *note timeit: 17c. module access to functions you define,
you can pass a `setup' parameter which contains an import statement:

    def test():
        "Stupid test function"
        L = []
        for i in range(100):
            L.append(i)

    if __name__=='__main__':
        from timeit import Timer
        t = Timer("test()", "from __main__ import test")
        print t.timeit()



File: python.info,  Node: trace --- Trace or track Python statement execution,  Prev: timeit --- Measure execution time of small code snippets,  Up: Debugging and Profiling

5.26.7 `trace' -- Trace or track Python statement execution
-----------------------------------------------------------

The *note trace: 181. module allows you to trace program execution,
generate annotated statement coverage listings, print caller/callee
relationships and list functions executed during a program run.  It can
be used in another program or from the command line.

See also
........

Latest version of the trace module Python source code(1)

* Menu:

* Command-Line Usage::
* Programmatic Interface::

Command-Line Usage

* Main options::
* Modifiers::
* Filters::

  ---------- Footnotes ----------

  (1)
http://svn.python.org/view/python/branches/release27-maint/Lib/trace.py?view=markup


File: python.info,  Node: Command-Line Usage,  Next: Programmatic Interface,  Up: trace --- Trace or track Python statement execution

5.26.7.1 Command-Line Usage
...........................

The *note trace: 181. module can be invoked from the command line.  It
can be as simple as

    python -m trace --count -C . somefile.py ...

The above will execute `somefile.py' and generate annotated listings of
all Python modules imported during the execution into the current
directory.

 -- Program Option: -help
     Display usage and exit.

 -- Program Option: -version
     Display the version of the module and exit.

* Menu:

* Main options::
* Modifiers::
* Filters::


File: python.info,  Node: Main options,  Next: Modifiers,  Up: Command-Line Usage

5.26.7.2 Main options
.....................

At least one of the following options must be specified when invoking
*note trace: 181.  The *note -listfuncs: 22fa. option is mutually
exclusive with the *note -trace: 22fb. and *note -counts: 22fc. options
. When *note -listfuncs: 22fa. is provided, neither *note -counts:
22fc. nor *note -trace: 22fb. are accepted, and vice versa.

 -- Program Option: -c, -count
     Produce a set of annotated listing files upon program completion
     that shows how many times each statement was executed.  See also
     *note -coverdir: 22fd, *note -file: 22fe. and *note -no-report:
     22ff. below.

 -- Program Option: -t, -trace
     Display lines as they are executed.

 -- Program Option: -l, -listfuncs
     Display the functions executed by running the program.

 -- Program Option: -r, -report
     Produce an annotated list from an earlier program run that used the
     *note -count: 22fc. and *note -file: 22fe. option.  This does not
     execute any code.

 -- Program Option: -T, -trackcalls
     Display the calling relationships exposed by running the program.


File: python.info,  Node: Modifiers,  Next: Filters,  Prev: Main options,  Up: Command-Line Usage

5.26.7.3 Modifiers
..................

 -- Program Option: -f, -file=<file>
     Name of a file to accumulate counts over several tracing runs.
     Should be used with the *note -count: 22fc. option.

 -- Program Option: -C, -coverdir=<dir>
     Directory where the report files go.  The coverage report for
     `package.module' is written to file
     `_dir_/_package_/_module_.cover'.

 -- Program Option: -m, -missing
     When generating annotated listings, mark lines which were not
     executed with `>>>>>>'.

 -- Program Option: -s, -summary
     When using *note -count: 22fc. or *note -report: 2300, write a
     brief summary to stdout for each file processed.

 -- Program Option: -R, -no-report
     Do not generate annotated listings.  This is useful if you intend
     to make several runs with *note -count: 22fc, and then produce a
     single set of annotated listings at the end.

 -- Program Option: -g, -timing
     Prefix each line with the time since the program started.  Only
     used while tracing.


File: python.info,  Node: Filters,  Prev: Modifiers,  Up: Command-Line Usage

5.26.7.4 Filters
................

These options may be repeated multiple times.

 -- Program Option: -ignore-module=<mod>
     Ignore each of the given module names and its submodules (if it is
     a package).  The argument can be a list of names separated by a
     comma.

 -- Program Option: -ignore-dir=<dir>
     Ignore all modules and packages in the named directory and
     subdirectories.  The argument can be a list of directories
     separated by *note os.pathsep: 62a.


File: python.info,  Node: Programmatic Interface,  Prev: Command-Line Usage,  Up: trace --- Trace or track Python statement execution

5.26.7.5 Programmatic Interface
...............................

 -- Class: trace.Trace ([count=1[, trace=1[, countfuncs=0[,
          countcallers=0[, ignoremods=()[, ignoredirs=()[,
          infile=None[, outfile=None[, timing=False]]]]]]]]])
     Create an object to trace execution of a single statement or
     expression.  All parameters are optional.  _count_ enables
     counting of line numbers.  _trace_ enables line execution tracing.
     _countfuncs_ enables listing of the functions called during the
     run.  _countcallers_ enables call relationship tracking.
     _ignoremods_ is a list of modules or packages to ignore.
     _ignoredirs_ is a list of directories whose modules or packages
     should be ignored.  _infile_ is the name of the file from which to
     read stored count information.  _outfile_ is the name of the file
     in which to write updated count information.  _timing_ enables a
     timestamp relative to when tracing was started to be displayed.

           -- Method: run (cmd)
               Execute the command and gather statistics from the
               execution with the current tracing parameters.  _cmd_
               must be a string or code object, suitable for passing
               into `exec()'.

           -- Method: runctx (cmd[, globals=None[, locals=None]])
               Execute the command and gather statistics from the
               execution with the current tracing parameters, in the
               defined global and local environments.  If not defined,
               _globals_ and _locals_ default to empty dictionaries.

           -- Method: runfunc (func, *args, **kwds)
               Call _func_ with the given arguments under control of
               the *note Trace: 230b.  object with the current tracing
               parameters.

           -- Method: results ()
               Return a *note CoverageResults: 2310. object that
               contains the cumulative results of all previous calls to
               `run', `runctx' and `runfunc' for the given *note Trace:
               230b. instance.  Does not reset the accumulated trace
               results.

 -- Class: trace.CoverageResults
     A container for coverage results, created by *note
     Trace.results(): 230f.  Should not be created directly by the user.

           -- Method: update (other)
               Merge in data from another *note CoverageResults: 2310.
               object.

           -- Method: write_results ([show_missing=True[,
                    summary=False[, coverdir=None]]])
               Write coverage results.  Set _show_missing_ to show
               lines that had no hits.  Set _summary_ to include in the
               output the coverage summary per module.  _coverdir_
               specifies the directory into which the coverage result
               files will be output.  If `None', the results for each
               source file are placed in its directory.

A simple example demonstrating the use of the programmatic interface:

    import sys
    import trace

    # create a Trace object, telling it what to ignore, and whether to
    # do tracing or line-counting or both.
    tracer = trace.Trace(
        ignoredirs=[sys.prefix, sys.exec_prefix],
        trace=0,
        count=1)

    # run the new command using the given tracer
    tracer.run('main()')

    # make a report, placing output in /tmp
    r = tracer.results()
    r.write_results(show_missing=True, coverdir="/tmp")



File: python.info,  Node: Python Runtime Services,  Next: Custom Python Interpreters,  Prev: Debugging and Profiling,  Up: The Python Standard Library

5.27 Python Runtime Services
============================

The modules described in this chapter provide a wide range of services
related to the Python interpreter and its interaction with its
environment.  Here's an overview:

* Menu:

* sys: sys --- System-specific parameters and functions. System-specific parameters and functions
* sysconfig: sysconfig --- Provide access to Python's configuration information. Provide access to Python's configuration information
* __builtin__: __builtin__ --- Built-in objects. Built-in objects
* future_builtins: future_builtins --- Python 3 builtins. Python 3 builtins
* __main__: __main__ --- Top-level script environment. Top-level script environment
* warnings: warnings --- Warning control. Warning control
* contextlib: contextlib --- Utilities for with-statement contexts. Utilities for with-statement contexts
* abc: abc --- Abstract Base Classes. Abstract Base Classes
* atexit: atexit --- Exit handlers. Exit handlers
* traceback: traceback --- Print or retrieve a stack traceback. Print or retrieve a stack traceback
* __future__: __future__ --- Future statement definitions. Future statement definitions
* gc: gc --- Garbage Collector interface. Garbage Collector interface
* inspect: inspect --- Inspect live objects. Inspect live objects
* site: site --- Site-specific configuration hook. Site-specific configuration hook
* user: user --- User-specific configuration hook. User-specific configuration hook
* fpectl: fpectl --- Floating point exception control. Floating point exception control
* distutils: distutils --- Building and installing Python modules. Building and installing Python modules


File: python.info,  Node: sys --- System-specific parameters and functions,  Next: sysconfig --- Provide access to Python's configuration information,  Up: Python Runtime Services

5.27.1 `sys' -- System-specific parameters and functions
--------------------------------------------------------

This module provides access to some variables used or maintained by the
interpreter and to functions that interact strongly with the
interpreter. It is always available.

 -- Data: sys.argv
     The list of command line arguments passed to a Python script.
     `argv[0]' is the script name (it is operating system dependent
     whether this is a full pathname or not).  If the command was
     executed using the *note -c: 277. command line option to the
     interpreter, `argv[0]' is set to the string `'-c''.  If no script
     name was passed to the Python interpreter, `argv[0]' is the empty
     string.

     To loop over the standard input, or the list of files given on the
     command line, see the *note fileinput: cd. module.

 -- Data: sys.byteorder
     An indicator of the native byte order.  This will have the value
     `'big'' on big-endian (most-significant byte first) platforms, and
     `'little'' on little-endian (least-significant byte first)
     platforms.

     New in version 2.0.

 -- Data: sys.subversion
     A triple (repo, branch, version) representing the Subversion
     information of the Python interpreter. _repo_ is the name of the
     repository, `'CPython''.  _branch_ is a string of one of the forms
     `'trunk'', `'branches/name'' or `'tags/name''. _version_ is the
     output of `svnversion', if the interpreter was built from a
     Subversion checkout; it contains the revision number (range) and
     possibly a trailing 'M' if there were local modifications. If the
     tree was exported (or svnversion was not available), it is the
     revision of `Include/patchlevel.h' if the branch is a tag.
     Otherwise, it is `None'.

     New in version 2.5.

 -- Data: sys.builtin_module_names
     A tuple of strings giving the names of all modules that are
     compiled into this Python interpreter.  (This information is not
     available in any other way -- `modules.keys()' only lists the
     imported modules.)

 -- Function: sys.call_tracing (func, args)
     Call `func(*args)', while tracing is enabled.  The tracing state
     is saved, and restored afterwards.  This is intended to be called
     from a debugger from a checkpoint, to recursively debug some other
     code.

 -- Data: sys.copyright
     A string containing the copyright pertaining to the Python
     interpreter.

 -- Function: sys._clear_type_cache ()
     Clear the internal type cache. The type cache is used to speed up
     attribute and method lookups. Use the function _only_ to drop
     unnecessary references during reference leak debugging.

     This function should be used for internal and specialized purposes
     only.

     New in version 2.6.

 -- Function: sys._current_frames ()
     Return a dictionary mapping each thread's identifier to the
     topmost stack frame currently active in that thread at the time
     the function is called. Note that functions in the *note
     traceback: 182. module can build the call stack given such a frame.

     This is most useful for debugging deadlock:  this function does
     not require the deadlocked threads' cooperation, and such threads'
     call stacks are frozen for as long as they remain deadlocked.  The
     frame returned for a non-deadlocked thread may bear no
     relationship to that thread's current activity by the time calling
     code examines the frame.

     This function should be used for internal and specialized purposes
     only.

     New in version 2.5.

 -- Data: sys.dllhandle
     Integer specifying the handle of the Python DLL. Availability:
     Windows.

 -- Function: sys.displayhook (value)
     If _value_ is not `None', this function prints it to `sys.stdout',
     and saves it in `__builtin__._'.

     `sys.displayhook' is called on the result of evaluating an *note
     expression: 231e.  entered in an interactive Python session.  The
     display of these values can be customized by assigning another
     one-argument function to `sys.displayhook'.

 -- Function: sys.excepthook (type, value, traceback)
     This function prints out a given traceback and exception to
     `sys.stderr'.

     When an exception is raised and uncaught, the interpreter calls
     `sys.excepthook' with three arguments, the exception class,
     exception instance, and a traceback object.  In an interactive
     session this happens just before control is returned to the
     prompt; in a Python program this happens just before the program
     exits.  The handling of such top-level exceptions can be
     customized by assigning another three-argument function to
     `sys.excepthook'.

 -- Data: sys.__displayhook__
 -- Data: sys.__excepthook__
     These objects contain the original values of `displayhook' and
     `excepthook' at the start of the program.  They are saved so that
     `displayhook' and `excepthook' can be restored in case they happen
     to get replaced with broken objects.

 -- Function: sys.exc_info ()
     This function returns a tuple of three values that give
     information about the exception that is currently being handled.
     The information returned is specific both to the current thread
     and to the current stack frame.  If the current stack frame is not
     handling an exception, the information is taken from the calling
     stack frame, or its caller, and so on until a stack frame is found
     that is handling an exception.  Here, "handling an exception" is
     defined as "executing or having executed an except clause."  For
     any stack frame, only information about the most recently handled
     exception is accessible.

     If no exception is being handled anywhere on the stack, a tuple
     containing three `None' values is returned.  Otherwise, the values
     returned are `(type, value, traceback)'.  Their meaning is: _type_
     gets the exception type of the exception being handled (a class
     object); _value_ gets the exception parameter (its _associated
     value_ or the second argument to *note raise: 593, which is always
     a class instance if the exception type is a class object);
     _traceback_ gets a traceback object (see the Reference Manual)
     which encapsulates the call stack at the point where the exception
     originally occurred.

     If *note exc_clear(): 453. is called, this function will return
     three `None' values until either another exception is raised in
     the current thread or the execution stack returns to a frame where
     another exception is being handled.

          Warning: Assigning the _traceback_ return value to a local
          variable in a function that is handling an exception will
          cause a circular reference.  This will prevent anything
          referenced by a local variable in the same function or by the
          traceback from being garbage collected.  Since most functions
          don't need access to the traceback, the best solution is to
          use something like `exctype, value = sys.exc_info()[:2]' to
          extract only the exception type and value.  If you do need
          the traceback, make sure to delete it after use (best done
          with a *note try: 384 ... *note finally: 385. statement) or
          to call *note exc_info(): 2e4. in a function that does not
          itself handle an exception.

          Note: Beginning with Python 2.2, such cycles are
          automatically reclaimed when garbage collection is enabled
          and they become unreachable, but it remains more efficient to
          avoid creating cycles.

 -- Function: sys.exc_clear ()
     This function clears all information relating to the current or
     last exception that occurred in the current thread.  After calling
     this function, *note exc_info(): 2e4. will return three `None'
     values until another exception is raised in the current thread or
     the execution stack returns to a frame where another exception is
     being handled.

     This function is only needed in only a few obscure situations.
     These include logging and error handling systems that report
     information on the last or current exception.  This function can
     also be used to try to free resources and trigger object
     finalization, though no guarantee is made as to what objects will
     be freed, if any.

     New in version 2.3.

 -- Data: sys.exc_type
 -- Data: sys.exc_value
 -- Data: sys.exc_traceback
     Deprecated since version 1.5: Use *note exc_info(): 2e4. instead.

     Since they are global variables, they are not specific to the
     current thread, so their use is not safe in a multi-threaded
     program.  When no exception is being handled, `exc_type' is set to
     `None' and the other two are undefined.

 -- Data: sys.exec_prefix
     A string giving the site-specific directory prefix where the
     platform-dependent Python files are installed; by default, this is
     also `'/usr/local''.  This can be set at build time with the
     `--exec-prefix' argument to the *configure* script.  Specifically,
     all configuration files (e.g. the `pyconfig.h' header file) are
     installed in the directory `exec_prefix +
     '/lib/pythonversion/config'', and shared library modules are
     installed in `exec_prefix + '/lib/pythonversion/lib-dynload'',
     where _version_ is equal to `version[:3]'.

 -- Data: sys.executable
     A string giving the name of the executable binary for the Python
     interpreter, on systems where this makes sense.

 -- Function: sys.exit ([arg])
     Exit from Python.  This is implemented by raising the *note
     SystemExit: 321.  exception, so cleanup actions specified by
     finally clauses of *note try: 384.  statements are honored, and it
     is possible to intercept the exit attempt at an outer level.

     The optional argument _arg_ can be an integer giving the exit
     status (defaulting to zero), or another type of object.  If it is
     an integer, zero is considered "successful termination" and any
     nonzero value is considered "abnormal termination" by shells and
     the like.  Most systems require it to be in the range 0-127, and
     produce undefined results otherwise.  Some systems have a
     convention for assigning specific meanings to specific exit codes,
     but these are generally underdeveloped; Unix programs generally
     use 2 for command line syntax errors and 1 for all other kind of
     errors.  If another type of object is passed, `None' is equivalent
     to passing zero, and any other object is printed to *note stderr:
     620. and results in an exit code of 1.  In particular,
     `sys.exit("some error message")' is a quick way to exit a program
     when an error occurs.

     Since *note exit(): 862. ultimately "only" raises an exception, it
     will only exit the process when called from the main thread, and
     the exception is not intercepted.

 -- Data: sys.exitfunc
     This value is not actually defined by the module, but can be set
     by the user (or by a program) to specify a clean-up action at
     program exit.  When set, it should be a parameterless function.
     This function will be called when the interpreter exits.  Only one
     function may be installed in this way; to allow multiple functions
     which will be called at termination, use the *note atexit: 12.
     module.

          Note: The exit function is not called when the program is
          killed by a signal, when a Python fatal internal error is
          detected, or when `os._exit()' is called.

     Deprecated since version 2.4: Use *note atexit: 12. instead.

 -- Data: sys.flags
     The struct sequence _flags_ exposes the status of command line
     flags. The attributes are read only.

     attribute                         flag
     -------------------------------------------------------------------------- 
     `debug'                           *note -d: 615.
     `py3k_warning'                    *note -3: 1c7.
     `division_warning'                *note -Q: 1c8.
     `division_new'                    *note -Qnew: 1c8.
     *note inspect: f9.                *note -i: 465.
     `interactive'                     *note -i: 465.
     `optimize'                        *note -O: 442. or *note -OO: 568.
     *note dont_write_bytecode: 2323.  *note -B: 332.
     `no_user_site'                    *note -s: 2f0.
     `no_site'                         *note -S: 61a.
     `ignore_environment'              *note -E: 617.
     `tabcheck'                        *note -t: 3bf. or *note -tt: 3bf.
     `verbose'                         *note -v: 3a2.
     *note unicode: 1f2.               *note -U: 627.
     `bytes_warning'                   `-b'

     New in version 2.6.

 -- Data: sys.float_info
     A structseq holding information about the float type. It contains
     low level information about the precision and internal
     representation.  The values correspond to the various
     floating-point constants defined in the standard header file
     `float.h' for the 'C' programming language; see section 5.2.4.2.2
     of the 1999 ISO/IEC C standard *note [C99]: 2324, 'Characteristics
     of floating types', for details.

     attribute                 float.h macro        explanation
     ------------------------------------------------------------------------------------------------------ 
     `epsilon'                 DBL_EPSILON          difference between 1 and the least value greater than
                                                    1 that is representable as a float
     `dig'                     DBL_DIG              maximum number of decimal digits that can be
                                                    faithfully represented in a float;  see below
     `mant_dig'                DBL_MANT_DIG         float precision: the number of base-`radix' digits in
                                                    the significand of a float
     *note max: 222.           DBL_MAX              maximum representable finite float
     `max_exp'                 DBL_MAX_EXP          maximum integer e such that `radix**(e-1)' is a
                                                    representable finite float
     `max_10_exp'              DBL_MAX_10_EXP       maximum integer e such that `10**e' is in the range
                                                    of representable finite floats
     *note min: 221.           DBL_MIN              minimum positive normalized float
     `min_exp'                 DBL_MIN_EXP          minimum integer e such that `radix**(e-1)' is a
                                                    normalized float
     `min_10_exp'              DBL_MIN_10_EXP       minimum integer e such that `10**e' is a normalized
                                                    float
     `radix'                   FLT_RADIX            radix of exponent representation
     `rounds'                  FLT_ROUNDS           constant representing rounding mode used for
                                                    arithmetic operations

     The attribute `sys.float_info.dig' needs further explanation.  If
     `s' is any string representing a decimal number with at most
     `sys.float_info.dig' significant digits, then converting `s' to a
     float and back again will recover a string representing the same
     decimal value:

         >>> import sys
         >>> sys.float_info.dig
         15
         >>> s = '3.14159265358979'    # decimal string with 15 significant digits
         >>> format(float(s), '.15g')  # convert to float and back -> same value
         '3.14159265358979'

     But for strings with more than `sys.float_info.dig' significant
     digits, this isn't always true:

         >>> s = '9876543211234567'    # 16 significant digits is too many!
         >>> format(float(s), '.16g')  # conversion changes value
         '9876543211234568'

     New in version 2.6.

 -- Data: sys.float_repr_style
     A string indicating how the *note repr(): 146. function behaves for
     floats.  If the string has value `'short'' then for a finite float
     `x', `repr(x)' aims to produce a short string with the property
     that `float(repr(x)) == x'.  This is the usual behaviour in Python
     2.7 and later.  Otherwise, `float_repr_style' has value `'legacy''
     and `repr(x)' behaves in the same way as it did in versions of
     Python prior to 2.7.

     New in version 2.7.

 -- Function: sys.getcheckinterval ()
     Return the interpreter's "check interval"; see *note
     setcheckinterval(): 2325.

     New in version 2.3.

 -- Function: sys.getdefaultencoding ()
     Return the name of the current default string encoding used by the
     Unicode implementation.

     New in version 2.0.

 -- Function: sys.getdlopenflags ()
     Return the current value of the flags that are used for `dlopen()'
     calls.  The flag constants are defined in the *note dl: b5. and
     `DLFCN' modules.  Availability: Unix.

     New in version 2.2.

 -- Function: sys.getfilesystemencoding ()
     Return the name of the encoding used to convert Unicode filenames
     into system file names, or `None' if the system default encoding
     is used. The result value depends on the operating system:

        * On Mac OS X, the encoding is `'utf-8''.

        * On Unix, the encoding is the user's preference according to
          the result of nl_langinfo(CODESET), or `None' if the
          `nl_langinfo(CODESET)' failed.

        * On Windows NT+, file names are Unicode natively, so no
          conversion is performed. *note getfilesystemencoding(): f93.
          still returns `'mbcs'', as this is the encoding that
          applications should use when they explicitly want to convert
          Unicode strings to byte strings that are equivalent when used
          as file names.

        * On Windows 9x, the encoding is `'mbcs''.

     New in version 2.3.

 -- Function: sys.getrefcount (object)
     Return the reference count of the _object_.  The count returned is
     generally one higher than you might expect, because it includes
     the (temporary) reference as an argument to *note getrefcount():
     2326.

 -- Function: sys.getrecursionlimit ()
     Return the current value of the recursion limit, the maximum depth
     of the Python interpreter stack.  This limit prevents infinite
     recursion from causing an overflow of the C stack and crashing
     Python.  It can be set by *note setrecursionlimit(): 4d4.

 -- Function: sys.getsizeof (object[, default])
     Return the size of an object in bytes. The object can be any type
     of object. All built-in objects will return correct results, but
     this does not have to hold true for third-party extensions as it
     is implementation specific.

     If given, _default_ will be returned if the object does not
     provide means to retrieve the size.  Otherwise a *note TypeError:
     215. will be raised.

     *note getsizeof(): 2327. calls the object's `__sizeof__' method
     and adds an additional garbage collector overhead if the object is
     managed by the garbage collector.

     New in version 2.6.

 -- Function: sys._getframe ([depth])
     Return a frame object from the call stack.  If optional integer
     _depth_ is given, return the frame object that many calls below
     the top of the stack.  If that is deeper than the call stack,
     *note ValueError: 233. is raised.  The default for _depth_ is
     zero, returning the frame at the top of the call stack.

     *CPython implementation detail:* This function should be used for
     internal and specialized purposes only.  It is not guaranteed to
     exist in all implementations of Python.

 -- Function: sys.getprofile ()
     Get the profiler function as set by *note setprofile(): 48c.

     New in version 2.6.

 -- Function: sys.gettrace ()
     Get the trace function as set by *note settrace(): 48d.

     *CPython implementation detail:* The *note gettrace(): 347.
     function is intended only for implementing debuggers, profilers,
     coverage tools and the like.  Its behavior is part of the
     implementation platform, rather than part of the language
     definition, and thus may not be available in all Python
     implementations.

     New in version 2.6.

 -- Function: sys.getwindowsversion ()
     Return a named tuple describing the Windows version currently
     running.  The named elements are _major_, _minor_, _build_,
     _platform_, _service_pack_, _service_pack_minor_,
     _service_pack_major_, _suite_mask_, and _product_type_.
     _service_pack_ contains a string while all other values are
     integers. The components can also be accessed by name, so
     `sys.getwindowsversion()[0]' is equivalent to
     `sys.getwindowsversion().major'. For compatibility with prior
     versions, only the first 5 elements are retrievable by indexing.

     _platform_ may be one of the following values:

     Constant                                      Platform
     ---------------------------------------------------------------------------- 
     `0 (VER_PLATFORM_WIN32s)'                     Win32s on Windows 3.1
     `1 (VER_PLATFORM_WIN32_WINDOWS)'              Windows 95/98/ME
     `2 (VER_PLATFORM_WIN32_NT)'                   Windows NT/2000/XP/x64
     `3 (VER_PLATFORM_WIN32_CE)'                   Windows CE

     _product_type_ may be one of the following values:

     Constant                                    Meaning
     ---------------------------------------------------------------------------------- 
     `1 (VER_NT_WORKSTATION)'                    The system is a workstation.
     `2 (VER_NT_DOMAIN_CONTROLLER)'              The system is a domain controller.
     `3 (VER_NT_SERVER)'                         The system is a server, but not a
                                                 domain controller.

     This function wraps the Win32 `GetVersionEx()' function; see the
     Microsoft documentation on `OSVERSIONINFOEX()' for more information
     about these fields.

     Availability: Windows.

     New in version 2.3.

     Changed in version 2.7: Changed to a named tuple and added
     _service_pack_minor_, _service_pack_major_, _suite_mask_, and
     _product_type_.

 -- Data: sys.hexversion
     The version number encoded as a single integer.  This is
     guaranteed to increase with each version, including proper support
     for non-production releases.  For example, to test that the Python
     interpreter is at least version 1.5.2, use:

         if sys.hexversion >= 0x010502F0:
             # use some advanced feature
             ...
         else:
             # use an alternative implementation or warn the user
             ...

     This is called `hexversion' since it only really looks meaningful
     when viewed as the result of passing it to the built-in *note
     hex(): 323. function.  The `version_info' value may be used for a
     more human-friendly encoding of the same information.

     The `hexversion' is a 32-bit number with the following layout:

     Bits (big endian order)       Meaning
     ----------------------------------------------------------------------------------- 
     `1-8'                         `PY_MAJOR_VERSION'  (the `2' in `2.1.0a3')
     `9-16'                        `PY_MINOR_VERSION'  (the `1' in `2.1.0a3')
     `17-24'                       `PY_MICRO_VERSION'  (the `0' in `2.1.0a3')
     `25-28'                       `PY_RELEASE_LEVEL'  (`0xA' for alpha, `0xB' for
                                   beta, `0xC' for release candidate and `0xF' for
                                   final)
     `29-32'                       `PY_RELEASE_SERIAL'  (the `3' in `2.1.0a3', zero
                                   for final releases)

     Thus `2.1.0a3' is hexversion `0x020100a3'.

     New in version 1.5.2.

 -- Data: sys.long_info
     A struct sequence that holds information about Python's internal
     representation of integers.  The attributes are read only.

     Attribute                     Explanation
     --------------------------------------------------------------------------------- 
     `bits_per_digit'              number of bits held in each digit.  Python
                                   integers are stored internally in base
                                   `2**long_info.bits_per_digit'
     `sizeof_digit'                size in bytes of the C type used to represent a
                                   digit

     New in version 2.7.

 -- Data: sys.last_type
 -- Data: sys.last_value
 -- Data: sys.last_traceback
     These three variables are not always defined; they are set when an
     exception is not handled and the interpreter prints an error
     message and a stack traceback.  Their intended use is to allow an
     interactive user to import a debugger module and engage in
     post-mortem debugging without having to re-execute the command
     that caused the error.  (Typical use is `import pdb; pdb.pm()' to
     enter the post-mortem debugger; see chapter *note pdb -- The
     Python Debugger: 22a9. for more information.)

     The meaning of the variables is the same as that of the return
     values from *note exc_info(): 2e4. above.  (Since there is only
     one interactive thread, thread-safety is not a concern for these
     variables, unlike for `exc_type' etc.)

 -- Data: sys.maxint
     The largest positive integer supported by Python's regular integer
     type.  This is at least 2**31-1.  The largest negative integer is
     `-maxint-1' -- the asymmetry results from the use of 2's
     complement binary arithmetic.

 -- Data: sys.maxsize
     The largest positive integer supported by the platform's
     Py_ssize_t type, and thus the maximum size lists, strings, dicts,
     and many other containers can have.

 -- Data: sys.maxunicode
     An integer giving the largest supported code point for a Unicode
     character.  The value of this depends on the configuration option
     that specifies whether Unicode characters are stored as UCS-2 or
     UCS-4.

 -- Data: sys.meta_path
     A list of *note finder: 7f7. objects that have their
     `find_module()' methods called to see if one of the objects can
     find the module to be imported. The `find_module()' method is
     called at least with the absolute name of the module being
     imported. If the module to be imported is contained in package
     then the parent package's `__path__' attribute is passed in as a
     second argument. The method returns `None' if the module cannot be
     found, else returns a *note loader: 7f8.

     *note sys.meta_path: 7f6. is searched before any implicit default
     finders or *note sys.path: 60f.

     See PEP 302(1) for the original specification.

 -- Data: sys.modules
     This is a dictionary that maps module names to modules which have
     already been loaded.  This can be manipulated to force reloading
     of modules and other tricks.  Note that removing a module from
     this dictionary is _not_ the same as calling *note reload(): 55f.
     on the corresponding module object.

 -- Data: sys.path
     A list of strings that specifies the search path for modules.
     Initialized from the environment variable *note PYTHONPATH: 564,
     plus an installation-dependent default.

     As initialized upon program startup, the first item of this list,
     `path[0]', is the directory containing the script that was used to
     invoke the Python interpreter.  If the script directory is not
     available (e.g.  if the interpreter is invoked interactively or if
     the script is read from standard input), `path[0]' is the empty
     string, which directs Python to search modules in the current
     directory first.  Notice that the script directory is inserted
     _before_ the entries inserted as a result of *note PYTHONPATH: 564.

     A program is free to modify this list for its own purposes.

     Changed in version 2.3: Unicode strings are no longer ignored.

See also
........

     Module *note site: 159. This describes how to use .pth files to
extend *note sys.path: 60f.

 -- Data: sys.path_hooks
     A list of callables that take a path argument to try to create a
     *note finder: 7f7. for the path. If a finder can be created, it is
     to be returned by the callable, else raise *note ImportError: 35f.

     Originally specified in PEP 302(2).

 -- Data: sys.path_importer_cache
     A dictionary acting as a cache for *note finder: 7f7. objects. The
     keys are paths that have been passed to *note sys.path_hooks: 7f9.
     and the values are the finders that are found. If a path is a
     valid file system path but no explicit finder is found on *note
     sys.path_hooks: 7f9. then `None' is stored to represent the
     implicit default finder should be used. If the path is not an
     existing path then *note imp.NullImporter: 232c. is set.

     Originally specified in PEP 302(3).

 -- Data: sys.platform
     This string contains a platform identifier that can be used to
     append platform-specific components to *note sys.path: 60f, for
     instance.

     For Unix systems, this is the lowercased OS name as returned by
     `uname -s' with the first part of the version as returned by
     `uname -r' appended, e.g. `'sunos5'' or `'linux2'', _at the time
     when Python was built_.  For other systems, the values are:

     System               *note platform: 133. value
     ----------------------------------------------------- 
     Windows              `'win32''
     Windows/Cygwin       `'cygwin''
     Mac OS X             `'darwin''
     OS/2                 `'os2''
     OS/2 EMX             `'os2emx''
     RiscOS               `'riscos''
     AtheOS               `'atheos''


 -- Data: sys.prefix
     A string giving the site-specific directory prefix where the
     platform independent Python files are installed; by default, this
     is the string `'/usr/local''.  This can be set at build time with
     the `--prefix' argument to the *configure* script.  The main
     collection of Python library modules is installed in the directory
     `prefix + '/lib/pythonversion'' while the platform independent
     header files (all except `pyconfig.h') are stored in `prefix +
     '/include/pythonversion'', where _version_ is equal to
     `version[:3]'.

 -- Data: sys.ps1
 -- Data: sys.ps2
     Strings specifying the primary and secondary prompt of the
     interpreter.  These are only defined if the interpreter is in
     interactive mode.  Their initial values in this case are `'>>> ''
     and `'... ''.  If a non-string object is assigned to either
     variable, its *note str(): 1e7. is re-evaluated each time the
     interpreter prepares to read a new interactive command; this can
     be used to implement a dynamic prompt.

 -- Data: sys.py3kwarning
     Bool containing the status of the Python 3.0 warning flag. It's
     `True' when Python is started with the -3 option.  (This should be
     considered read-only; setting it to a different value doesn't have
     an effect on Python 3.0 warnings.)

     New in version 2.6.

 -- Data: sys.dont_write_bytecode
     If this is true, Python won't try to write `.pyc' or `.pyo' files
     on the import of source modules.  This value is initially set to
     `True' or `False' depending on the `-B' command line option and
     the `PYTHONDONTWRITEBYTECODE' environment variable, but you can
     set it yourself to control bytecode file generation.

     New in version 2.6.

 -- Function: sys.setcheckinterval (interval)
     Set the interpreter's "check interval".  This integer value
     determines how often the interpreter checks for periodic things
     such as thread switches and signal handlers.  The default is
     `100', meaning the check is performed every 100 Python virtual
     instructions. Setting it to a larger value may increase
     performance for programs using threads.  Setting it to a value
     `<=' 0 checks every virtual instruction, maximizing responsiveness
     as well as overhead.

 -- Function: sys.setdefaultencoding (name)
     Set the current default string encoding used by the Unicode
     implementation.  If _name_ does not match any available encoding,
     *note LookupError: 859. is raised.  This function is only intended
     to be used by the *note site: 159. module implementation and,
     where needed, by `sitecustomize'.  Once used by the *note site:
     159. module, it is removed from the *note sys: 16e. module's
     namespace.

     New in version 2.0.

 -- Function: sys.setdlopenflags (n)
     Set the flags used by the interpreter for `dlopen()' calls, such
     as when the interpreter loads extension modules.  Among other
     things, this will enable a lazy resolving of symbols when
     importing a module, if called as `sys.setdlopenflags(0)'.  To
     share symbols across extension modules, call as
     `sys.setdlopenflags(dl.RTLD_NOW | dl.RTLD_GLOBAL)'.  Symbolic
     names for the flag modules can be either found in the *note dl:
     b5. module, or in the `DLFCN' module. If `DLFCN' is not available,
     it can be generated from `/usr/include/dlfcn.h' using the *h2py*
     script. Availability: Unix.

     New in version 2.2.

 -- Function: sys.setprofile (profilefunc)
     Set the system's profile function, which allows you to implement a
     Python source code profiler in Python.  See chapter *note The
     Python Profilers: 22b4. for more information on the Python
     profiler.  The system's profile function is called similarly to the
     system's trace function (see *note settrace(): 48d.), but it isn't
     called for each executed line of code (only on call and return,
     but the return event is reported even when an exception has been
     set).  The function is thread-specific, but there is no way for
     the profiler to know about context switches between threads, so it
     does not make sense to use this in the presence of multiple
     threads. Also, its return value is not used, so it can simply
     return `None'.

 -- Function: sys.setrecursionlimit (limit)
     Set the maximum depth of the Python interpreter stack to _limit_.
     This limit prevents infinite recursion from causing an overflow of
     the C stack and crashing Python.

     The highest possible limit is platform-dependent.  A user may need
     to set the limit higher when she has a program that requires deep
     recursion and a platform that supports a higher limit.  This
     should be done with care, because a too-high limit can lead to a
     crash.

 -- Function: sys.settrace (tracefunc)
     Set the system's trace function, which allows you to implement a
     Python source code debugger in Python.  The function is
     thread-specific; for a debugger to support multiple threads, it
     must be registered using *note settrace(): 48d. for each thread
     being debugged.

     Trace functions should have three arguments: _frame_, _event_, and
     _arg_. _frame_ is the current stack frame.  _event_ is a string:
     `'call'', `'line'', `'return'', `'exception'', `'c_call'',
     `'c_return'', or `'c_exception''. _arg_ depends on the event type.

     The trace function is invoked (with _event_ set to `'call'')
     whenever a new local scope is entered; it should return a
     reference to a local trace function to be used that scope, or
     `None' if the scope shouldn't be traced.

     The local trace function should return a reference to itself (or
     to another function for further tracing in that scope), or `None'
     to turn off tracing in that scope.

     The events have the following meaning:

    `'call''
          A function is called (or some other code block entered).  The
          global trace function is called; _arg_ is `None'; the return
          value specifies the local trace function.

    `'line''
          The interpreter is about to execute a new line of code or
          re-execute the condition of a loop.  The local trace function
          is called; _arg_ is `None'; the return value specifies the
          new local trace function.  See `Objects/lnotab_notes.txt' for
          a detailed explanation of how this works.

    `'return''
          A function (or other code block) is about to return.  The
          local trace function is called; _arg_ is the value that will
          be returned, or `None' if the event is caused by an exception
          being raised.  The trace function's return value is ignored.

    `'exception''
          An exception has occurred.  The local trace function is
          called; _arg_ is a tuple `(exception, value, traceback)'; the
          return value specifies the new local trace function.

    `'c_call''
          A C function is about to be called.  This may be an extension
          function or a built-in.  _arg_ is the C function object.

    `'c_return''
          A C function has returned. _arg_ is the C function object.

    `'c_exception''
          A C function has raised an exception.  _arg_ is the C
          function object.

     Note that as an exception is propagated down the chain of callers,
     an `'exception'' event is generated at each level.

     For more information on code and frame objects, refer to *note The
     standard type hierarchy: 6c8.

     *CPython implementation detail:* The *note settrace(): 48d.
     function is intended only for implementing debuggers, profilers,
     coverage tools and the like.  Its behavior is part of the
     implementation platform, rather than part of the language
     definition, and thus may not be available in all Python
     implementations.

 -- Function: sys.settscdump (on_flag)
     Activate dumping of VM measurements using the Pentium timestamp
     counter, if _on_flag_ is true. Deactivate these dumps if _on_flag_
     is off. The function is available only if Python was compiled with
     `--with-tsc'. To understand the output of this dump, read
     `Python/ceval.c' in the Python sources.

     New in version 2.4.

     *CPython implementation detail:* This function is intimately bound
     to CPython implementation details and thus not likely to be
     implemented elsewhere.

 -- Data: sys.stdin
 -- Data: sys.stdout
 -- Data: sys.stderr
     File objects corresponding to the interpreter's standard input,
     output and error streams.  `stdin' is used for all interpreter
     input except for scripts but including calls to *note input():
     3ae. and *note raw_input(): 83a.  `stdout' is used for the output
     of *note print: 4cd. and *note expression: 231e. statements and
     for the prompts of *note input(): 3ae. and *note raw_input(): 83a.
     The interpreter's own prompts and (almost all of) its error
     messages go to `stderr'.  `stdout' and `stderr' needn't be
     built-in file objects: any object is acceptable as long as it has
     a `write()' method that takes a string argument.  (Changing these
     objects doesn't affect the standard I/O streams of processes
     executed by *note os.popen(): 6d7, *note os.system(): 3e9. or the
     `exec*()' family of functions in the *note os: 129. module.)

 -- Data: sys.__stdin__
 -- Data: sys.__stdout__
 -- Data: sys.__stderr__
     These objects contain the original values of `stdin', `stderr' and
     `stdout' at the start of the program.  They are used during
     finalization, and could be useful to print to the actual standard
     stream no matter if the `sys.std*' object has been redirected.

     It can also be used to restore the actual files to known working
     file objects in case they have been overwritten with a broken
     object.  However, the preferred way to do this is to explicitly
     save the previous stream before replacing it, and restore the
     saved object.

 -- Data: sys.tracebacklimit
     When this variable is set to an integer value, it determines the
     maximum number of levels of traceback information printed when an
     unhandled exception occurs.  The default is `1000'.  When set to
     `0' or less, all traceback information is suppressed and only the
     exception type and value are printed.

 -- Data: sys.version
     A string containing the version number of the Python interpreter
     plus additional information on the build number and compiler used.
     This string is displayed when the interactive interpreter is
     started.  Do not extract version information out of it, rather,
     use *note version_info: 2336. and the functions provided by the
     *note platform: 133. module.

 -- Data: sys.api_version
     The C API version for this interpreter.  Programmers may find this
     useful when debugging version conflicts between Python and
     extension modules.

     New in version 2.3.

 -- Data: sys.version_info
     A tuple containing the five components of the version number:
     _major_, _minor_, _micro_, _releaselevel_, and _serial_.  All
     values except _releaselevel_ are integers; the release level is
     `'alpha'', `'beta'', `'candidate'', or `'final''.  The
     `version_info' value corresponding to the Python version 2.0 is
     `(2, 0, 0, 'final', 0)'.  The components can also be accessed by
     name, so `sys.version_info[0]' is equivalent to
     `sys.version_info.major' and so on.

     New in version 2.0.

     Changed in version 2.7: Added named component attributes

 -- Data: sys.warnoptions
     This is an implementation detail of the warnings framework; do not
     modify this value.  Refer to the *note warnings: 194. module for
     more information on the warnings framework.

 -- Data: sys.winver
     The version number used to form registry keys on Windows
     platforms. This is stored as string resource 1000 in the Python
     DLL.  The value is normally the first three characters of *note
     version: 2335.  It is provided in the *note sys: 16e.  module for
     informational purposes; modifying this value has no effect on the
     registry keys used by Python. Availability: Windows.

Citations
.........

(C99) ISO/IEC 9899:1999.  "Programming languages - C."  A public draft
of this standard is available at
<http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1256.pdf> .

  ---------- Footnotes ----------

  (1) http://www.python.org/dev/peps/pep-0302

  (2) http://www.python.org/dev/peps/pep-0302

  (3) http://www.python.org/dev/peps/pep-0302


File: python.info,  Node: sysconfig --- Provide access to Python's configuration information,  Next: __builtin__ --- Built-in objects,  Prev: sys --- System-specific parameters and functions,  Up: Python Runtime Services

5.27.2 `sysconfig' -- Provide access to Python's configuration information
--------------------------------------------------------------------------

New in version 2.7.

  The *note sysconfig: 16f. module provides access to Python's
configuration information like the list of installation paths and the
configuration variables relevant for the current platform.

* Menu:

* Configuration variables::
* Installation paths::
* Other functions::


File: python.info,  Node: Configuration variables,  Next: Installation paths,  Up: sysconfig --- Provide access to Python's configuration information

5.27.2.1 Configuration variables
................................

A Python distribution contains a `Makefile' and a `pyconfig.h' header
file that are necessary to build both the Python binary itself and
third-party C extensions compiled using *note distutils: 86.

  *note sysconfig: 16f. puts all variables found in these files in a
dictionary that can be accessed using *note get_config_vars(): 270. or
*note get_config_var(): 26f.

  Notice that on Windows, it's a much smaller set.

 -- Function: sysconfig.get_config_vars (*args)
     With no arguments, return a dictionary of all configuration
     variables relevant for the current platform.

     With arguments, return a list of values that result from looking
     up each argument in the configuration variable dictionary.

     For each argument, if the value is not found, return `None'.

 -- Function: sysconfig.get_config_var (name)
     Return the value of a single variable _name_. Equivalent to
     `get_config_vars().get(name)'.

     If _name_ is not found, return `None'.

  Example of usage:

    >>> import sysconfig
    >>> sysconfig.get_config_var('Py_ENABLE_SHARED')
    0
    >>> sysconfig.get_config_var('LIBDIR')
    '/usr/local/lib'
    >>> sysconfig.get_config_vars('AR', 'CXX')
    ['ar', 'g++']



File: python.info,  Node: Installation paths,  Next: Other functions,  Prev: Configuration variables,  Up: sysconfig --- Provide access to Python's configuration information

5.27.2.2 Installation paths
...........................

Python uses an installation scheme that differs depending on the
platform and on the installation options.  These schemes are stored in
*note sysconfig: 16f. under unique identifiers based on the value
returned by *note os.name: 1087.

  Every new component that is installed using *note distutils: 86. or a
Distutils-based system will follow the same scheme to copy its file in
the right places.

  Python currently supports seven schemes:

   - _posix_prefix_: scheme for Posix platforms like Linux or Mac OS X.
     This is the default scheme used when Python or a component is
     installed.

   - _posix_home_: scheme for Posix platforms used when a _home_ option
     is used upon installation.  This scheme is used when a component
     is installed through Distutils with a specific home prefix.

   - _posix_user_: scheme for Posix platforms used when a component is
     installed through Distutils and the _user_ option is used.  This
     scheme defines paths located under the user home directory.

   - _nt_: scheme for NT platforms like Windows.

   - _nt_user_: scheme for NT platforms, when the _user_ option is used.

   - _os2_: scheme for OS/2 platforms.

   - _os2_home_: scheme for OS/2 patforms, when the _user_ option is
     used.

  Each scheme is itself composed of a series of paths and each path has
a unique identifier.  Python currently uses eight paths:

   - _stdlib_: directory containing the standard Python library files
     that are not platform-specific.

   - _platstdlib_: directory containing the standard Python library
     files that are platform-specific.

   - _platlib_: directory for site-specific, platform-specific files.

   - _purelib_: directory for site-specific, non-platform-specific
     files.

   - _include_: directory for non-platform-specific header files.

   - _platinclude_: directory for platform-specific header files.

   - _scripts_: directory for script files.

   - _data_: directory for data files.

  *note sysconfig: 16f. provides some functions to determine these
paths.

 -- Function: sysconfig.get_scheme_names ()
     Return a tuple containing all schemes currently supported in *note
     sysconfig: 16f.

 -- Function: sysconfig.get_path_names ()
     Return a tuple containing all path names currently supported in
     *note sysconfig: 16f.

 -- Function: sysconfig.get_path (name[, scheme[, vars[, expand]]])
     Return an installation path corresponding to the path _name_, from
     the install scheme named _scheme_.

     _name_ has to be a value from the list returned by *note
     get_path_names(): 233f.

     *note sysconfig: 16f. stores installation paths corresponding to
     each path name, for each platform, with variables to be expanded.
     For instance the _stdlib_ path for the _nt_ scheme is:
     `{base}/Lib'.

     *note get_path(): 271. will use the variables returned by *note
     get_config_vars(): 270.  to expand the path.  All variables have
     default values for each platform so one may call this function and
     get the default value.

     If _scheme_ is provided, it must be a value from the list returned
     by *note get_path_names(): 233f.  Otherwise, the default scheme
     for the current platform is used.

     If _vars_ is provided, it must be a dictionary of variables that
     will update the dictionary return by *note get_config_vars(): 270.

     If _expand_ is set to `False', the path will not be expanded using
     the variables.

     If _name_ is not found, return `None'.

 -- Function: sysconfig.get_paths ([scheme[, vars[, expand]]])
     Return a dictionary containing all installation paths
     corresponding to an installation scheme. See *note get_path():
     271. for more information.

     If _scheme_ is not provided, will use the default scheme for the
     current platform.

     If _vars_ is provided, it must be a dictionary of variables that
     will update the dictionary used to expand the paths.

     If _expand_ is set to False, the paths will not be expanded.

     If _scheme_ is not an existing scheme, *note get_paths(): 2340.
     will raise a *note KeyError: 202.


File: python.info,  Node: Other functions,  Prev: Installation paths,  Up: sysconfig --- Provide access to Python's configuration information

5.27.2.3 Other functions
........................

 -- Function: sysconfig.get_python_version ()
     Return the `MAJOR.MINOR' Python version number as a string.
     Similar to `sys.version[:3]'.

 -- Function: sysconfig.get_platform ()
     Return a string that identifies the current platform.

     This is used mainly to distinguish platform-specific build
     directories and platform-specific built distributions.  Typically
     includes the OS name and version and the architecture (as supplied
     by *note os.uname(): 10a6.), although the exact information
     included depends on the OS; e.g. for IRIX the architecture isn't
     particularly important (IRIX only runs on SGI hardware), but for
     Linux the kernel version isn't particularly important.

     Examples of returned values:

        - linux-i586

        - linux-alpha (?)

        - solaris-2.6-sun4u

        - irix-5.3

        - irix64-6.2

     Windows will return one of:

        - win-amd64 (64bit Windows on AMD64 (aka x86_64, Intel64,
          EM64T, etc)

        - win-ia64 (64bit Windows on Itanium)

        - win32 (all others - specifically, sys.platform is returned)

     Mac OS X can return:

        - macosx-10.6-ppc

        - macosx-10.4-ppc64

        - macosx-10.3-i386

        - macosx-10.4-fat

     For other non-POSIX platforms, currently just returns *note
     sys.platform: 232d.

 -- Function: sysconfig.is_python_build ()
     Return `True' if the current Python installation was built from
     source.

 -- Function: sysconfig.parse_config_h (fp[, vars])
     Parse a `config.h'-style file.

     _fp_ is a file-like object pointing to the `config.h'-like file.

     A dictionary containing name/value pairs is returned.  If an
     optional dictionary is passed in as the second argument, it is
     used instead of a new dictionary, and updated with the values read
     in the file.

 -- Function: sysconfig.get_config_h_filename ()
     Return the path of `pyconfig.h'.


File: python.info,  Node: __builtin__ --- Built-in objects,  Next: future_builtins --- Python 3 builtins,  Prev: sysconfig --- Provide access to Python's configuration information,  Up: Python Runtime Services

5.27.3 `__builtin__' -- Built-in objects
----------------------------------------

This module provides direct access to all 'built-in' identifiers of
Python; for example, `__builtin__.open' is the full name for the
built-in function *note open(): 2cb.

  This module is not normally accessed explicitly by most applications,
but can be useful in modules that provide objects with the same name as
a built-in value, but in which the built-in of that name is also
needed.  For example, in a module that wants to implement an *note
open(): 2cb. function that wraps the built-in *note open(): 2cb, this
module can be used directly:

    import __builtin__

    def open(path):
        f = __builtin__.open(path, 'r')
        return UpperCaser(f)

    class UpperCaser:
        '''Wrapper around a file that converts output to upper-case.'''

        def __init__(self, f):
            self._f = f

        def read(self, count=-1):
            return self._f.read(count).upper()

        # ...

*CPython implementation detail:* Most modules have the name
`__builtins__' (note the `'s'') made available as part of their
globals.  The value of `__builtins__' is normally either this module or
the value of this modules's `__dict__' attribute.  Since this is an
implementation detail, it may not be used by alternate implementations
of Python.


File: python.info,  Node: future_builtins --- Python 3 builtins,  Next: __main__ --- Top-level script environment,  Prev: __builtin__ --- Built-in objects,  Up: Python Runtime Services

5.27.4 `future_builtins' -- Python 3 builtins
---------------------------------------------

New in version 2.6.

  This module provides functions that exist in 2.x, but have different
behavior in Python 3, so they cannot be put into the 2.x builtins
namespace.

  Instead, if you want to write code compatible with Python 3 builtins,
import them from this module, like this:

    from future_builtins import map, filter

    ... code using Python 3-style map and filter ...

The *note 2to3: bbf. tool that ports Python 2 code to Python 3 will
recognize this usage and leave the new builtins alone.

     Note: The Python 3 *note print(): 2fc. function is already in the
     builtins, but cannot be accessed from Python 2 code unless you use
     the appropriate future statement:

         from __future__ import print_function



  Available builtins are:

 -- Function: future_builtins.ascii (object)
     Returns the same as *note repr(): 146.  In Python 3, *note repr():
     146. will return printable Unicode characters unescaped, while
     *note ascii(): 234a. will always backslash-escape them.  Using
     *note future_builtins.ascii(): 234a. instead of *note repr(): 146.
     in 2.6 code makes it clear that you need a pure ASCII return value.

 -- Function: future_builtins.filter (function, iterable)
     Works like *note itertools.ifilter(): 84c.

 -- Function: future_builtins.hex (object)
     Works like the built-in *note hex(): 323, but instead of *note
     __hex__(): 351. it will use the *note __index__(): 25c. method on
     its argument to get an integer that is then converted to
     hexadecimal.

 -- Function: future_builtins.map (function, iterable, ...)
     Works like *note itertools.imap(): d1f.

 -- Function: future_builtins.oct (object)
     Works like the built-in *note oct(): 314, but instead of *note
     __oct__(): 352. it will use the *note __index__(): 25c. method on
     its argument to get an integer that is then converted to octal.

 -- Function: future_builtins.zip (*iterables)
     Works like *note itertools.izip(): 3f5.


File: python.info,  Node: __main__ --- Top-level script environment,  Next: warnings --- Warning control,  Prev: future_builtins --- Python 3 builtins,  Up: Python Runtime Services

5.27.5 `__main__' -- Top-level script environment
-------------------------------------------------

This module represents the (otherwise anonymous) scope in which the
interpreter's main program executes -- commands read either from
standard input, from a script file, or from an interactive prompt.  It
is this environment in which the idiomatic "conditional script" stanza
causes a script to run:

    if __name__ == "__main__":
        main()



File: python.info,  Node: warnings --- Warning control,  Next: contextlib --- Utilities for with-statement contexts,  Prev: __main__ --- Top-level script environment,  Up: Python Runtime Services

5.27.6 `warnings' -- Warning control
------------------------------------

New in version 2.1.

  Warning messages are typically issued in situations where it is
useful to alert the user of some condition in a program, where that
condition (normally) doesn't warrant raising an exception and
terminating the program.  For example, one might want to issue a
warning when a program uses an obsolete module.

  Python programmers issue warnings by calling the *note warn(): 4ad.
function defined in this module.  (C programmers use *note
PyErr_WarnEx(): 3d6.; see *note Exception Handling: 2354. for details).

  Warning messages are normally written to `sys.stderr', but their
disposition can be changed flexibly, from ignoring all warnings to
turning them into exceptions.  The disposition of warnings can vary
based on the warning category (see below), the text of the warning
message, and the source location where it is issued.  Repetitions of a
particular warning for the same source location are typically
suppressed.

  There are two stages in warning control: first, each time a warning
is issued, a determination is made whether a message should be issued
or not; next, if a message is to be issued, it is formatted and printed
using a user-settable hook.

  The determination whether to issue a warning message is controlled by
the warning filter, which is a sequence of matching rules and actions.
Rules can be added to the filter by calling *note filterwarnings():
443. and reset to its default state by calling *note resetwarnings():
2355.

  The printing of warning messages is done by calling *note
showwarning(): 2356, which may be overridden; the default
implementation of this function formats the message by calling *note
formatwarning(): 12b5, which is also available for use by custom
implementations.

* Menu:

* Warning Categories::
* The Warnings Filter::
* Temporarily Suppressing Warnings::
* Testing Warnings::
* Updating Code For New Versions of Python::
* Available Functions::
* Available Context Managers::


File: python.info,  Node: Warning Categories,  Next: The Warnings Filter,  Up: warnings --- Warning control

5.27.6.1 Warning Categories
...........................

There are a number of built-in exceptions that represent warning
categories.  This categorization is useful to be able to filter out
groups of warnings.  The following warnings category classes are
currently defined:

Class                                  Description
------------------------------------------------------------------------------------------- 
*note Warning: 922.                    This is the base class of all warning category
                                       classes.  It is a subclass of *note Exception: 328.
*note UserWarning: 923.                The default category for *note warn(): 4ad.
*note DeprecationWarning: 1b9.         Base category for warnings about deprecated
                                       features (ignored by default).
*note SyntaxWarning: 444.              Base category for warnings about dubious syntactic
                                       features.
*note RuntimeWarning: 924.             Base category for warnings about dubious runtime
                                       features.
*note FutureWarning: 2a9.              Base category for warnings about constructs that
                                       will change semantically in the future.
*note PendingDeprecationWarning: 1ed.  Base category for warnings about features that
                                       will be deprecated in the future (ignored by
                                       default).
*note ImportWarning: 3a3.              Base category for warnings triggered during the
                                       process of importing a module (ignored by default).
*note UnicodeWarning: 925.             Base category for warnings related to Unicode.

  While these are technically built-in exceptions, they are documented
here, because conceptually they belong to the warnings mechanism.

  User code can define additional warning categories by subclassing one
of the standard warning categories.  A warning category must always be
a subclass of the *note Warning: 922. class.

  Changed in version 2.7: *note DeprecationWarning: 1b9. is ignored by
default.


File: python.info,  Node: The Warnings Filter,  Next: Temporarily Suppressing Warnings,  Prev: Warning Categories,  Up: warnings --- Warning control

5.27.6.2 The Warnings Filter
............................

The warnings filter controls whether warnings are ignored, displayed,
or turned into errors (raising an exception).

  Conceptually, the warnings filter maintains an ordered list of filter
specifications; any specific warning is matched against each filter
specification in the list in turn until a match is found; the match
determines the disposition of the match.  Each entry is a tuple of the
form (_action_, _message_, _category_, _module_, _lineno_), where:

   * _action_ is one of the following strings:

     Value               Disposition
     ----------------------------------------------------------------------- 
     `"error"'           turn matching warnings into exceptions
     `"ignore"'          never print matching warnings
     `"always"'          always print matching warnings
     `"default"'         print the first occurrence of matching warnings
                         for each location where the warning is issued
     `"module"'          print the first occurrence of matching warnings
                         for each module where the warning is issued
     `"once"'            print only the first occurrence of matching
                         warnings, regardless of location

   * _message_ is a string containing a regular expression that the
     warning message must match (the match is compiled to always be
     case-insensitive).

   * _category_ is a class (a subclass of *note Warning: 922.) of which
     the warning category must be a subclass in order to match.

   * _module_ is a string containing a regular expression that the
     module name must match (the match is compiled to be
     case-sensitive).

   * _lineno_ is an integer that the line number where the warning
     occurred must match, or `0' to match all line numbers.

  Since the *note Warning: 922. class is derived from the built-in
*note Exception: 328.  class, to turn a warning into an error we simply
raise `category(message)'.

  The warnings filter is initialized by *note -W: 1ba. options passed
to the Python interpreter command line.  The interpreter saves the
arguments for all *note -W: 1ba. options without interpretation in
`sys.warnoptions'; the *note warnings: 194. module parses these when it
is first imported (invalid options are ignored, after printing a
message to `sys.stderr').

* Menu:

* Default Warning Filters::


File: python.info,  Node: Default Warning Filters,  Up: The Warnings Filter

5.27.6.3 Default Warning Filters
................................

By default, Python installs several warning filters, which can be
overridden by the command-line options passed to *note -W: 1ba. and
calls to *note filterwarnings(): 443.

   * *note PendingDeprecationWarning: 1ed, and *note ImportWarning:
     3a3. are ignored.

   * `BytesWarning' is ignored unless the `-b' option is given once or
     twice; in this case this warning is either printed (`-b') or
     turned into an exception (`-bb').


File: python.info,  Node: Temporarily Suppressing Warnings,  Next: Testing Warnings,  Prev: The Warnings Filter,  Up: warnings --- Warning control

5.27.6.4 Temporarily Suppressing Warnings
.........................................

If you are using code that you know will raise a warning, such as a
deprecated function, but do not want to see the warning, then it is
possible to suppress the warning using the *note catch_warnings: 2269.
context manager:

    import warnings

    def fxn():
        warnings.warn("deprecated", DeprecationWarning)

    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        fxn()

While within the context manager all warnings will simply be ignored.
This allows you to use known-deprecated code without having to see the
warning while not suppressing the warning for other code that might not
be aware of its use of deprecated code.  Note: this can only be
guaranteed in a single-threaded application. If two or more threads use
the *note catch_warnings: 2269. context manager at the same time, the
behavior is undefined.


File: python.info,  Node: Testing Warnings,  Next: Updating Code For New Versions of Python,  Prev: Temporarily Suppressing Warnings,  Up: warnings --- Warning control

5.27.6.5 Testing Warnings
.........................

To test warnings raised by code, use the *note catch_warnings: 2269.
context manager. With it you can temporarily mutate the warnings filter
to facilitate your testing. For instance, do the following to capture
all raised warnings to check:

    import warnings

    def fxn():
        warnings.warn("deprecated", DeprecationWarning)

    with warnings.catch_warnings(record=True) as w:
        # Cause all warnings to always be triggered.
        warnings.simplefilter("always")
        # Trigger a warning.
        fxn()
        # Verify some things
        assert len(w) == 1
        assert issubclass(w[-1].category, DeprecationWarning)
        assert "deprecated" in str(w[-1].message)

One can also cause all warnings to be exceptions by using `error'
instead of `always'. One thing to be aware of is that if a warning has
already been raised because of a `once'/`default' rule, then no matter
what filters are set the warning will not be seen again unless the
warnings registry related to the warning has been cleared.

  Once the context manager exits, the warnings filter is restored to
its state when the context was entered. This prevents tests from
changing the warnings filter in unexpected ways between tests and
leading to indeterminate test results. The *note showwarning(): 2356.
function in the module is also restored to its original value.  Note:
this can only be guaranteed in a single-threaded application. If two or
more threads use the *note catch_warnings: 2269. context manager at the
same time, the behavior is undefined.

  When testing multiple operations that raise the same kind of warning,
it is important to test them in a manner that confirms each operation
is raising a new warning (e.g. set warnings to be raised as exceptions
and check the operations raise exceptions, check that the length of the
warning list continues to increase after each operation, or else delete
the previous entries from the warnings list before each new operation).


File: python.info,  Node: Updating Code For New Versions of Python,  Next: Available Functions,  Prev: Testing Warnings,  Up: warnings --- Warning control

5.27.6.6 Updating Code For New Versions of Python
.................................................

Warnings that are only of interest to the developer are ignored by
default. As such you should make sure to test your code with typically
ignored warnings made visible. You can do this from the command-line by
passing `-Wd' to the interpreter (this is shorthand for `-W default').
This enables default handling for all warnings, including those that
are ignored by default.  To change what action is taken for encountered
warnings you simply change what argument is passed to *note -W: 1ba,
e.g. `-W error'. See the *note -W: 1ba. flag for more details on what
is possible.

  To programmatically do the same as `-Wd', use:

    warnings.simplefilter('default')

Make sure to execute this code as soon as possible. This prevents the
registering of what warnings have been raised from unexpectedly
influencing how future warnings are treated.

  Having certain warnings ignored by default is done to prevent a user
from seeing warnings that are only of interest to the developer. As you
do not necessarily have control over what interpreter a user uses to
run their code, it is possible that a new version of Python will be
released between your release cycles.  The new interpreter release
could trigger new warnings in your code that were not there in an older
interpreter, e.g.  *note DeprecationWarning: 1b9. for a module that you
are using. While you as a developer want to be notified that your code
is using a deprecated module, to a user this information is essentially
noise and provides no benefit to them.


File: python.info,  Node: Available Functions,  Next: Available Context Managers,  Prev: Updating Code For New Versions of Python,  Up: warnings --- Warning control

5.27.6.7 Available Functions
............................

 -- Function: warnings.warn (message[, category[, stacklevel]])
     Issue a warning, or maybe ignore it or raise an exception.  The
     _category_ argument, if given, must be a warning category class
     (see above); it defaults to *note UserWarning: 923.  Alternatively
     _message_ can be a *note Warning: 922. instance, in which case
     _category_ will be ignored and `message.__class__' will be used.
     In this case the message text will be `str(message)'. This
     function raises an exception if the particular warning issued is
     changed into an error by the warnings filter see above.  The
     _stacklevel_ argument can be used by wrapper functions written in
     Python, like this:

         def deprecation(message):
             warnings.warn(message, DeprecationWarning, stacklevel=2)

     This makes the warning refer to `deprecation()''s caller, rather
     than to the source of `deprecation()' itself (since the latter
     would defeat the purpose of the warning message).

 -- Function: warnings.warn_explicit (message, category, filename,
          lineno[, module[, registry[, module_globals]]])
     This is a low-level interface to the functionality of *note
     warn(): 4ad, passing in explicitly the message, category, filename
     and line number, and optionally the module name and the registry
     (which should be the `__warningregistry__' dictionary of the
     module).  The module name defaults to the filename with `.py'
     stripped; if no registry is passed, the warning is never
     suppressed.  _message_ must be a string and _category_ a subclass
     of *note Warning: 922. or _message_ may be a *note Warning: 922.
     instance, in which case _category_ will be ignored.

     _module_globals_, if supplied, should be the global namespace in
     use by the code for which the warning is issued.  (This argument
     is used to support displaying source for modules found in zipfiles
     or other non-filesystem import sources).

     Changed in version 2.5: Added the _module_globals_ parameter.

 -- Function: warnings.warnpy3k (message[, category[, stacklevel]])
     Issue a warning related to Python 3.x deprecation. Warnings are
     only shown when Python is started with the -3 option. Like *note
     warn(): 4ad. _message_ must be a string and _category_ a subclass
     of *note Warning: 922. *note warnpy3k(): 2364.  is using *note
     DeprecationWarning: 1b9. as default warning class.

     New in version 2.6.

 -- Function: warnings.showwarning (message, category, filename,
          lineno[, file[, line]])
     Write a warning to a file.  The default implementation calls
     `formatwarning(message, category, filename, lineno, line)' and
     writes the resulting string to _file_, which defaults to
     `sys.stderr'.  You may replace this function with an alternative
     implementation by assigning to `warnings.showwarning'.  _line_ is
     a line of source code to be included in the warning message; if
     _line_ is not supplied, *note showwarning(): 2356. will try to
     read the line specified by _filename_ and _lineno_.

     Changed in version 2.7: The _line_ argument is required to be
     supported.

 -- Function: warnings.formatwarning (message, category, filename,
          lineno[, line])
     Format a warning the standard way.  This returns a string which
     may contain embedded newlines and ends in a newline.  _line_ is a
     line of source code to be included in the warning message; if
     _line_ is not supplied, *note formatwarning(): 12b5. will try to
     read the line specified by _filename_ and _lineno_.

     Changed in version 2.6: Added the _line_ argument.

 -- Function: warnings.filterwarnings (action[, message[, category[,
          module[, lineno[, append]]]]])
     Insert an entry into the list of *note warnings filter
     specifications: 2359.  The entry is inserted at the front by
     default; if _append_ is true, it is inserted at the end.  This
     checks the types of the arguments, compiles the _message_ and
     _module_ regular expressions, and inserts them as a tuple in the
     list of warnings filters.  Entries closer to the front of the list
     override entries later in the list, if both match a particular
     warning.  Omitted arguments default to a value that matches
     everything.

 -- Function: warnings.simplefilter (action[, category[, lineno[,
          append]]])
     Insert a simple entry into the list of *note warnings filter
     specifications: 2359.  The meaning of the function parameters is
     as for *note filterwarnings(): 443, but regular expressions are
     not needed as the filter inserted always matches any message in
     any module as long as the category and line number match.

 -- Function: warnings.resetwarnings ()
     Reset the warnings filter.  This discards the effect of all
     previous calls to *note filterwarnings(): 443, including that of
     the *note -W: 1ba. command line options and calls to *note
     simplefilter(): 226a.


File: python.info,  Node: Available Context Managers,  Prev: Available Functions,  Up: warnings --- Warning control

5.27.6.8 Available Context Managers
...................................

 -- Class: warnings.catch_warnings ([*, record=False, module=None])
     A context manager that copies and, upon exit, restores the
     warnings filter and the *note showwarning(): 2356. function.  If
     the _record_ argument is *note False: 3a0. (the default) the
     context manager returns *note None: 389. on entry. If _record_ is
     *note True: 39f, a list is returned that is progressively
     populated with objects as seen by a custom *note showwarning():
     2356. function (which also suppresses output to `sys.stdout').
     Each object in the list has attributes with the same names as the
     arguments to *note showwarning(): 2356.

     The _module_ argument takes a module that will be used instead of
     the module returned when you import *note warnings: 194. whose
     filter will be protected. This argument exists primarily for
     testing the *note warnings: 194.  module itself.

          Note: The *note catch_warnings: 2269. manager works by
          replacing and then later restoring the module's *note
          showwarning(): 2356. function and internal list of filter
          specifications.  This means the context manager is modifying
          global state and therefore is not thread-safe.

          Note: In Python 3.0, the arguments to the constructor for
          *note catch_warnings: 2269. are keyword-only arguments.

     New in version 2.6.


File: python.info,  Node: contextlib --- Utilities for with-statement contexts,  Next: abc --- Abstract Base Classes,  Prev: warnings --- Warning control,  Up: Python Runtime Services

5.27.7 `contextlib' -- Utilities for `with'-statement contexts
--------------------------------------------------------------

New in version 2.5.

  This module provides utilities for common tasks involving the *note
with: 1bd.  statement. For more information see also *note Context
Manager Types: 736. and *note With Statement Context Managers: 735.

See also
........

Latest version of the contextlib Python source code(1)

  Functions provided:

 -- Function: contextlib.contextmanager (func)
     This function is a *note decorator: 827. that can be used to
     define a factory function for *note with: 1bd. statement context
     managers, without needing to create a class or separate *note
     __enter__(): 1fc. and *note __exit__(): 1fd. methods.

     A simple example (this is not recommended as a real way of
     generating HTML!):

         from contextlib import contextmanager

         @contextmanager
         def tag(name):
             print "<%s>" % name
             yield
             print "</%s>" % name

         >>> with tag("h1"):
         ...    print "foo"
         ...
         <h1>
         foo
         </h1>

     The function being decorated must return a *note generator:
     5bb.-iterator when called. This iterator must yield exactly one
     value, which will be bound to the targets in the *note with: 1bd.
     statement's *note as: 2e9. clause, if any.

     At the point where the generator yields, the block nested in the
     *note with: 1bd.  statement is executed.  The generator is then
     resumed after the block is exited.  If an unhandled exception
     occurs in the block, it is reraised inside the generator at the
     point where the yield occurred.  Thus, you can use a *note try:
     384...*note except: 386...*note finally: 385. statement to trap
     the error (if any), or ensure that some cleanup takes place. If an
     exception is trapped merely in order to log it or to perform some
     action (rather than to suppress it entirely), the generator must
     reraise that exception. Otherwise the generator context manager
     will indicate to the *note with: 1bd. statement that the exception
     has been handled, and execution will resume with the statement
     immediately following the *note with: 1bd. statement.

 -- Function: contextlib.nested (mgr1[, mgr2[, ...]])
     Combine multiple context managers into a single nested context
     manager.

     This function has been deprecated in favour of the multiple
     manager form of the *note with: 1bd. statement.

     The one advantage of this function over the multiple manager form
     of the *note with: 1bd. statement is that argument unpacking
     allows it to be used with a variable number of context managers as
     follows:

         from contextlib import nested

         with nested(*managers):
             do_something()

     Note that if the *note __exit__(): 1fd. method of one of the
     nested context managers indicates an exception should be
     suppressed, no exception information will be passed to any
     remaining outer context managers. Similarly, if the *note
     __exit__(): 1fd. method of one of the nested managers raises an
     exception, any previous exception state will be lost; the new
     exception will be passed to the *note __exit__(): 1fd. methods of
     any remaining outer context managers. In general, *note
     __exit__(): 1fd. methods should avoid raising exceptions, and in
     particular they should not re-raise a passed-in exception.

     This function has two major quirks that have led to it being
     deprecated. Firstly, as the context managers are all constructed
     before the function is invoked, the *note __new__(): 6d3. and
     *note __init__(): 36b. methods of the inner context managers are
     not actually covered by the scope of the outer context managers.
     That means, for example, that using *note nested(): 1e6. to open
     two files is a programming error as the first file will not be
     closed promptly if an exception is thrown when opening the second
     file.

     Secondly, if the *note __enter__(): 1fc. method of one of the
     inner context managers raises an exception that is caught and
     suppressed by the *note __exit__(): 1fd. method of one of the
     outer context managers, this construct will raise *note
     RuntimeError: 38a. rather than skipping the body of the *note
     with: 1bd.  statement.

     Developers that need to support nesting of a variable number of
     context managers can either use the *note warnings: 194. module to
     suppress the DeprecationWarning raised by this function or else
     use this function as a model for an application specific
     implementation.

     Deprecated since version 2.7: The with-statement now supports this
     functionality directly (without the confusing error prone quirks).

 -- Function: contextlib.closing (thing)
     Return a context manager that closes _thing_ upon completion of
     the block.  This is basically equivalent to:

         from contextlib import contextmanager

         @contextmanager
         def closing(thing):
             try:
                 yield thing
             finally:
                 thing.close()

     And lets you write code like this:

         from contextlib import closing
         import urllib

         with closing(urllib.urlopen('http://www.python.org')) as page:
             for line in page:
                 print line

     without needing to explicitly close `page'.  Even if an error
     occurs, `page.close()' will be called when the *note with: 1bd.
     block is exited.

See also
........

PEP 0343(2) - The "with" statement
     The specification, background, and examples for the Python *note
     with: 1bd.  statement.

  ---------- Footnotes ----------

  (1)
http://svn.python.org/view/python/branches/release27-maint/Lib/contextlib.py?view=markup

  (2) http://www.python.org/dev/peps/pep-0343


File: python.info,  Node: abc --- Abstract Base Classes,  Next: atexit --- Exit handlers,  Prev: contextlib --- Utilities for with-statement contexts,  Up: Python Runtime Services

5.27.8 `abc' -- Abstract Base Classes
-------------------------------------

New in version 2.6.

  This module provides the infrastructure for defining an *note
abstract base class: 874. (ABCs) in Python, as outlined in PEP 3119(1);
see the PEP for why this was added to Python. (See also PEP 3141(2) and
the *note numbers: 126. module regarding a type hierarchy for numbers
based on ABCs.)

  The *note collections: 65. module has some concrete classes that
derive from ABCs; these can, of course, be further derived. In addition
the *note collections: 65. module has some ABCs that can be used to
test whether a class or instance provides a particular interface, for
example, is it hashable or a mapping.

  This module provides the following class:

 -- Class: abc.ABCMeta
     Metaclass for defining Abstract Base Classes (ABCs).

     Use this metaclass to create an ABC.  An ABC can be subclassed
     directly, and then acts as a mix-in class.  You can also register
     unrelated concrete classes (even built-in classes) and unrelated
     ABCs as "virtual subclasses" - these and their descendants will be
     considered subclasses of the registering ABC by the built-in *note
     issubclass(): 30f. function, but the registering ABC won't show up
     in their MRO (Method Resolution Order) nor will method
     implementations defined by the registering ABC be callable (not
     even via *note super(): 36c.). (3)

     Classes created with a metaclass of *note ABCMeta: 6f4. have the
     following method:

      -- Method: register (subclass)
          Register _subclass_ as a "virtual subclass" of this ABC. For
          example:

              from abc import ABCMeta

              class MyABC:
                  __metaclass__ = ABCMeta

              MyABC.register(tuple)

              assert issubclass(tuple, MyABC)
              assert isinstance((), MyABC)



     You can also override this method in an abstract base class:

      -- Method: __subclasshook__ (subclass)
          (Must be defined as a class method.)

          Check whether _subclass_ is considered a subclass of this
          ABC.  This means that you can customize the behavior of
          `issubclass' further without the need to call *note
          register(): 236b. on every class you want to consider a
          subclass of the ABC.  (This class method is called from the
          `__subclasscheck__()' method of the ABC.)

          This method should return `True', `False' or
          `NotImplemented'.  If it returns `True', the _subclass_ is
          considered a subclass of this ABC.  If it returns `False',
          the _subclass_ is not considered a subclass of this ABC, even
          if it would normally be one.  If it returns `NotImplemented',
          the subclass check is continued with the usual mechanism.


     For a demonstration of these concepts, look at this example ABC
     definition:

         class Foo(object):
             def __getitem__(self, index):
                 ...
             def __len__(self):
                 ...
             def get_iterator(self):
                 return iter(self)

         class MyIterable:
             __metaclass__ = ABCMeta

             @abstractmethod
             def __iter__(self):
                 while False:
                     yield None

             def get_iterator(self):
                 return self.__iter__()

             @classmethod
             def __subclasshook__(cls, C):
                 if cls is MyIterable:
                     if any("__iter__" in B.__dict__ for B in C.__mro__):
                         return True
                 return NotImplemented

         MyIterable.register(Foo)

     The ABC `MyIterable' defines the standard iterable method, *note
     __iter__(): 310, as an abstract method.  The implementation given
     here can still be called from subclasses.  The `get_iterator()'
     method is also part of the `MyIterable' abstract base class, but
     it does not have to be overridden in non-abstract derived classes.

     The *note __subclasshook__(): 236c. class method defined here says
     that any class that has an *note __iter__(): 310. method in its
     `__dict__' (or in that of one of its base classes, accessed via
     the `__mro__' list) is considered a `MyIterable' too.

     Finally, the last line makes `Foo' a virtual subclass of
     `MyIterable', even though it does not define an *note __iter__():
     310. method (it uses the old-style iterable protocol, defined in
     terms of *note __len__(): 3f9. and *note __getitem__(): 43e.).
     Note that this will not make `get_iterator' available as a method
     of `Foo', so it is provided separately.

  It also provides the following decorators:

 -- Function: abc.abstractmethod (function)
     A decorator indicating abstract methods.

     Using this decorator requires that the class's metaclass is *note
     ABCMeta: 6f4. or is derived from it.  A class that has a metaclass
     derived from *note ABCMeta: 6f4.  cannot be instantiated unless
     all of its abstract methods and properties are overridden.  The
     abstract methods can be called using any of the normal 'super' call
     mechanisms.

     Dynamically adding abstract methods to a class, or attempting to
     modify the abstraction status of a method or class once it is
     created, are not supported.  The *note abstractmethod(): 236d.
     only affects subclasses derived using regular inheritance;
     "virtual subclasses" registered with the ABC's `register()' method
     are not affected.

     Usage:

         class C:
             __metaclass__ = ABCMeta
             @abstractmethod
             def my_abstract_method(self, ...):
                 ...


          Note: Unlike Java abstract methods, these abstract methods
          may have an implementation. This implementation can be called
          via the *note super(): 36c. mechanism from the class that
          overrides it.  This could be useful as an end-point for a
          super-call in a framework that uses cooperative
          multiple-inheritance.

 -- Function: abc.abstractproperty ([fget[, fset[, fdel[, doc]]]])
     A subclass of the built-in *note property(): 476, indicating an
     abstract property.

     Using this function requires that the class's metaclass is *note
     ABCMeta: 6f4. or is derived from it.  A class that has a metaclass
     derived from *note ABCMeta: 6f4. cannot be instantiated unless all
     of its abstract methods and properties are overridden.  The
     abstract properties can be called using any of the normal 'super'
     call mechanisms.

     Usage:

         class C:
             __metaclass__ = ABCMeta
             @abstractproperty
             def my_abstract_property(self):
                 ...

     This defines a read-only property; you can also define a
     read-write abstract property using the 'long' form of property
     declaration:

         class C:
             __metaclass__ = ABCMeta
             def getx(self): ...
             def setx(self, value): ...
             x = abstractproperty(getx, setx)



  ---------- Footnotes ----------

  (1) http://www.python.org/dev/peps/pep-3119

  (2) http://www.python.org/dev/peps/pep-3141

  (3) C++ programmers should note that Python's virtual base class
concept is not the same as C++'s.


File: python.info,  Node: atexit --- Exit handlers,  Next: traceback --- Print or retrieve a stack traceback,  Prev: abc --- Abstract Base Classes,  Up: Python Runtime Services

5.27.9 `atexit' -- Exit handlers
--------------------------------

New in version 2.0.

  The *note atexit: 12. module defines a single function to register
cleanup functions.  Functions thus registered are automatically
executed upon normal interpreter termination.

See also
........

Latest version of the atexit Python source code(1)

  Note: the functions registered via this module are not called when
the program is killed by a signal not handled by Python, when a Python
fatal internal error is detected, or when *note os._exit(): 91c. is
called.

  This is an alternate interface to the functionality provided by the
`sys.exitfunc' variable.

  Note: This module is unlikely to work correctly when used with other
code that sets `sys.exitfunc'.  In particular, other core Python
modules are free to use *note atexit: 12. without the programmer's
knowledge.  Authors who use `sys.exitfunc' should convert their code to
use *note atexit: 12. instead.  The simplest way to convert code that
sets `sys.exitfunc' is to import *note atexit: 12. and register the
function that had been bound to `sys.exitfunc'.

 -- Function: atexit.register (func[, *args[, **kargs]])
     Register _func_ as a function to be executed at termination.  Any
     optional arguments that are to be passed to _func_ must be passed
     as arguments to *note register(): 4de.

     At normal program termination (for instance, if *note sys.exit():
     2a2. is called or the main module's execution completes), all
     functions registered are called in last in, first out order.  The
     assumption is that lower level modules will normally be imported
     before higher level modules and thus must be cleaned up later.

     If an exception is raised during execution of the exit handlers, a
     traceback is printed (unless *note SystemExit: 321. is raised) and
     the exception information is saved.  After all exit handlers have
     had a chance to run the last exception to be raised is re-raised.

     Changed in version 2.6: This function now returns _func_ which
     makes it possible to use it as a decorator without binding the
     original name to `None'.

See also
........

Module *note readline: 145.
     Useful example of *note atexit: 12. to read and write *note
     readline: 145. history files.

* Menu:

* atexit Example::

  ---------- Footnotes ----------

  (1)
http://svn.python.org/view/python/branches/release27-maint/Lib/atexit.py?view=markup


File: python.info,  Node: atexit Example,  Up: atexit --- Exit handlers

5.27.9.1 `atexit' Example
.........................

The following simple example demonstrates how a module can initialize a
counter from a file when it is imported and save the counter's updated
value automatically when the program terminates without relying on the
application making an explicit call into this module at termination.

    try:
        _count = int(open("/tmp/counter").read())
    except IOError:
        _count = 0

    def incrcounter(n):
        global _count
        _count = _count + n

    def savecounter():
        open("/tmp/counter", "w").write("%d" % _count)

    import atexit
    atexit.register(savecounter)

Positional and keyword arguments may also be passed to *note
register(): 4de. to be passed along to the registered function when it
is called:

    def goodbye(name, adjective):
        print 'Goodbye, %s, it was %s to meet you.' % (name, adjective)

    import atexit
    atexit.register(goodbye, 'Donny', 'nice')

    # or:
    atexit.register(goodbye, adjective='nice', name='Donny')

Usage as a *note decorator: 827.:

    import atexit

    @atexit.register
    def goodbye():
        print "You are now leaving the Python sector."

This obviously only works with functions that don't take arguments.


File: python.info,  Node: traceback --- Print or retrieve a stack traceback,  Next: __future__ --- Future statement definitions,  Prev: atexit --- Exit handlers,  Up: Python Runtime Services

5.27.10 `traceback' -- Print or retrieve a stack traceback
----------------------------------------------------------

This module provides a standard interface to extract, format and print
stack traces of Python programs.  It exactly mimics the behavior of the
Python interpreter when it prints a stack trace.  This is useful when
you want to print stack traces under program control, such as in a
"wrapper" around the interpreter.

  The module uses traceback objects -- this is the object type that is
stored in the variables *note sys.exc_traceback: 224b. (deprecated) and
*note sys.last_traceback: 22ad. and returned as the third item from
*note sys.exc_info(): 2e4.

  The module defines the following functions:

 -- Function: traceback.print_tb (traceback[, limit[, file]])
     Print up to _limit_ stack trace entries from _traceback_.  If
     _limit_ is omitted or `None', all entries are printed. If _file_
     is omitted or `None', the output goes to `sys.stderr'; otherwise
     it should be an open file or file-like object to receive the
     output.

 -- Function: traceback.print_exception (type, value, traceback[,
          limit[, file]])
     Print exception information and up to _limit_ stack trace entries
     from _traceback_ to _file_. This differs from *note print_tb():
     2375. in the following ways: (1) if _traceback_ is not `None', it
     prints a header `Traceback (most recent call last):'; (2) it
     prints the exception _type_ and _value_ after the stack trace; (3)
     if _type_ is *note SyntaxError: 485. and _value_ has the
     appropriate format, it prints the line where the syntax error
     occurred with a caret indicating the approximate position of the
     error.

 -- Function: traceback.print_exc ([limit[, file]])
     This is a shorthand for `print_exception(sys.exc_type,
     sys.exc_value, sys.exc_traceback, limit, file)'.  (In fact, it
     uses *note sys.exc_info(): 2e4. to retrieve the same information
     in a thread-safe way instead of using the deprecated variables.)

 -- Function: traceback.format_exc ([limit])
     This is like `print_exc(limit)' but returns a string instead of
     printing to a file.

     New in version 2.4.

 -- Function: traceback.print_last ([limit[, file]])
     This is a shorthand for `print_exception(sys.last_type,
     sys.last_value, sys.last_traceback, limit, file)'.  In general it
     will work only after an exception has reached an interactive
     prompt (see *note sys.last_type: 2329.).

 -- Function: traceback.print_stack ([f[, limit[, file]]])
     This function prints a stack trace from its invocation point.  The
     optional _f_ argument can be used to specify an alternate stack
     frame to start.  The optional _limit_ and _file_ arguments have
     the same meaning as for *note print_exception(): 1292.

 -- Function: traceback.extract_tb (traceback[, limit])
     Return a list of up to _limit_ "pre-processed" stack trace entries
     extracted from the traceback object _traceback_.  It is useful for
     alternate formatting of stack traces.  If _limit_ is omitted or
     `None', all entries are extracted.  A "pre-processed" stack trace
     entry is a quadruple (_filename_, _line number_, _function name_,
     _text_) representing the information that is usually printed for a
     stack trace.  The _text_ is a string with leading and trailing
     whitespace stripped; if the source is not available it is `None'.

 -- Function: traceback.extract_stack ([f[, limit]])
     Extract the raw traceback from the current stack frame.  The
     return value has the same format as for *note extract_tb(): 237a.
     The optional _f_ and _limit_ arguments have the same meaning as
     for *note print_stack(): 2379.

 -- Function: traceback.format_list (list)
     Given a list of tuples as returned by *note extract_tb(): 237a. or
     *note extract_stack(): 237b, return a list of strings ready for
     printing.  Each string in the resulting list corresponds to the
     item with the same index in the argument list.  Each string ends
     in a newline; the strings may contain internal newlines as well,
     for those items whose source text line is not `None'.

 -- Function: traceback.format_exception_only (type, value)
     Format the exception part of a traceback.  The arguments are the
     exception type and value such as given by `sys.last_type' and
     `sys.last_value'.  The return value is a list of strings, each
     ending in a newline.  Normally, the list contains a single string;
     however, for *note SyntaxError: 485. exceptions, it contains
     several lines that (when printed) display detailed information
     about where the syntax error occurred.  The message indicating
     which exception occurred is the always last string in the list.

 -- Function: traceback.format_exception (type, value, tb[, limit])
     Format a stack trace and the exception information.  The arguments
     have the same meaning as the corresponding arguments to *note
     print_exception(): 1292.  The return value is a list of strings,
     each ending in a newline and some containing internal newlines.
     When these lines are concatenated and printed, exactly the same
     text is printed as does *note print_exception(): 1292.

 -- Function: traceback.format_tb (tb[, limit])
     A shorthand for `format_list(extract_tb(tb, limit))'.

 -- Function: traceback.format_stack ([f[, limit]])
     A shorthand for `format_list(extract_stack(f, limit))'.

 -- Function: traceback.tb_lineno (tb)
     This function returns the current line number set in the traceback
     object.  This function was necessary because in versions of Python
     prior to 2.3 when the *note -O: 442. flag was passed to Python the
     `tb.tb_lineno' was not updated correctly.  This function has no
     use in versions past 2.3.

* Menu:

* Traceback Examples::

